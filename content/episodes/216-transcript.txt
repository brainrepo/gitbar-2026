Siamo noi quelli che leggendo il codice cercano lo stronzo che ha scritto quello schifo, ma ahimè lo stronzo è me medesimo e l'ho scritto giusto ieri. Siamo quelli che santificano il nuovo framework javascript preferendo segretamente jQuery, stessi per il quale il testing è importante, infatti la nostra codezza ha solo due test e flake pure. Siamo noi quelli che il tuo linguaggio fa cagare ma il mio è peggio, quelli che la chiarezza nei comment message prima di tutto e dentro ce l'appella tutti i santi, quelli che in call parlano per 5 minuti prima di accorgersi che il mic è muto, quelli che non si può fare di default diventa velocemente un tutto e possibile sia le risorse tempo e budget ilimitato. Siamo noi Noi quelli che l'AI va regolamentata, mai visto questo nuovo modello che disegna Ratti Nifunambuli? Quelli che il "dipende" e un esci gratis da prigione. E quelli che la RAL... No vabbè, fa già ridere così. Siamo quelli che fanno lo slalom tra le specifiche che cambiano costantemente, ormai rassegnati che la definition of ready è solo una pia illusione. Quelli che si sentano dire "ho un'idea per un'app" ed è subito l'ennesimo social come Instagram, ma meglio. Siamo noi che nonostante il deploy fallito, la C.I. rossa, il business incazzato, ci troviamo al Gitbar e davanti a una birra tutto ci sembra un po' meno grave. Bene bene bene e benvenuti su Gitbar, nuova settimana e nuovo episodio qua nel nostro bar degli sviluppatori. Io sono Brain Repo come ben sapete, lo so lo so è da un po' che non mi faccio sentire, vi ho fatto tante promesse di ritornare regolare ma questo avverrà, non posso dirvi quando ma questo avverrà presto. Detto questo io vi ricordo rapidamente i nostri contatti prima di iniziare, info@gitbar.it @brainrepo su Twitter che ormai non uso più quindi in realtà dimenticate quello che ho appena detto, e il nostro gruppo Telegram, il gruppo nel quale ci troviamo, nel quale chiacchieriamo delle nostre cose, roba tecnica, roba un po' più politica, in realtà trovate un po' di tutto, se non l'avete ancora fatto mi raccomando entrate nel gruppo e entrerete nella tana del bianconiglio. Detto questo io voglio presentarvi i miei due ospiti di oggi, in realtà questa puntata la stiamo organizzando da un po' di tempo credo e io tutto questo tempo fremevo nell'averli in puntata perché questa puntata prenderà anche una piega un po' politica Ed è quello che a me piace di Gitver, lo sapete, no? Quest'ultimo... più vado col tempo e più divento, vabbè, a parte bisbetico, un po' tipo... non so se ricordate il vecchio film di Celentano, no? Il bisbetico domato, ecco, più il tempo passa più divento Celentano, fondamentalmente. Celentano di un metro e venti e più il tempo passa però e più mi appassiono alle challenge di natura sociale politica con la p maiuscola e sono queste quelle challenge che talvolta cerchiamo di portare qua qua su github. Mega introduzione per dirvi che ho con noi due illustrissimi membri della open Open Knowledge Foundation, ho con noi Sara Petti, community manager, più un altro, mi ha spiegato altri 70 ruoli che io ahimè faccio fatica a ricordare. Ciao Sara. Ciao, e se li posso ricordare dopo se vuoi. Sì sì no, poi ci torniamo, ci torniamo subito, subito dopo aver presentato Patrizio Del Bocca che è invece il tech lead dell'Open Knowledge Foundation. Ciao Patrizio! Ciao, ciao Ryan, grazie per l'invitazione, un piacere per noi stare qui. Allora, se Patrizio in qualità di tech lead ha un ruolo che un po' ci viene facile, no, perché si avvicina tantissimo all'audience media di Gitbar, sarà... possiamo fare un percorso o una breve analisi dei tuoi ruoli? Assolutamente, questo è quello che faccio ogni volta che incontro mia madre o qualsiasi membro della mia famiglia e cercare di spiegare quello che faccio, sempre senza grande successo, spero di averne di più in questa occasione. Dunque, il mio primo ruolo quindi, che ti hai già nominato, Community Manager, è quello con cui ho cominciato, Open Knowledge Foundation, ed è praticamente tra i vari progetti che noi abbiamo. Ovviamente abbiamo tutti i progetti open source e quindi essendo progetti open source ci sono delle comunità che lavorano intorno a questi progetti e quindi quello di cui io inizialmente mi sono occupata Open è la comunità che si raccoglie intorno a un progetto che si chiama Frictionless Data, che è brevemente un toolkit praticamente con uno standard per containerizzare i dati, non so se questa parola esiste in italiano, potrei averla appena inventata, che si chiama Data Package, e poi dopo una serie di librerie, software, che implementano questo standard e che praticamente rendono possibile fare tutta una serie di cose con i dati, come convalidare dei dataset, per esempio trasformare i dati, eccetera. E gli altri due miei ruoli che invece non ricordavi, uno in realtà è molto semplice ed è il ruolo di Project Manager, quindi Open Knowledge Foundation ovviamente nel senso abbiamo bisogno anche di questi ruoli qui. E sono la Project Manager sia per dei progetti di Seacon, che è un progetto di cui parleremo più avanti, sia per un altro progetto che ci piacerebbe molto discutere in questo podcast, che è Open Data Editor, che è un'applicazione, vabbè ne parleremo dopo. E comunque l'ultimo mio ruolo invece è leader del network internazionale perché Open Knowledge Foundation nasce come un'organizzazione non profit, ma rapidamente nel momento di boom dei dati aperti ci sono state una serie di comunità o di gruppi o di organizzazioni che sono andate in vari paesi e che in effetti quindi ora si chiamano per esempio Open Knowledge Germania, Open Knowledge Svizzera. C'era anche un tempo Open Knowledge Italia, che si raccoglieva intorno al gruppo Spaghetti Open Data, ma anche di questo magari parleremo più avanti. e questi sono i miei ruoli comunque. Insomma, tanta... - La nostra guisata. - No, tra l'altro quando dicevi "faccio fatica comunque a spiegare alla mia famiglia i miei ruoli", tranquilla, è un po' credo quello che succede a Patrizio quando deve spiegare il suo, che è solo uno, però è altrettanto complesso. Io... anche io in qualità di teclizzo talvolta non so come dirlo, non so cosa fai, "boh, aiuto macchine e persone a non bisticciare tra di loro gli uni con gli altri, you know, è un po' così. Comunque scherzi a parte, negli ultimi una decina di anni fa c'era tanto rumore attorno agli open data, partiva la famosa rivoluzione delle API, dove le API iniziavano a essere viste più come un prodotto aperto, le famose app... come si chiamavano? Le mix up, mixed up dove prendevi consumavi dati da una parte, API dall'altra e creavi un prodotto tutto nuovo, un'idea tutta nuova con dei dati che erano presenti e delle funzionalità che erano esposte e c'era un rumore enorme attorno agli open data ricordo che c'erano budget investiti anche a livello pubblico, intendo le amministrazioni pubbliche per gli open data e sembrava fosse quella la via no? Sembrava chiaro a tutti che gli open data sarebbero stati il modo per gestire i dati di pubblica utilità almeno quelli di pubblica utilità. Sono passati dieci anni da quando io ricordo così a spanne, no? Sto un po' andando a sentimenti però credo siano passati attorno ai dieci anni forse qualcuno in più da quel periodo. Qual è lo stato di salute dalla vostra prospettiva degli open data? Come siamo messi in Italia, in Europa e in generale nel mondo? Allora comincio io ma poi dopo Patrizio sicuramente può completare sicuramente con un sacco di informazioni tecniche in più. Diciamo la grande spinta degli Open Data che poi nel senso è quello che Open Knowledge ha anche spinto tantissimo. Open Knowledge nasce nel 2004 ed è una delle organizzazioni veramente pioniere di tutta la spinta per gli Open Data. In effetti Open Knowledge è anche quella che poi dopo ha fatto partire quella che è conosciuta come la Open Definition ma che era una cosa di cui anche potremmo possiamo parlare più avanti, quindi è stata quella che ha definito, che ha creato uno standard di che cosa voleva dire, praticamente un contenuto open o i dati open per l'appunto. C'è stato sicuramente, come dicevi te, una fortissima spinta intorno ai primi dieci anni degli anni 2000, in cui anche i governi si sono moltissimo attrezzati, insomma, quel periodo di fortuna anche di Spaghetti o Pendera, che premeva tantissimo, per esempio, per avere dati aperti delle pubbliche amministrazioni in Italia, e c'è stato un certo successo, nel senso che a un certo punto, comunque nel senso effettivamente le pubbliche amministrazioni hanno cominciato a pubblicare dei dati aperti. Ora, abbiamo raggiunto il livello di qualità meraviglioso che ci aspettavamo? Probabilmente no, però se non altro insomma direi che c'è stata comunque una legifrazione a proposito e quindi in questo momento comunque nel senso in generale le pubbliche amministrazioni sono obbligate a pubblicare dei dati. Quindi questa è sicuramente una grande conquista che forse ha anche a che fare con il fatto, diciamo, che si sente meno parlare di Open Data e che forse c'è stata una grande conquista a un certo punto e ora quindi si è passati da un lato diciamo meno combattivo e si è passati in una fase un po' più istituzionale, diciamo, in cui c'è ancora tanto lavoro da fare, chiaramente, perché la qualità dei dati ancora non c'è, però diciamo quella prima lotta e quella prima spinta forse è passata in un certo senso. E una cosa che Patrizio mi dice sempre, che io trovo super interessante, è che in effetti forse siamo passati da un movimento che lottava contro le pubbliche amministrazioni per dire ci dovete dare i dati aperti, aprite i dati, aprite i dati, a una fase in cui forse delle organizzazioni come la nostra dovrebbero più accompagnare e allearsi in un certo senso con le pubbliche amministrazioni per aiutarli a fare un lavoro migliore. E su questo lascio la parola a Patrizio che sicuramente ha qualcosa di più da dire. Va bene lo che hai dito, ma credo che per aggiungere un po' di informazione della situazione attuale dell'open data, io credo che dopo 15 anni l'open data non ha arrivato alla sua promessa iniziale di che l'open data rivoluzionare tutto, o rivoluzionaria tutto. Abbiamo avuto tantissimo progresso abbiamo avuto tantissime cose buone ma siamo stancati, siamo in un periodo in cui cosa facciamo con l'open data? In due sensi, prima perché hai una grave diversità, una gran diversità tra lo che è l'open data in Europa e negli Stati Uniti e lo che è l'open data in latinoamerica o in l'africa o in la sud dell'asia. Io sono argentino, sono del sud america e il contesto e la tecnologia in latinoamerica e l'accesso all'open data è completamente diverso per le varrete tecnologica, per la diversità in prezzi, per la diversità in talento. Quindi la promessa di un movimento globale sta lì perché hanno tantissimo movimento, l'Open Knowledge Foundation è una red che abbiamo tantissimi capitoli anche in latinoamerica, anche in africa, ma il punto tecnologico ha una barriera e ha una diversità enorme. Credo che se non possiamo ridurre o avvicinare la differenza tra nord e sud, la promessa dell'open data sarà un po' problematica. E credo che in situazione tecnologica siamo in un punto nel quale, se parliamo dell'Europa o degli Stati Uniti, la pubblicazione e l'accesso al dato e all'open data è buono, è buono, ha i buoni tools e software per pubblicazione di open data, ma non abbiamo tantissimi tools per consumire questi dati, non abbiamo software per fare cose con l'open data. In tantissime parti della popolazione non so che cosa è l'open data, non so come utilizzare e l'open data. Quindi siamo in un punto che come che la base dell'open data sta, ma dobbiamo ripensare il movimento, dobbiamo ripensare cosa facciamo con tutto lo che abbiamo costruito in questi ultimi dieci anni. Mi viene intanto da approfondire una cosa, perché questa cosa mi interessa particolarmente. hai detto che ci sono parti del mondo dove l'accesso al dato o immagino anche la creazione del dato è limitato da un technological gap che è ancora presente e che da questa parte dell'Europa che è abbastanza sviluppata a livello tecnologico facciamo difficoltà a vedere quindi aiutaci a inquadrare il problema. Quando noi diciamo che per esempio esiste ancora questo technological gap per esempio in latinoamerica e in africa, riesce a portarci degli esempi pratici perché io vedo che i computer grosso modo ci sono dappertutto nelle amministrazioni anche quelli insomma più, mi viene da dire più più più remote no? Mi veniva inculandia giusto per dire quelle più remote o comunque con un accesso difficile alla rete. Grosso modo una connessione e un computer c'è sempre. Spesso c'è un foglio di calcolo o un computer per quanto vecchio può riuscire a generare e a gestire dei dati. Quindi quando dici technological gap a cosa ti riferisci nello specifico? me rifero a due cose. Prima che non hanno il conoscimento della tecnologia per accedere al dato no, una cosa, che non hanno il conoscimento per accedere al dato. Per esempio la promessa dell'open data era open, accessibile a tutto il mondo, leggere per la macchina, gratuito, economico. E ho detto "buono, se pubbliciamo l'open data il giornalista, la società civile, tutto il mondo potrà usare l'open data". Ma in Asentina io ho lavorato per esempio con un gruppo di giornalista. sì il mio governo nazionale ha pubblicato una API per accedere alla serie temporale di dati economici ma quando io vado al giornalista del giornale locale gli dico "no no ma guarda questa API" cosa è un'API? che cosa faccio con questa cosa? no ma perché si fa un script con Python con che? Io ho un Excel qui, cosa faccio con questo? Buono, sì, guarda, se tu vai con questi bottoni puoi download un CSV. Cosa è un CSV? Beh, è come un archivo di Excel, è come un file di Excel ma similare, buono, aprilo con l'Excel, buono sì. Ora, fa una pivot table per... cosa è una pivot table? Quindi il giornalista non sapeva come usare un Excel e mi chiamava una volta in un programma perché noi avevamo un blog di Data Journalism e avevo fatto un piccolo analisi di un dinerò dell'estato e mi hanno detto "ma come hai fatto questo? Era una notizia importante, come hai fatto questo?" Guarda, ho entrato nel portale, ho scaricato il csv, il csv, l'ho aperto con l'excel, filtro, ordinare di maggiore a minore, ecco, e basta. Quindi bene, questo è il gap, hai un gap enorme nel conoscimento per accedere alla tecnologia e negli soldi per pagarli alla persona che sape come usare la tecnologia. - Ho colto pienamente, mi sono occupato anche io di data journalist, di data journalism, infatti sono un giornalista tra le tante cose che faccio, è una cosa, una difficoltà che che ho sempre avuto parlando a quei colleghi è stata quella di dire "Ehi, siamo nel ventunesimo secolo, ormai inoltrato, insomma, passato un bel po' dall'inizio del ventunesimo secolo, quindi oggi la tua fonte è anche questo, devi imparare a gestirlo il dato, perché ci sono tanti dati e questi dati ti danno indizi, informazioni, elementi, quindi sì sì ho colto pieno il concetto, quello che manca in realtà non è un gap di natura meramente tecnologica ma di alfabetizzazione tecnologica, alfabetizzazione al dato. Mentre Patrizio parlava in realtà ha tirato dentro un concetto di giornalista locale e così stiamo andando a braccio però questa cosa mi ha aperto, mi ha portati in un light bulb time, no? Un momento lampadina. Come vedete, perché una cosa che ho sempre visto quando si parla di big data è un forte gap tra quello che è macro e quello che è micro. Io ho sempre visto le grandi organizzazioni, lo Stato, le grandi entità, rilasciare dei dati. Parliamo dei ministeri, parliamo delle regioni, però ho visto sempre meno o sempre pochi comuni o piccoli ambiti lasciare dei dati che abbiano senso. È una mia percezione o è qualcosa che anche voi registrate in fase di raccolta dati cioè le piccole comunità, i piccoli ambienti fanno difficoltà a rilasciare dei dati e se sì secondo voi quali sono le cause di questo di questo gap? Guarda è interessante come domanda e penso che alcune delle risposte erano già in quello che ti diceva Patrizio prima, secondo me. La prima cosa è che effettivamente una piccola realtà avrà anche meno risorse che può dedicare alla raccolta di dati, alla pubblicazione di dati, eccetera. Ci sono dei casi virtuosi in Italia, per esempio, stavo guardando poco prima del podcast, per esempio, chi è che usa Seacan e ci sono dei comuni più grandi, chiaramente, che usano Seacan, per esempio, come portale per i dati aperti, per esempio il comune di Palermo, di Bari, insomma, Firenze, mi sembra Torino anche. Però stiamo parlando di grandi città già, quindi comunque delle realtà che hanno delle risorse che possono dedicare, hanno probabilmente un team tecnico che può lavorare a questa cosa o comunque insomma hanno delle risorse economiche che possono dedicare a questo. Io vengo da un piccolissimo comune del sud Italia in provincia di Salerno, dubito che il mio comune abbia qualsiasi tipo di equip tecnica, magari sarò molto sorpresa la prossima volta che vado e sicuramente indagherò. Quindi c'è questo secondo me che è il problema principale. C'è anche, secondo me, una cosa legata alle regolamentazioni e le legislazioni, in quello che appunto le varie entità, i vari livelli sono obbligati anche a pubblicare, che mi viene da pensare che probabilmente per un piccolo comune sono probabilmente anche meno. Poi ci sono dei casi virtuosi di nuovo, perché il punto secondo me che è sempre e basta avere poi una persona che è una persona illuminata, che si interessa alla cosa e lo vediamo spesso anche nel nostro lavoro. Basta avere una persona e una persona può veramente trainare tutti quanti. Però c'è sicuramente una grossa difficoltà legata anche all'alfabetizzazione dei dati, al fatto che le persone ancora non capiscono l'importanza di pubblicare dei dati e quindi, di conseguenza, ci dedicano poche risorse. Ecco, quindi questo penso che è il problema principale. si vale. Sì, sì, non è una cosa difficile, è così, è falta di cultura, di pubblicazione di dati, di conoscere l'importanza e falta di budget anche, perché quella è la realtà, le piccole comune... poi tantissime volte sono questi piccoli comuni lo che hanno tantissimi dati di interesse, ma non hanno il budget, non hanno le culture. Chi sono le comune o i governi che possono aprire i dati? I che hanno un equipo tecnico, una squadra tecnica dentro il governo che puoi montare un servitore, una piattaforma web, un SICAN, e poi tu hai bisogno di due o tre developer, un piccolo product owner, un equipo di apertura di access di informazioni. Il governo ha bisogno di una struttura, di una squadra, un equipo, un team interno. Un piccolo comune di 10.000 abitanti, non credo che altre persone per quello. Lo quale è un problema è una tristezza perché quelli comune piccolino hanno tantissima informazione, ma sì, credo che è semplice, falta di pacchetti, falta di cultura. - Su questo avete ragione, però secondo me c'è una sfumatura che dobbiamo considerare. Io per un po' di tempo mi sono... ho lavorato lavorato coi comuni, mi sono occupato anche anche anche di politica no? E quindi questo tipo di rapporti li ho vissuti in prima persona. Credo che però ci sia una considerazione da fare che spesso quando siamo concentrati sul macro trascuriamo. Molte delle attività dei comuni spesso vengono gestite da piattaforme molto più ampie del comune stesso mi viene da pensare noi sistemi SOGIEI o chi per loro ok altre volte alcuni servizi vengono offerti da sistemi SAS e in realtà mi chiedo quanti di questi sistemi possono in modo essendo sistemi distribuiti orizzontalmente in un numero ampio di comuni possano by design esportare i dati e quanto per esempio questi sistemi SAS possono automaticamente esportare cacchio esistono delle piattaforme per creare il sito del comune con le comunicazioni l'app del comune quello che volete ci può essere per quei comuni che non se lo possono permettere intanto esistono le unioni di comuni quindi in realtà i costi si possono spalmare su più comuni però esistono dei servizi che ti dicono che tu non ti preoccupare non tirare il tuo chicane della situazione tu paghi una piccola fee c'è questa società che lo fa per te il classico business open source no? che ti mettono su te lo tengono app and running e tu distribuisci i tuoi file. Quindi da una parte potremmo avere delle società che fanno questo, dall'altra parte potremmo avere le grandi piattaforme o comunque le piattaforme distribuite che in modo automatico e by design possono esportare i dati. Quindi in realtà il vero problema dal momento che l'operatore nel comune carica i dati perché li deve caricare sul gestionale e la piattaforma lo fa in modo automatico perché se lo può permettere perché la piattaforma serve 1000-2000 comuni, 500 comuni e quindi il budget per fare questo tipo di attività esiste ed è spalmato su 500 comuni, mi chiedo quanto in realtà questo non avvenga per un problema di A) coordinamento entità. B domanda da parte dei comuni o delle piccole realtà che vanno dal fornitore e si dicono sì va beh noi lo acquistiamo ma abbiamo bisogno anche di questa feature quindi anche consapevolezza. C è qua bold opinion e quindi insomma mi prendo tutte le responsabilità di quello tutto quello che dico lo dico come Mauro e è solo Mauro e me ne prendo tutte le responsabilità, quanti invece queste grandi piattaforme non hanno interesse a condividere i dati? Perché? Perché il famoso effetto Lockheed e mille mille altre dinamiche. Ragazzi quando una cosa che si fa di solito quando quando si fa una campagna elettorale di solito si va alla Nagrafe e si chiedono le liste elettorali perché servono per avere uno spaccato delle persone. Questa è una cosa, è una prassi comune, chiunque abbia fatto una campagna elettorale l'ha fatto. Andare a un comune, chiedere le liste elettorali e dire "ok questo l'abbiamo contattato, con questo ci abbiamo parlato, con questo no". Ecco, ma vi sembra normale che nel caso migliore sono dei file di testo tabulati, nel caso peggiore sono dei pdf che sono intrasformabili perché hanno intestazione... anzi adesso con l'esplosione degli LLM poi gli script di estrazione dal pdf sono migliorati ma rimangono comunque uno schifo totale quindi mi chiedo quali sono, giusto per ricapitolare perché io quando poi prendo la tangente non mi farò ma quali sono le portanti di questa situazione è davvero un problema di solo di consapevolezza? è un problema di costi solo di costi? o c'è anche qualcosa che in realtà va palesato ma che insomma è insito nella natura dei grandi contractor o dei grandi SaaS che entrano nell'amministrazione nelle piccole realtà? - Qua tocchi precisamente il punto su cui noi ci stiamo più interessando a Open Knowledge in questo momento, che è legato a un'iniziativa che è tutta un'idea di Patrizio che è venuta l'anno scorso a un certo punto, insomma viene da tutti i brainstorming anche precedenti, è un'iniziativa che si chiama "The Tech We Want", in cui in effetti c'è quello di cui anche che osserviamo effettivamente c'è una incredibile complicazione legata allo stack che viene utilizzato per anche per i dati aperti, ma comunque in generale in ambito tecnologico, e che spesso magari un piccolo comune, per esempio, che è un ottimo esempio, non ha bisogno di tutti quegli layer di complicazione, magari ha bisogno di una feature particolare e specifica, ma a lui gli vendono direttamente tutto il pacchetto completo con tutta una serie di cose che in realtà non gli servono e che tra l'altro lo obbligano a tenere su tutta una equipe tecnica molto grossa per star dietro a queste cose o comunque ad avere una spesa economica legata a quello. E l'altra cosa che dicevi, che è una cosa che osserviamo con questo prodotto che stiamo sviluppando in questa iniziativa di TechCoop Conf, che si chiama Open Data Editor, che è un'applicazione desktop che praticamente aiuta persone senza competenze tecniche di programmazione a, diciamo, migliorare la qualità dei dataset con cui lavorano. In effetti c'è uno sviluppo tecnologico gigantesco che abbiamo negli ultimi anni, però in effetti lo status dei dati è sempre lo stesso ed è una schifezza, come decite, nel senso dall'inizio di come funzionano i dati tabulari. e ci sono PDF ancora che vengono pubblicati e che vengono definiti dati aperti e insomma tutto è chiaramente estremamente complicato. Nonostante ci sono principi come i Fair Data Principle, insomma ci sono comunque delle, in teoria, degli standard da rispettare. La situazione è ancora abbastanza drammatica e ci sono dataset falciti di errori con anche nel senso doppie intitolature, con insomma nel senso un format che non è neanche quadrato, a volte insomma sono delle cose abbastanza agghiaccianti. E quello è dovuto di nuovo a forse una poca ed una scarsa educazione dei dati, ma anche forse al fatto che per tanto tempo in effetti l'idea di dato aperto è rimasta semplicemente un'idea in ambito tecnologico e per persone con skills abbastanza avanzate. Mentre invece la realtà dei fatti è che in un piccolo comune la persona che pubblica i dati probabilmente non ha delle conoscenze di programmazione. Quindi quello che noi ci siamo chiesti è come aiutare queste persone, perché sicuramente non sono persone che avendo un lavoro full time sono interessate a prendere una laurea in data engineering, quindi com'è che possiamo aiutarle a fare il loro lavoro anche in una maniera migliore, senza, insomma, nel senso neanche, come dire, caricarli di un'eccessiva complicazione. E quindi per questo servono degli strumenti, che però sono degli strumenti che devono essere pensati appositamente per queste persone. Infatti la cosa molto interessante che abbiamo osservato, abbiamo una super produttore che ha cominciato a lavorare con noi l'anno scorso, Romina Colman, e lei ha fatto tutta una grande ricerca, una user research, in cui si è resa conto che un sacco di termini che noi usavamo dentro quel knowledge, perché noi lavoriamo sempre con comunità tecnica, abbiamo sempre lavorato semplicemente con comunità tecnica, di programmatori, di persone super esperte in dati, e c'erano proprio dei termini che utilizziamo che la gente non capiva, tipo per esempio se te dici validare un dataset, io lo capisco, o patrice lo capisce, tu lo capisci, ma se vai a parlare con quello del comune del mio paese, probabilmente no, non capisce neanche di che stai parlando. E quello di cui ci siamo resi conto è che effettivamente quando inizi a utilizzare un linguaggio che è complesso e che la gente non capisce, la gente automaticamente penserà che non è una cosa per loro e che quindi, di conseguenza, fanno un passo indietro e quindi ti riconsegnano il PDF di cui parlavamo prima. Quindi diciamo che c'è una problematica anche legata a questo. Quindi quello di cui noi ci stiamo tanto interessando è anche cercare di capire come fornire gli strumenti perché in realtà la maggior parte delle persone là fuori che non hanno delle competenze tecniche. E però ci sono tante di queste persone, appunto, che comunque sono obbligate a lavorare con i dati, che pubblicano i dati che noi dovremmo consumare e quindi nel senso come fare in modo di aiutare queste persone in modo che i dati che poi consumiamo sono dei dati di migliore qualità. Buono, no, perché tu hai detto con il repo tre cose interessanti, e tre punti che hai menzionato, l'ABC. nel video che hai menzionato che sì, tutte le comuni usano lo stesso software e forse loro possono avere la capacità tecnica e il budget perché è un software che tutti utilizzano una sola feature. È vero, il problema lì per me è la cultura, che non ha cultura di apertura di dati, questa cooperazione che hai bisogno per definire che il nostro software deve avere una feature per pubblicare dati, non esiste quella cultura. È una cosa che la nostra fondazione fa, è una advocacy per parlare con il comune, per dirle che questa cosa devi pensare in questo. Noi abbiamo la Open Knowledge Foundation, questi è "open by design" e quando pensiamo ai processi, quando pensiamo al software, by design pensiamo all'apertura dei dati, quindi dobbiamo pensarlo e dobbiamo, se il comune e la organizzazione, il governo ha la cultura, è possibile di creare questa feature nel sistema che utilizzano tutto il mondo. Ma dopo hai parlato di una cosa importantissima che è il vendor lock-in. Quello è vero. Non so com'è la situazione specificamente in Italia ma in Latino America e in Argentina tante volte si utilizzano software, private software, nel governo dove il dati dell'amministrazione pubblica è o in un Google Drive o in un OneDrive di Microsoft o è in una piattaforma SaaS che non so chi è la venduto e che nel processo di compra che il governo ha usato per licitare o per... voglio questi software non ha un punto lì che dice "Bueno, se questo è un software as a service, io voglio che c'è una app per me per scaricare tutti i dati". Quindi il vendor lock-in e il data lock-in è un problema che dobbiamo risolvere. E particolarmente, perché ha menzionato le lezioni, noi avevamo un problema in Argentina, perché per un sistema elettorale hanno usato Amazon Cloud per la gestione del software e quindi tutti i dati elettorali e le fotografie, la carta, i documenti erano su un Amazon Web Service ma la nostra processo giudiziale non ha giurisdizione sul territorio nordamericano e quindi se abbiamo algun problema, che avevamo bisogno di quei dati, se lo dobbiamo chiedere al governo degli Stati Uniti. Quindi era una cosa come "com'è possibile che il nostro processo elettorale corre sopra una plataforma straniera?". E' un problema del cloud, che il cloud è tutto un mondo. Ma il Ma il vendor lock-in, per chiudere il topic, il vendor lock-in dobbiamo di parlarlo apertamente, che è un problema enorme. Sì, il problema del cloud americano e di tutti i risvolti nell'adozione a livello nazionale, anche in Italia, è una delle mie battaglie. Non perché sia contro il cloud americano, ma perché si sta parlando di geopolitica e non più di acquistare un servizio. e quindi bisogna agire in termini geopolitici, però questo potrebbe aprire un'enorme discussione che ci teniamo per la prossima volta in realtà, però voglio voglio proprio essere il cattivo, il rompiscatola della situazione. In realtà talvolta aprire i dati può essere un rischio politico e porta un'esperienza personale. Io tanti anni fa, più di dieci, avevo una società che si occupava di servizio alle pubbliche amministrazioni e avevamo realizzato un prodotto che abbiamo fatto, abbiamo fatto tantissima difficoltà a piazzarlo sul mercato perché in realtà era il momento, dieci, quindici anni fa, era il momento in cui i consigli comunali delle municipalità si iniziavano a fare online e in diretta. e quindi noi cosa abbiamo detto? Sempre con la logica dell'open data. Vabbè, sapete cosa facciamo? Noi li registriamo, li trascriviamo e creiamo dei file che tracciano cosa ogni politico dice nel consiglio comunale. In realtà il prodotto era una figata perché tu potevi cercare esattamente cosa quella specifica persona aveva detto, essendo un politico ed essendo una seduta pubblica aveva senso, non c'era privacy perché è una seduta pubblica e quindi era ottimo per i fini della cittadinanza attiva e tutte quelle belle attività, però in realtà avere quel tipo di dati open, accessibili e liberamente fruibili era un problema, quindi in realtà il quarto punto che secondo me va considerato è quanto gli open data possano essere un problema perché se noi abbiamo il pdf come dicevo un prima e ho 50.000 pdf a meno che tu non sia veramente super skillato che estrai i testi da tutti i pdf aggreghi te sei proprio un data scientist e tu fai questo tipo di lavoro e in realtà ce n'è pochi e pochi che hanno voglia di farlo, però a meno che tu non sia così tu stai nascondendo l'informazione all'interno di un grande calderone informazioni, ma se tu l'informazione la strutturi, la distribuisci seguendo uno standard che quindi ha come obiettivo la fruizione dell'informazione stessa, tu stai semplificando tutto il processo che può portarti a generare quel rischio. Sto ragionando da politico in questo momento no? Dico perché io devo aprire dei dati, che ne so, dei budget spesi nella mia regione ok, se non ho una richiesta specifica della legge che mi dica lo devi fare in con questo formato e in questo modo. Perché devo farlo quando è più facile non farlo o nascondere l'informazione? Ma non perché ci sia un dolo nel farlo, ma perché semplicemente si evita un problema perché poi quando entrano in mano i giornalisti i dati strutturati i giornalisti poi sparano perché è il loro lavoro fare, fare quello no? E quindi c'è secondo me anche questo, questo elemento da considerare e in questo elemento, in questa arena abbiamo la cittadinanza e la classe politica dirigenziale quindi ci metto anche dirigenti pubblici e i dirigenti e le grandi partecipate, di quelli che dovrebbero essere i data provider di pubblica utilità che sono in due angoli divisi e distanti del ring. E anche questo secondo me è uno dei problemi che ha in qualche modo messo un tappo alla distribuzione dei dati. Sì, ma è vero, in un ring abbiamo la cittadinanza di un lato, e in un lato i politici dell'altro; l'apertura dato è un problema politico alcune volte, ma è anche un processo politico. Come attivista dell'open data io credo che l'apertura di dato è un ciclo, è come che va e vena. Per esempio noi abbiamo fatto tantissimo lavoro in Cordova, Argentina, nella mia città, per l'apertura di dati. Un governo aveva bisogno di trasparenza, di legittimità, di dire "noi vogliamo fare le cose bene", quindi hanno detto "vogliamo fare un open data portal, vogliamo pubblicare informazione. Quindi loro hanno chiamato alla società civile, alla cittadinanza e hanno detto "vogliamo aprire dato, vogliamo fare un processo pubblico, trasparente, aperto". Va bene, noi abbiamo andato, abbiamo parlato con i politici che le fotografie, che l'apertura, che l'informazione, perfetto, portali dato aperto, hanno pubblicato tre o quattro, perfetto, va bene, perfetto sei anni... sei mesi dopo, sette mesi dopo stiamo investigando, ricercando sul soldi che il governo gli dà al giornalista per la pubblicità e come il governo gli dà soldi ai diversi giornalisti; ho andato al stesso governo che sei mesi prima mi hanno dato la mano perché hanno stato... io "eh senti ho bisogno di questi dati" "no questi dati non lo abbiamo, questi dati ha informazione personale che non si può dare, che è una cosa che è altra cosa" e l'ho detto "guarda il governo nazionale lo pubblica quindi tu devi pubblicarlo anche" Bene, con il stesso governo che sei mesi prima abbiamo fatto una fotografia, abbiamo tutto un processo giudiziale, illegale, perché loro non volevano aprire. E dopo, un altro governo, un anno dopo, hanno usato il nostro processo legale per combattere non sai che cosa, l'arena politica. Quindi, se uno come attivista o come giornalista entra in questo gioco politico e gioca con il tempo, uno ha bisogno che il dato che uno non vuole aprire e l'altro sì lo vuole aprire. Quando uno non vuole aprire uno, vuole aprire l'altro. Quindi uno può giocare lì, in questo gioco politico e poi piano piano, anno tra anno, apre apre però l'importante è che se uno sube come... no loro lo pubblicano tu devi pubblicarli se uno lo pubblica perché non so se è sbagliato o non so che cosa ma se uno lo pubblica tu sai da quelli lo pubblica quindi tu devi pubblicarlo anche - sì perché hai la chiave del cos'hai da nascondere - esatto sì, però sì un amico mio dice, ma non so se in italiano sarà lo stesso, dice "dati che si apre e tavacheria che si chiude" quindi perché dentro del governo anche il dato e l'informazione è un business, quindi puoi aprirmi questi dati? No, perché se io ti avrò questo dato il mio business interno la mia negoziazione perdo il leverage che ho, quindi se io ti apro il tatto perdo questo business, e quella è un'altra battaglia che dobbiamo dare, quindi sì, l'arena politica è un tema. - E poi pensavo sempre al discorso che facevate, no, delle piccole realtà, no? e io ritorno ai comuni ma perché ci ho passato tanto tempo lottando nei comuni che sono poi comuni e province che sono un po' le entità a cui il cittadino ha più facilmente accesso anche la piccola azienda ha più facilmente accesso l'associazione ha più facilmente accesso e pensavo una cosa entriamo nel piccolo comune di 5.000 abitanti sfido chiunque a dire quanti cavolo di giardinieri ha un comune di 5.000 abitanti perché abbiamo parlato di risorse no? Quanti giardinieri ha il comune 5.000 abitanti? Secondo me almeno due o tre e allora vogliamo dire che giardinieri tuttofare, riparatori no, quei signori che rendono la città vivibile non curano le piccole cose, gli immobili del comune. Ok, ma Cribbio, saranno forse i giardini e le aiuole un asset più importante dei dati di quella comunità? - Beh nella testa di tanti è così penso purtroppo... - E questo in un'epoca storica che ci piace chiamare l'epoca del dato no? Cioè suona suona solo a me paradossale questa cosa... - Anche a noi, assolutamente! - Con giardini i dati io ho una ossessione perché anche io abito in un comune non di 5.000 ma di 20.000-30.000 abitanti, ma non ora forse 50.000 abitanti in Argentina e abbiamo tantissimo giardinero e tantissimi giardini ma sempre abbiamo... loro cambiano le fiori tutto il tempo, tutto il tempo cambiano le fiori e io voglio dato che mi dice "quanto soldi per le fiori a chi se le compra? è un processo di licitazione aperta o è un piccolo business tra un amico che ha il...?" quindi sì, non so, al micro level il dato è... per per me, per il giornalista locale, questi dati sono come l'elita della notizia. Sì, la mia provocazione era, ma se c'hai, che ne so, dieci manutentori, sette manutentori, e stai pagando dieci stipendi, sette stipendi, prenderti un data scientist, un data analyst, un data expert, uno, per tutto il comune, per tutta la piccola realtà, che ce la fa insomma c'è un po' di dati, lavora full time e uno stipendio. In Italia i data analyst sono pagati più o meno come i giardinieri. Questa è un'altra provocazione. Però penso che manca un po' la cultura secondo me, nel senso, ora pensando al mio per esempio comune che è anche un comune di 15.000 20.000 abitanti e non so quanti hanno l'idea che può essere effettivamente utile assumere un data scientist e in effetti assumendo il giardiniero o comunque delle persone che si occupano dello spazio pubblico ti ingrazia un po' i voti della gente che vedono che stai facendo qualcosa mentre invece diciamo per la cittadinanza poco attiva del mio comune per esempio e in effetti la fruzione di dati è proprio un problema non è neanche una cosa che sentono come una necessità e quindi in effetti c'è anche un gap di domanda secondo me. E' questo perché la classe politica che abbiamo è ridicola perché da persona che ha fatto politica so benissimo che i dati si possono piegare a qualunque tipo di narrazione e quindi hanno un estremo valore politico in termini di propaganda. Quindi in realtà anche questo è quello che hai appena detto sì, sono d'accordo con te, ma è proprio legato alla generazione, all'analfabetismo e non in termini di dati, ma l'analfabetismo della politica moderna e dell'approccio moderno alla politica stessa. Però forse è meglio... - No, è interessante questa cosa che dici, mi fa pensare a una newsletter che ho letto tipo due giorni fa di Donata Columbro che si chiama "Cherry picking dei dati" che se non avete letto vi consiglio assolutamente di come la classe politica in effetti può anche utilizzare i dati per prendere un'informazione e stravolarla completamente dal proprio contesto e utilizzarla completamente per parlare di una cosa che è l'opposto di una cosa che è il dato. Non fatelo a casa, non è corretto farlo, però questo per dire che hanno comunque anche un valore per quel politico locale che vuole costruire. Quindi in realtà è proprio come dicevate prima... Boh... non so se è un mix di ignoranza, malafede, paura... Ci sono tante cose in mezzo che è difficile. Però adesso parliamo un attimo di progetti e di giocattoli, perché questa è una di quelle parti che mi interessa tantissimo. Mi avete parlato di una serie di progetti. Credo che mi avete parlato di frictionless data, open data editor, SCCAN e poi del progetto "The Tech We Want". Da cosa vogliamo partire? Scegli tu! Ok, "The Tech We Want", giusto per seguire un filone discorsivo. Di cosa si tratta? E' perfetto per il filone esclusivo, perché questo progetto nasce da tutti i problemi che stiamo parlando ora. Come è possibile che in Comune, nell'anno 2025, non puoi avere due software engineers per fare il processo digitale, il servizio pubblico digitale? Come è possibile? Quali sono i problemi? Perché? Perché non ha? E uno dei tanti problemi è che il software e la tecnologia è complicata. E in questi ultimi 10-20 anni di software development la tecnologia non si è avvolta più facile, si è avvolta più difficile. anni fa un software engineering un server con un HTML con un PHP una pagina web un MySQL una persona ti faceva due tre software e va bene. Ora vuoi una pagina web? Buona, guarda, che il backend engineer, che il front end engineer, che il product owner, che il UX designer, che... "ma io voglio un formulario online per chiedere al mio cittadino cosa vuole per la festività di Natale". No, che il Agile, che il Backlog, che... "guarda, un piccolo formulario". No, no, perché vogliamo che l'intorno del testing, che l'Automatic, che il Kubernetes, che vogliamo la reproduzione... Quindi il software è diventato questa cosa assurda che per noi, prima che lavoriamo nella società civile, che non abbiamo i soldi che hanno Facebook, Netflix, Microsoft per pagare i soldi di ingegneri, che lavoriamo con il comune, noi abbiamo detectato, abbiamo visto che con la tecnologia, oggi in dia, il software è un casino, dobbiamo semplificarlo. Quindi The Tech Week One è questo progetto ombrellone per discutere tutto, per discutere l'estate come è il software oggi. Quindi è un progetto più filosofico, più politico e non tanto tecnologico. Io voglio di parlarlo tecnologicamente anche perché voglio parlare con il software designer, software engineer che programma il framework del React o il framework di Svelte. La cultura del programmatore. Perché dobbiamo andare all'ultima moda del software per tutto lo che abbiamo bisogno? Perché scegliamo un framework e tra due anni dobbiamo re-scrivere tutte le applicazioni perché il render engine ha cambiato. No, no, no. Dobbiamo scegliere il nostro tool in maniera un po' più sostenibile, un po' più pensando futuro, un po' più eticamente. Quindi Tag1 è questo, è un progetto per parlare, per pensare una forma diversa, più sostenibile di fare tecnologia. E questo dopo arriva a tutti gli altri nostri progetti tecnologici. L'Open Data Editor è un esempio di quello. L'Open Data Editor è un'applicazione desktop per aiutare alla persona che non ha conoscenza tecnologica di validare un dato, di aprire un CSV che si voglia pubblicare, un'applicazione che aiuta l'usuario a dirle "no, guarda, hai due file che sono le stesse, due columne hanno le stesse nome, guarda in questa columna hanno tipo di dati diversi e un'applicazione desktop. Quando abbiamo iniziato, vabbè, che il fast API, che il React frontend, che l'electron, che non se che altro casino, era una cosa... voglio aprire un CSV, fare un paio di validazioni e un un paio di warnings all'usuario. Non ho un disegno di tanta complessità e anche la vogliamo fare desktop perché i nostri usuari sono per esempio giornalista che non vuole che il suo CSV è nella nuve, nella cloud. Quindi perché abbiamo scelto una tecnologia come React, come Fest API, come Electron che, sì, è il standard oggi dell'industria per fare desktop application, ma perché? Perché la Big Tech o perché tutte le grandi compagnie che hanno team di front-end e di back-end vogliono reusare lo stesso team per fare un scrittorio, un'app di scrittorio, o perché voglio che la mia applicazione sia web e anche nel desktop. Quindi è un tool che forse per la Big Tech o per queste grandi compagnie va bene, ma per una piccola organizzazione come la nostra, noi vogliamo un tool, un framework un po' più semplice. Quindi abbiamo scelto Qt, il PySide 6, un framework desktop di antico che sta nel mercato da 30 anni fa, ma che è stabile, che funziona, che va bene, che non ha una parafernalia, che simplifica tutto, che abbiamo un solo disarrollatore Python per tutto, non abbiamo bisogno di un Python, di un React. Quindi non solamente l'Open Data Editor è un software per una persona che non è tecnica, ma anche stiamo pensando come fare il development dell'applicazione. È una tecnologia che sappiamo che in 20 anni sarà lì, perché Qt è nel '90 e nel 2050 sarà lì. È la boring technology, ma è la tecnologia sostenibile. Quindi, questo è un po' il "tech we want", no? Come possiamo scegliere le tecnologie ad una forma un po' più sostenibile? - Sì, anche perché c'è un discorso, poi, secondo me, legato anche a quello che dice Patrizio di quando sei una piccola realtà, per esempio, che sviluppa un software o qualcosa, c'è una fase iniziale di ideazione della cosa e e quindi parti con la cosa nuova ed è subito attrattiva per tutti, però c'è poi una fase in cui quella roba che hai costruito la devi mantenere e la fase di manutenzione non è attrattiva per nessuno, nessuno ci vuole mettere i soldi, nessuno ci vuole mettere delle risorse, quindi come fare anche per pensare, diciamo, dei software che possano essere più facili anche da mantenere e, come Patrizio diceva, basta un programmatore per tenerlo in piedi, per esempio. Questa è un po' l'idea, ecco. Sì, capisco a pieno e questo ragionamento mi colpisce perché in realtà tutti noi siamo affascinati dall'ultima tecnologia e riscriviamo lo stesso software 16 volte ogni volta che esce un framework nuovo. certo non sono un grande amante di Qt ma insomma questo lo trovo un po' un po' convoluto però questa è opinione personale mi chiedo essendo Open Data Editor un tool open source da quello che posso vedere quanto in realtà la scelta di utilizzare una tecnologia stabile perché non posso dire altrimenti ma che non è il gioco scintillante l'ultimo gioco scintillante che attira abbia penalizzato in termini di contribuzioni. Sì, quella può essere una disadvantage del software. Quindi sì, può essere che perché abbiamo scelto una tecnologia che non è tanto conosciuta e abbiamo meno contribuzione, ma anche tante volte più contribuzione è piggiore. Io Sikan, Sikan è un altro, uno dei nostri altri software, noi abbiamo nel ripositorio di Sikan 150 pull request open che non abbiamo tempo di revisare quindi quando tu mi dici "poi forse meno contribuzione" grazie Dio capisco capisco capisco quello che dici sì perché poi quando quando i repository crescono ci sono... ci sono i governants e la governants costa - sì sì e guarda credo firmemente che hai ragione quando dice che queste tecnologie che non sono le ultime hanno meno traction non hanno tante persone che voleva. Ma quando io l'ho iniziato a provare, perché dico "bene, devo migrare o voglio migrare questa applicazione, a cosa la migro?" Io ho provato questi framework e è stato tanto semplice che l'ho imparato in tre settimane, un mese. In un mese ho imparato come utilizzare il framework e ho iniziato a migrare l'applicazione. E dopo è entrato un altro developer alla nostra organizzazione per aiutare con queste... E mi ha detto "guarda, questo è semplicissimo di capire come l'architettura, come il framework, in due o tre settimane sono produttivo". E per noi quello è un'avventaggio, è una cosa che cercamo, perché noi siamo una piccola organizzazione. Se noi vogliamo contrattare un React developer, come facciamo con il market di software developer di React? Perché noi dobbiamo, in soldi, pagare lo stesso che gli paga Facebook, che gli paga Netflix, che gli paga... il talento del React è caro e se io ho un programmadore React nella mia organizzazione, per lo unico che lo puoi usare è per quell'applicazione, perché le mie altre applicazioni sono Django, sono Flux, sono HTML, CSS. Quindi è anche una decisione di organizzazione, no? Perché con questi framework, tu sei Python, sì, perfetto. Tu puoi lavorare in tutti i nostri progetti, perché non sei... quindi sei meno contributore ma il software engineer della mia organizzazione può lavorare in tutti i progetti, pro e contra, pro e cons, che uno sceglie a definire una tecnologia. sì sì ma sono d'accordo con te io credo che questa consapevolezza si sia insomma quando si inizia a maturare anche professionalmente nel senso che io l'ho vista in me stesso negli ultimi 5-6 anni quando sì ok 1070 mila framework nuovi, librerie nuove sì l'acqua passa sotto i ponti io neanche ci guardo più perché chi me le paga ste energie no? Ho bisogno di... il mio compito in qualità di nel tuo caso di tech lead di un'organizzazione nel mio caso di tech lead che lavora per una corporation è generare valore. Se la tecnologia mi permette di generare valore posso scriverla in Cobol. Io oggi mi interfaccio con sistemi che girano da più di 40 anni in Cobol ok e funzionano ancora e quindi bom se io non ho l'esigenza di cambiarli perché li cambio per il gusto di riscriverli quindi da questo punto di vista ha assolutamente senso o se posso fare qualcosa con... e il famoso discorso no? se posso risolvere il problema con low code o con no code perché devo scrivere il codice se posso farlo con quattro clic l'ho fatto più velocemente mi risolve il problema e non ho requirements che mi dicono devi scalare il software deve essere in questo modo quindi questo pragmatismo lo comprendo e lo sposo, lo sposo oggi. Abbiamo parlato di governance legata all'open source, possiamo shiftare questo topic sul concetto di governance dell'open data invece? Quali sono le challenge? La, there, la, la. Beh, diciamo nel senso le challenge sono sicuramente tantissime e ci hanno a che fare di nuovo con un'alfabetizzazione dei dati e col fatto che gli rendenso c'è, che effettivamente è importante che le persone che producono i dati siano in grado di capire anche l'importanza. Sì, penso che ci sono... sì, appunto, è un hot topic al momento, sicuramente, quello della governance dei dati. Abbiamo due... io credo che il... abbiamo un challenge nella governanza di dati aperti oggi che è la definizione di aperti cosa significa un dato aperti? - definisce un'Europea o un'Americana perché esistono due scuole di pensiero dell'apertura no? - sì e che cosa dobbiamo... guarda, a vedere... il problema è che quando il movimento dei dati aperti ha iniziato la definizione di aperti hanno detto per qualsiasi uso dei dati aperti e ora abbiamo un sistema di machine learning che utilizzano per automaticamente scegliere che persona mi arma, ammazzano e guerra. Siamo, o abbiamo questi sistema di intelligenza artificiale per decidere, per scegliere che persone ricevono aiuto dall'Estato. Abbiamo questi sistemi automatizzazione che hanno usato dati aperti, per fine che non sono tan etico. Ma buono, ma era un dato aperto, il dato aperto, la licenza, la licenza e il dato aperto era per qualsiasi uso, quindi non possiamo dire niente. Ma ora sapendo cosa si può fare con la tecnologia oggi, dobbiamo o non dobbiamo mantenere la definizione di open per qualsiasi uso o dobbiamo restringere? No, buono io voglio... è dato aperto ma non puoi usarlo per fine militare per esempio. Si io pongo quella restrizione per la definizione di oggi non è un dato aperto perché sono limitando l'uso ma vogliamo in un futuro che i dati aperti si usano però militare? Per uso militare? Sì? No? Non so. Quello è un problema grande della governanza di dati che abbiamo. Il secondo, buono, come si usano quelli dati? È un problema un po' più grande che i dati aperti, che la governanza di l'open in generale. Open AI. Cosa è l'open AI? la definizione di un sistema di intelligenza artificiale aperto, cosa significa aperto? L'Open Source Institute ha definito che l'intelligenza artificiale aperta non ha bisogno di avere dati aperti, perché la comunità ha grittato all'aereo "com'è possibile che hai fatto questa definizione?" perché noi avevamo bisogno dei dati per capire come funziona questo sistema di intelligenza artificiale. L'OpenAI. La compagnia si chiama OpenAI, ma di Open? Niente. E secondo, dobbiamo combattere questa ipocresia di che tutto il movimento avverto ha avuto tanta pelea e tanta fight per l'accesso all'informazione, per destruire la barrera del copyright, per l'accesso al conoscimento e abbiamo avuto tanta resistenza legale, gubernamentale, ma ora OpenAI le sta chiedendo al governo degli Stati Uniti che le permita usare tutto il copyright per il training del suo modello perché se no perde la battaglia tecnologica con la Cina. Cos'è che era? Aaron Swartz e ora se lo diamo all'OpenAI. Quindi è una battaglia culturale, quello è il problema della governanza, il desafio, il challenge dell'Open Data Hall, questa battaglia culturale di cui il conoscimento deve essere aperto, ma deve essere aperto per tutti e che non possiamo dirlo sì per l'OpenAI, per no per il ricercatorio, per il scientifico dell'università che deve pagare per la pubblicazione, per l'accesso alle pubblicazioni. Io credo che quelli è il problema grande della governanza oggi per i lati aperti e per il aperto in generale. - Io diciamo che forse c'è anche un problema legato a, cioè, per esempio, che come puoi effettivamente condannare qualcuno che usa una parola come "open" in un contesto che non è open, per esempio, perché al momento, insomma, mi sembra che appunto open AI continui, forse prospera un po' meno da quando c'è DeepSeek, però, insomma, continua ad andare avanti senza problemi e non è che nessuno gli dice di cambiare nome. Quindi c'è anche una cosa legata a come, una volta che c'è, e c'è una definizione, per esempio, di open, come facciamo a fare in modo che questa venga rispettata effettivamente anche? E al momento, insomma non c'è effettivamente un modo e diventa effettivamente ancora più complesso se poi vuoi inserire dei principi come quello "do not harm" per esempio o per esempio "do not use for military purposes" o queste cose del genere. Credo che si ci sia tanto margine proprio di discussione in questo e talvolta siamo davanti a delle situazioni dove sembriamo quasi davanti a paradossi nel senso che se diciamo no a OpenAI vuol dire che l'open generale come ha definito prima Patricio sta venendo meno e noi vorremmo tutelarlo però nel contempo nel contempo noi vorremmo dire no all'uso militare dei dati per esempio e anche in quel caso il concetto di open wide così come lo consideriamo viene meno e quindi dal nostro punto di attivisti, dal nostro punto di persone con una certa visione politica vogliamo dire che forse l'open in senso più ampio non è quello che ci serve ma suona brutto e suona molto brutto detto così perché l'open in gergo più ampio è quella bandiera che abbiamo sventolato per gli ultimi 20 anni, tutte le nostre battaglie andando in trincea e oggi dopo vent'anni diciamo sì vabbè ma forse insomma la democrazia è bella però anche la dittatura potrebbe funzionare... cioè, non so come dirlo. Lo sto portando per paradossi, giusto? Per far vedere la dissonanza che questa cosa genera, no? Ed è una cosa che in realtà dovremmo fermarci a ragionare e probabilmente ad oggi una risposta non l'abbiamo, perché dobbiamo ancora maturare, dobbiamo anche prendere dei calci nel culo dai sistemi di intelligenza artificiale, perché ancora calci nel culo forti forti magari li stiamo iniziando a prendere ma non ne abbiamo ancora consapevolezza e quelli devono devono venire e sono i calci nel sedere che iniziere... stiamo già iniziando a prendere invece per quello che riguarda il cloud, quello che diceva Patrizio prima, perché ci troviamo in una situazione geopolitica dove iniziamo a essere penalizzati dall'uso del cloud. Quando Elon Musk dice "ti spengo Starlink se tu non fai quello che dico io" e nel contempo abbiamo un primo ministro italiano che vuole dare a Starlink la creazione della rete delle comunicazioni strategiche, io credo che non lavorerò mai più per la pubblica amministrazione. Però è interessante quello che dice, penso che effettivamente è quando si inizia a essere un po' scomodi che le cose iniziano a muoversi e so che anche te sei stato a Fosderm quest'anno e non ho mai sentito tanto parlare di Euro. No, quest'anno non sono riuscito ad andarci, però i due, tre anni precenti sì. Però quest'anno, cioè io ho sentito parlare continuamente di Euro Stack, che era una cosa che mai avevo, cioè un po' si sentiva però insomma nel senso forte come questa volta per esempio non si era mai sentita in effetti ed è una cosa che di cui non si parla soltanto più in ambito appunto di persone con un profilo più tecnico ma sono anche i politici che parlano di questa cosa quindi diciamo che quando inizia a prendere calci nel culo e a stare scomodo sulla sedia è il momento in cui comunque anche tutte le persone intorno iniziano a muoversi iniziano a capire che c'è qualcosa che non va quindi a volte forse le crisi sono utili in questo senso perché fanno sì la cosa che mi preoccupa è i mostri vestiti di nuovo non nel senso quello che per esempio sta succedendo in italia dove i grandi player in realtà sono appaltatori e sotto il cofano ritorna amazon ritorna google e ritorna microsoft che da persona che usa google microsoft e amazon riconosco la facilità d'uso la possibilità di veramente tirare su delle infrastrutture mega complesse con dei costi ridotti e con degli effort minimali però nel contempo riconosco che a) i dati si trovano, anche se si trovano in Italia sono sottoposti a pressioni politiche che noi non possiamo controllare b) ci hanno la valigetta, adesso c'è la valigetta alla bomba nucleare e la valigetta del cloud, secondo me fa più danno la valigetta del cloud della valigetta alla bomba nucleare tra un po' cioè questa è la situazione e ci il vero problema è che in realtà quando tu crei un'infrastruttura che è pubblica privata tutta su un single point of failure anche se sono tre corporations sono un single point of failure hai un problema. Se lo fa la Cina è editatura e se lo fa gli Stati Uniti? E tutta quella knowledge tecnica sviluppata. Raga io ho preso una certificazione Microsoft dove ho studiato i prodotti Microsoft. Non ho studiato che cos'è una rete, che cos'è una... cioè il mercato oggi chiede questo tipo di robe e quello è un altro concetto noi abbiamo parlato di knowledge ma quello che sta succedendo in ambito tecnico è che buona parte della knowledge tecnologica sta per diventare una non transferable knowledge e anche questo apre un altro capitolo dove potremmo rimanere mesi a discuterne no? Cioè io mi sono... sono un ops, mi sono specializzato in AWS, conosco tutto lo stack AWS, faccio funzionare una corporation da decine, centinaia di milioni di euro su AWS. Cosa succede se in un contesto geopolitico AWS dice al primo ministro italiano sì ma se non contribuisci all'attacco militare a questo paese x io ti spengo le risorse tecnologiche, ma siamo fuori? Sì, a me, e non è un caso ipotetico, sta succedendo Ora, ho leggeto una notizia che il Parlamento dell'Olanda ha chieduto al governo dell'Olanda di fare una cloud pubblica olandesa per disminuire la relazione e la dipendenza con il cloud americano e uno dei punti era che per le sanctions di Trump alla ICC, alla International Criminal Court della Hague, loro possono perdere l'accesso a Microsoft, all'e-mail, al drive, a tutto, perché la ICC lavora con Outlook e lavora con Microsoft, ma Trump le ha posto una sanzione e questa sanzione può provocare questa questione che la ICC non può usare più Microsoft e se non può usare più Microsoft deve chiudere perché è tutto il suo email e tutti i suoi documenti lì. Quindi sono situazioni che sono reali, che sono succedendo. Lo quale per me, che ho studiato Ingegneria e Sistema, studiato l'inizio della dell'internet. L'internet è nasciuto come una rete che dovrebbe sopportare una bomba e non importa perché se hai una bomba tutti gli astronomi sono redondanti e possiamo colpire. L'inizio dell'internet è un progetto militare per fare una comunicazione che se una bomba mi distrugge un centro di comunicazione io posso seguire comunicando tutti i miei... Ma oggi il Busy West Virginia ha un problema lì, mezzo Internet, lascia di funzionare, perché abbiamo una dipendenza enorme a tre o quattro data centers mondiali, quindi questa immaginazione, hanno questa cosa che tagliano le cable di comunicazione sul mare e perdiamo tutto. Quindi è una tragedia lo che è successo con l'internet, ma io credo che il gran problema è che ha avuto un divorzio enorme tra la comunità tecnologica e la comunità politica. E mi piace tantissimo spazio come Gitbar, perché non è comune di avere spazio dove uno può parlare di politica tecnologia. La tecnologia e la cultura tecnologica in gli ultimi 20 anni è una burbuja. I programmatori, a me piace programmare, guadagno bene, non mi disturbo, ma no, dobbiamo iniziare un movimento interdisciplinario, quando parlavamo di challenge anche, dobbiamo un movimento interdisciplinario, dobbiamo avere persone tecniche con il conoscimento tecnologico, parlando con il conoscimento di geopolitica, parlando con il conoscimento del climate change, perché tutti per il nostro lato non funziona. Io credo che un po' il problema, per ritornare all'inizio la nostra conversazione, un problema della situazione attuale dell'open data è che dopo venti anni il niche e la comunità dell'open data è una bubble. Non parla, non ha attaccato, non ha combattuto i problemi reali del mondo, si hanno perduto nell'analisi del lato sonso, lato stronzo, del lato che non è importante, che non è vero, quindi dobbiamo di avere un posto per parlare di questa cosa, credo che questo episodio, credo che questo podcast è uno di questi spazi. Vi faccio una domanda, abbiamo parlato del rapporto conflittuale di amore e odio tra i i sistemi di LLM, le società che tirano su questi sistemi spesso in perdita perché sono armi geopolitiche come ben sappiamo e il dato. Può questa situazione essere un'ulteriore miccia per riaccendere una discussione profonda sul dato, sull'open data, sulla natura del dato e sull'impatto del dato e l'importanza del dato in qualità di asset delle comunità. C'è sicuramente un, diciamo, un ritorno in auge un po' del discorso dell'open data che è legato tantissimo ai sistemi LLM e dell'intelligenza artificiale semplicemente perché ovviamente siccome vengono esercitati su dei dataset avrebbe una certa importanza che quei dataset siano di una certa qualità e rispettino certi standard, chiaramente, perché hai un risultato migliore poi dopo all'interno, all'interno del sistema. E quindi sicuramente c'è in qualche modo, quello potrebbe essere un nostro cavallo di battaglia tenendo comunque in considerazione che ci sono tutta una serie di considerazioni politiche ovviamente che vanno insieme all'uso di un large language model o di un'intelligenza artificiale e che non sempre si sposano con l'etica che va insieme con il movimento, diciamo, dei dati aperti. Quindi c'è sicuramente anche quella considerazione lì da fare. Nel senso vogliamo ovviamente che migliore la qualità dei dati e che i dati siano aperti e che rispettino dei principi e degli standard, ma non è che lo vogliamo perché chat gpd diventi migliore o perché deepseek sia meglio, insomma, lo vogliamo perché è semplicemente importante averceli e sarebbe importante forse che crescano anche delle alternative e diciamo magari più locali per esempio a questi giganti qui che escano fuori da una dinamica anche appunto di lotta geopolitica e che inizino veramente a essere a interessarsi a un'utilità civica o comunque insomma per per i cittadini. C'era un discorso abbastanza interessante che facevano su questo mi sa sempre a Fosdam sul fatto che ripollegandomi a quello che ti dicevi prima il 90% delle infrastrutture che utilizziamo attualmente in Europa è completamente infrastruttura americana e quindi c'è forse anche, diciamo, questo discorso andrebbe legato anche a un discorso di sovranità dei dati, ma anche della tecnologia un po' di più. E con delle cose più locali, per ritornare al nostro discorso dei comuni, di nuovo, insomma, forse trovare delle soluzioni più locali potrebbe essere sicuramente la chiave. Sono d'accordo con voi. C'è un ultimo punto in realtà che mi era appuntato e che non abbiamo ancora trattato. Guardavo l'orario, siamo a un'ora e mezza e tipo è volata. Io poi son partito che, ero completamente drained dalla giornata però mi sono... mi è di nuovo rigonfiata la vena qua, no? quando parlo delle cose delle cose che amo. No, abbiamo abbiamo introdotto il concetto di... il progetto di frictionless data dove tu Sara sei, se non ricordo male, community manager. Di cosa si tratta? Allora, l'idea è molto semplice in realtà. Frictionless data nasce una decina d'anni fa con l'idea di avere uno standard per containerizzare i dati. Di nuovo, mi sto propriamente inventando questa parola in italiano, ma facciamo finta che esista. L'idea è quella di creare un data package che è come un pacchetto, una scatola, in cui infili il tuo dataset, i tuoi metadata e anche una descrizione praticamente di quello che c'è dentro questo data package. Quindi quello che succede è che quando poi i dati vengono condivisi come data package, questo significa che una persona può direttamente prenderli e riutilizzarli direttamente senza dover andare a chiedere al primo che gli ha pubblicato i dati "Cos'è sta roba?", "Cosa c'è in questa colonna?", "Non capisco sta cosa", "Cos'è?", "A che ora l'hai raccolto?", e roba di questo genere. Che l'autore c'è una licenza su questi dati perché è tutto contenuto dentro questo data package. Quindi l'idea è questo, data package, per dopo insomma all'interno c'è una serie di specificazioni e poi dopo su appunto come si costruisce lo schema, per esempio, eccetera. E poi a partire da questo standard, diciamo, quello di cui ci siamo resi conto, cioè ci siamo, in realtà era ben prima che io arrivassi a Open Knowledge, quello di cui le persone all'epoca si sono rese conto, che effettivamente è il motivo per cui ha anche avuto un certo successo il progetto, è che lo standard da solo a volte non basta per l'adozione, ma che quello che ti serve sopra sono anche delle librerie software che puoi utilizzare per utilizzare lo standard e fare un certo numero di cose. Quindi nel caso di Frictionless abbiamo delle librerie, mi sembra, in nove lingue di programmazione, però diciamo quelle sicuramente migliore, più up to date, e che ancora funzionano bene, e che hanno effettivamente delle persone che le mantengono, sono Python, R e JavaScript abbastanza, diciamo. E queste librerie sono, insomma, nel senso, che ti permettono di fare una serie di cose, tra cui validare i tuoi dati, trasformarli, estrarre per esempio i metadata e cose di questo genere, e quindi automatizzare tutta una serie di cose che faresti praticamente. E tra l'altro Open Data Editor, di cui parlavamo prima, utilizza una delle librerie di Frictionless per validare i dataset. Sì, dal punto di vista tecnologico mi piace dire che Frictionless è come il primo, l'ultimo chilometri di tutti gli analisi dei dati. Tutti persone che hanno lavorato con dati sapono che ho un API, ho un CSV. Cosa faccio? Pandas, Red CSV. La prima columna è un intento. La seconda è un string con queste quattro categorie. La quinta columna è un float. Questi valori sono nuli. Quindi, in tutto il nostro script di analisi di dati, le prime 50 linee di codigo e dirle al programma come leggere questi dati. Frictionless è quello. Invece di queste 50 linee di codigo, hai un frictionless.read e come frictionless ti dà il dato e la metadata, il data frame è pulito e è bello per l'analisi perché come il dato viaggia con la metadata che ti dice questa columna è un intero, questa columna è un date time, questa columna è un string, quando tu dici frictionless.read data package automaticamente il tuo data frame è pronto per l'analisi di dato. E in l'ultimo chilometro, quando tu hai finito l'analisi e voglio scriverlo a un nuovo CSV, cosa dice? Il CSV è la metadata anche, quindi il prossimo ricercatore o la prossima persona, il prossimo data analyst puoi leggere esattamente. Quindi la meraviglia del standard e del dato e la metà data che è il pacco, il data package che Sara ha menzionato. Ho una domanda Patrizia, adesso parliamo di giocattoli per un attimo. Hai parlato di data frame, sotto il cofano abbiamo pandas, però abbiamo citato, hai citato anche anche anche javascript Sara, come come fai funzionare la parte di javascript? questa è un'ottima domanda forse padrissimo lo sa? io lo ho usato in python e in R In JavaScript lo che abbiamo è il package per scrivere la metadata e per leggere la metadata non tanto per generare un data frame per l'analisi di dato come in R o in Python ma più il toolkit per generare la metadata, validare il dato, ma non per l'analisi di dato Se non tutte le librerie hanno lo stesso numero di funzioni, hanno lo stesso livello di sviluppo No perché mia moglie è una data engineer e quindi ahimè mi tocca insomma affrontare questi discorsi a cento spesso no? E proprio insomma qualche mese fa parlavamo di Polars che è diciamo la contropartita di pandas, tra l'altro io so che tantissimi contributori di pandas oggi sono anche contributi di Polars, che in realtà espone di binding anche per JavaScript e quindi mi chiedevo "avete usato pandas, avete usato Polars?" Insomma, era... sono uno sviluppatore anch'io, ho questi problemi, lo sapete. Ma poi un'altra cosa che va detto è che tutte le librerie in effetti sono mantenute da delle entità diverse, quindi noi manteniamo la libreria in Python, a Open Knowledge siamo più che altro Pythonisti direi e per esempio JavaScript è gestita da un'altra organizzazione, R la stessa cosa, quindi diciamo sulle altre librerie siamo anche un po' meno informati, sappiamo diciamo grosso modo quello che succede e però sono poi dopo anche abbastanza autonome. Esiste una coordinazione tra queste organizzazioni? Sarei io in teoria coordinazione. E infatti volevo volevo arrivare là. Come è questo lavoro di coordinazione? Quali sono le challenge? E diciamo come fare interfacciare organizzazioni diverse per uno stesso obiettivo ma con ritmi, passi, budget e approcci potenzialmente diversi. Sì, non è una cosa semplice affatto, anche perché appunto quello che c'è, dopo molto spesso, è che delle persone prendono diciamo su di sé la creazione o il mantenimento di una certa libreria o di una certa parte del progetto, però non è che li puoi obbligare chiaramente a rimanere lì a fare delle cose, se ad un certo punto per esempio si vogliono ritirare o tirare indietro, o si interessa in un'altra cosa, Quindi la difficoltà è anche, diciamo, cercare di coordinare e fare in modo che, insomma, nel senso, almeno il core core del progetto continui ad andare avanti in qualche modo. E diciamo, nel progetto Frictionless siamo abbastanza fortunati, direi, nel senso che sia l'organizzazione, siamo un'organizzazione francese al momento che mantiene, per esempio, il pacchetto Python, sia quella belga che gestisce R, per esempio, sono estremamente attivi e dialogano moltissimo. Abbiamo delle community call una volta al mese, ma poi dopo c'è tra di loro comunque parlano tantissimo. E la comunità comunque, che è una piccola comunità alla fine, nel senso di contributori veramente, diciamo, attivi, si attivano molto comunque tra di loro. La cosa che forse ha riattivato anche un po' più la comunità è che ultimamente l'anno scorso abbiamo fatto un grosso update dello standard data package, passandolo alla versione 2, e quindi quello ha sicuramente attirato tantissima gente dentro il progetto di nuovo, erano interessati, si parlava di nuovo di Frictionless Data, quindi quello è sicuramente stato un'altra cosa. Il challenge anche a volte, essendo un prodotto open source, non abbiamo idea di chi lo utilizza, quindi per esempio a volte sarebbe bello portare, sai, nel senso degli esempi, di dire "guarda, questo progetto è super utile, sappiamo che viene utilizzato in tutte queste cose" e diciamo io a cadenza mensile scopro qualcosa di nuovo che usa Data Package o Frictionless, dico "ah, vedi, se l'avessi saputo cinque mesi fa, quando parlavo con quell'altra persona sarebbe stato utile. Però quella è una cosa con cui bisogna fare i conti ed è anche una cosa bella, poi, tutto sommato, essere sorpresi anche dopo di com'è, appunto. Ho scoperto che anche era nelle linee guida di Agile, per esempio, a un certo punto, e l'Agenzia Italiana per il Digitale e questa cosa mi aveva... e me l'ha comunicato qualcuno dentro la comunità, per esempio. Quindi, ecco, queste sono sicuramente un po' un challenge, ma è anche una cosa bella. E poi mantenere le persone motivate. e insomma nel senso a continuare a contribuire al progetto sicuramente non è una cosa semplice. Anche allineare l'interesse della comunità è un gran challenge, che alcune volte arrivano allo stesso cammino. Per esempio, ora abbiamo due challenge technical, challenges, che vogliamo attaccare. Il primo è perché... Frictionless è un standard, è il standard CSV, ma dopo, sopra quel standard, sono nate tantissime librerie. Ma le librerie non hanno un'API unificata. Una libreria ha chiamato "frictionless.rail" e l'altra ha chiamato "frictionless_leggere" leggere l'arcivo. Il nome e il metodo sono diversi in tutte le librerie. Abbiamo detto "Ma se io ho un pitonista lavorando in Friction e dopo voglio fare un analisi in R, voglio avere un'app similare, quindi il viaggio tra un DeWaag e un Prometheus". Quindi ora stiamo parlando di trattare di arrivare a un'app in comune che tutti i pacchetti e tutte le implementazioni di Friction hanno una sintaxis o un API similare. Quello è un desafio. Il secondo desafio è possiamo fare un core unificato, per esempio in Rust o in C, per risolvere il problema di la validazione dei che dopo tutte le altre librerie possono usare internamente. Quindi tra tutti facciamo una sola libreria core in sé che solve il problema della validazione dei dati e dopo tutti, R, Python, puoi chiamare questa libreria e unifichiamo i lavori. Questa coordinazione è un lavoro enorme che Sara lo fa benissimo, ma è un challenge, è un challenge perché, prima, chi pone il soldi? Tra tutti stiamo provando di applicare a un grant per il dinero, ma dopo chi recive il il dinero, chi lo distribuisce, chi lo... il management di tutti i processi collaborativi è anche un gran lavoro, è un gran lavoro. Quindi quello è un challenge, la collaborazione è sempre un challenge, sempre un challenge. - Penso che ci sono anche delle cose anche legate a un discorso anche di governance del progetto e di come spesso ci sono tantissime cose che sono implicite in un certo senso e quindi lo sforzo è anche nel rendere tutto estremamente esplicito e soprattutto un senso aperto, che lo rende poi dopo un progetto aperto a nuove collaborazioni anche. E quindi, diciamo, a volte la difficoltà è anche di fare un passo indietro e dire "abbiamo sempre deciso le cose così, però forse le dobbiamo mettere per iscritto e dobbiamo dire effettivamente com'è che decidiamo le cose e se decidiamo che le cose vengono decise con un consenso, cos'è che vuol dire consenso per la nostra comunità". Quindi sono a volte delle, diciamo, riflessioni abbastanza elementari, in un certo senso, che però sono necessarie che bisogna appunto esplicitamente mettere da qualche parte. Sì, io sto provando a proiettarmi nella complessità, in realtà dopo aver frequentato alcune community open source dove il successo era guidato dall'attitudine, dell'approccio del dittatore benevolo che dice bene tutto però alla fine la decisione la prendo io il progetto open source è il mio e si tira così dall'altro canto ci sono progetti come questo dove invece la governance è condivisa e il movimento è condiviso e l'effort è immagino immane e comparato no? specie se da una parte c'hai problemi di organizzazione budgeting dall'altro hai problemi di magari entità con con delle posizioni super opinionate su un certo stack su una certa tecnologia quindi da una parte vedo le challenge di Sara dall'altra vedo le challenge di Patrizio che deve impazzire perché magari si vuole riscrivere, che ne so, una parte in Rust, ma poi chi la mantiene, quanto costa mantenerla, quanto costa uno sviluppatore Rust per una fondazione che comunque deve fare i conti col budgeting, nel contempo come si preserva la qualità del codice quando ci trovi quello che magari vuole buttarci del funzionale, che aggiunge complessità e carico cognitivo, e invece il carico cognitivo deve essere il più basso possibile perché l'accesso deve essere il più facile possibile al codice, quello che dicevamo prima, no? E quindi le challenge sono enormi. Sì, e non abbiamo una risposta, davvero. Io participo in diversa comunità di open source, sì che anche un altro progetto che non abbiamo parlato, ma va bene, è un altro progetto che anche a una comunità e in alcuni progetti voglio tantissimo... io voglio un benevolente dictator in questo progetto perché semplificaria tutto tantissimo, tutto tantissimo, ma in altri progetti ho un benevolente dictator e dico no, no, no, non voglio un benevolente dictator, voglio un consenso. Quindi io non credo che c'è una soluzione per una silver bullet per tutte le governance. Io credo che ogni progetto, ogni comunità è diversa e in alcuni casi un benevolente detector funziona bene, in altri casi no. Ma noi che siamo nel business della governance e dell'open source e che abbiamo un progetto con Siccan che ha 15 anni, con software, noi pensiamo tantissimo in chi mantiene questi software in dieci anni, noi pensiamo in termini di infrastruttura, in termini di... in 20 anni io sempre penso alla mia mamma perché la mia mamma quando vede una casa grande, io "mamma non ti piace questa casa?" "sì, ma chi la pule?" "chi la pule?" "bueno, con il software è una cosa così per noi" e come che "ti piace questo software?" "sì, "Sì, ma chi lo mantiene tra 5 anni, tra 20 anni? Chi lo mantiene queste cose?" E se vogliamo davvero un'infrastruttura pubblica, un'infrastruttura sostenibile, vogliamo pensare al software che tra 10 anni sono funzionando, ma chi mantiene? Quindi la governance, e perché dico questo? Perché la governance, il benevolent dictator, A vece in volte tiene questo problema di che avanza rapido rapido rapido rapido rapido perché va solo quindi va rapido. La governance in community si viaggia lento ma si arriva lontano. Quindi, cosa volete? Volete un software per 20 anni? una governance di community perché sarà lenta, burocratica, ma forse il risultato sarà un software stabile, un software maturo, perché ha tantissimi interessi in questi software che deve negoziare, che deve essere il punto in comune di tutti gli interessi. Quindi credo che si debba di fare una raccomandazione, buono se volete qualcosa rapida benevolent dictator va bene, se volete una cosa lontana una comunitaria, ma ora penso in Linux, che Linux ha il suo benevolente dictator e buono Linux è Linux, chi dice che... - Sì, sulla parte benevolente magari possiamo discutere... io lo definirei un po' più rude dictator ma in realtà sì è vero, è così certo da quel punto di vista però vedi che comunque la community è stata in grado di applicare una pressione fortissima Linus Torvald, tanto che un paio d'anni fa lui si fece da parte, poi però la community non era abbastanza matura e questo è il problema del benevolent dictator che guida troppo, la community non era abbastanza matura da continuare a tenere la guida. Ma un altro esempio che mi viene in mente sono progetti come Dino o come BAN e progetti come Node. Node è molto più lento però è molto più maturo. La codebase è probabilmente meno bella, si muove più lentamente però è molto più maturo di un BAN e di un DINO perché? Perché la comunità orizzontale lo forza ad utilizzare un certo approccio, per esempio ad utilizzare l'approccio conservativo. Prima di introdurre una breaking change in Node.js devi picchiare la testa sul muro 10.000 volte perché la breaking change non te la fanno passare e lo dico perché c'è tantissimi amici dentro come come Node collaborator e nello steer committee amici di gitbar intendo che queste cose le le evidenziano, quindi anche questo è una considerazione da fare. Io vorrei prima di chiudere, perché siamo quasi a due ore insomma, e la chiamata doveva essere di un'ora, ma va bene, guardare anche questo, quando chiacchieriamo di cose che ci interessano, non guardiamo gli orologi, Volevo però spendere due minuti perché non ne abbiamo parlato, però l'abbiamo citato un paio di volte e mi piacerebbe mettere una cornice, quindi definirlo, dare una forma a CKAN. CKAN. Sì. CKAN è il bianco per il portale dati avverti. È un framework che gli dà al developer tutti gli erramenti, tutto il tool per disegnare portali di dati aperti. È quello. È basicamente, è letteralmente un Django, ma per portali aperti. È un software che permette di disegnare catalogo di dati aperti. Quindi è un software che guarda... no, che guarda no, guarda in spagnolo... che è "safe", che almacena tutte le metà data del dato. Quindi tu puoi avere un portale con tutte le metà date di dove sono i dati guardati. E allora... Sì, la mia lingua sta... Quindi sì, Sika è un software che aiuta ai governi e ai developers a disegnare e implementare portali di dati aperti. È una comunità grande, è un progetto da 15 anni, ha iniziato nel 2007 e oggi si utilizzano mille dei portali dati aperti. portali dati aperti del governo degli Stati Uniti, dell'Europa, dell'Italia, Argentina. Abbiamo tantissime implementazioni, come Sara diceva, è un open source quindi non sappiamo chi lo utilizza, no? Ma abbiamo fatto un survey e abbiamo scoperto circa 1200 istanze di SICAN, di portare i dati aperti nel mondo; quindi sì, se hai... - Ah, domanda, tecnica ma politica - Sì, le nostre preferite - La butto qui, ma telemetria? Sì, no e perché no? Se mi dite che avete fatto una survey e no, quindi perché no? Prima perché nessuno l'ha implementato, secondo perché abbiamo avuto un... ha un issue nel nostro github per parlare di telemetria e di un call back home e con una piccola opt-in quando la persona installa il software dire se volete mandare un paio di dati per... ma anche a dove mandiamo questi questi dati? Alcuno della comunità deve di portare un... deve di prendere un servitore con una massa di dato per ricevere questi questi dati, qualcuno lo deve di mantenere e la comunità e cosa facciamo con questi dati, è importante, è un dato aperto, non è dato aperto, io credo che sì, perché non sono dati personali, ma sì, lo abbiamo a Unisium in Github, dove stiamo parlando di come implementare una telemetria un po' più etica. Sì, perché un po' di tempo fa, adesso per colpa del pochissimo tempo, mando un abbraccio a Flavio, che mi ha aiutato tantissimo in questo progetto, avevo lanciato il progetto FURVIE, che cos'era il progetto FURVIE? Avrete sentito parlare di podcasting e di open podcasting. La nostra idea era quella di creare un'applicazione desktop per creare e gestire i feed RSS per la creazione del podcast, perché tutti i podcast stavano postando e stavano passando per piattaforme e siamo fatti un po' prendere la mano quindi abbiamo messo trascrizioni usando Open Whisper automatiche nell'applicazione embeddata, l'applicazione era in Rust con un'interfaccia React. Insomma ci siamo chiesti chi lo usa? Come facciamo? Mettiamo una telemetria e là c'è stata un'altra sfida di natura etica ma dici ma cavolo ma a questo punto sto tracciando, sto chiedendo dei dati, cosa mi distingue da Google e là dici allora ok ma allora posso farla opt-in ma opt-in 90% mi perdo i dati allora posso farla opt-out con un model così grande che ti dice se non vuoi che ti tracciamo clicca qua ma è etico farlo opt-out e là era iniziato sto mega discorso che poi alla fine non avevamo messo telemetria e quindi mi chiedevo se l'esperienza era la stessa no o almeno simile nel senso che quando si parla di telemetria si sveglia, si risveglia una bestia che insomma... Parlando di Shikan però, Shikan, c'è un elemento che ha catturato la mia attenzione, la parte di federazione. - Sì. - Quali sono le challenge di federare tanti portali di open data, o almeno, quali challenge vedete da quel punto di vista? Due challenge, il primo è quasi risolto che è l'standard, per federare tutti dobbiamo compartire le informazioni nello stesso modo quindi abbiamo bisogno di un standard, l'standard esiste si chiama DCAT, è un standard per il data catalog dove se tu vuoi compartire queste informazioni con una federation del Data Catalog, apri una API con questi dati, con tutti questi standard, e va bene, si può federare. Quello è il primo challenge. È un po' risolto già, ha una comunità grande tra Dicat, ha un plugin per Dicat anche, La seconda è la discoverabilità dei dati. Tu puoi federare tutti i dati che vuoi, ma se hai un sito con 25 milioni di dataset, come trova quello che vuoi trovare in quel casino? Non so. e quella è la discoverabilità dei dati è un problema. Il secondo, il terzo problema, sto pensando un altro, ora è la veracità. Tu puoi federare, tu puoi dire "questo è il mio CSV, questo è il mio file", qualcuno lo puoi replicare, ma se tu lo replica come tu dimostra che il dato che tu stai replicando è lo stesso che io sto pubblicando. E' buono sì, un hash, puoi avere alcuna alternativa, ma se il mio portale disapparece, non è più, come sai che la tua copia è la vera? Che sta succedendo oggi negli Stati Uniti, ha successo anche in Argentina, che tanti portali di dati aperti stanno... non esistono più. e cosa facciamo con il dato? Sì, io puoi fare una copia, puoi federare, ma come dico che lo mio e che la mia copia è vera, il blockchain può essere una soluzione? Non so, non conosco tanto di blockchain, ma credo che può essere. Alcuni hanno detto che forse blockchain può risolvere questi problema nessuno ha... e un altro challenge è il linked data che è, buono, io ho questo dataset che parla di, non so, consumo di elettricità nel mio paese, buono, e la Svizzera o la Germania hanno un altro dataset che parla del consumo di elettricità, buono, come puoi fare la connessione tra dataset e nel mondo delle affaire relazioni come quello che è il famoso link data, quello è un problema quindi... - I modelli di dati possono essere differenti no? è quello che un po' è stato provato a risolvere schema.org per quanto riguarda la parte delle... - Sì e non solo è ciò, sino a dirle "buono, questi primary key è la stessa in tutti o puoi dirle "buono la primary key di questo dataset è il dataset che sta pubblicato per la pubblicazione nazionale" quindi la pubblicazione nazionale ha il dataset con tutti le comune e l'ID del mio dataset è il pubblicato in quello, quelli è anche un problema tecnico, un challenge. Quindi ritornando nuovamente all'inizio della conversazione, i challenge della situazione attuale dell'open data. Abbiamo pubblicato tantissime informazioni, ma dopo un gran challenge dell'open data, la riscoverabilità, l'uso, come usiamo queste informazioni? Perché abbiamo generato un data swamp, che se le chiama, nel mondo della big data. Abbiamo tantissimi dati, ma non sappiamo come mesclare, come aggiungere tutto. - Chiaro, chiaro. Ragazzi, io rimarrei altre 5 ore a chiacchierare con voi, però ahimè... - Si è fatta l'aperto. - Eh sì, io poi, la mia venerandetta a quest'ora inizia a disconnettere la centralina. Abbiamo due momentini, un momentino tra pochissimo, quindi prima di passare a questo momentino però, però in realtà c'è una cosa doverosissima da fare. Naturalmente io come sempre non sono pronto e in realtà mi devo muovere rapidamente per risolvere problemi tecnici e per lanciare una cosina. è il momento di ringraziare chi supporta github, chi si fa carico dei costi di server, di hosting, di tooling e di cose insomma che che che che dobbiamo tenere in piedi funzionanti per il nostro podcast. Come diceva Patrizio questi costi spesso non sono trascurabili e anche Gitbar nel suo piccolo c'ha i suoi costi che però in parte vengono supportati da alcuni di voi che ci fanno una donazione. Per noi non è una donazione vera e propria e essendo Gitbar un vero Gitbar è è una birra che ci offrite e quindi questa settimana abbiamo Fabio Marzotti che ci invita tre birre, giusto una per me, una per Sara e una per Patrizio e lo fa, sono birre virtuali nel nostro caso, e lo fa dicendo "grazie Mauro e tutti mi tenete compagnia è bello stare con persone con la stessa passione, soprattutto nei periodi no good aiuta". Fabio, i periodi no good, credimi ci sono sempre e tipo io sono nel bel mezzo di uno di quelli, ecco perché non siamo super regolari, quindi ti mandiamo un enorme abbraccio e solleviamo i calici brindando a te e alla tua felicità. È arrivato adesso il momento tipico e topico di Gitbar, mi sono appena reso conto che in tutto l'episodio non ho guardato una volta in camera e quindi è fantastico, perfetto. No è arrivato il momento tipico e topico di Gitbar, il momento in cui sia i nostri host che i nostri guest condividono un libro o un film o qualunque cosa abbia catturato la loro attenzione e pensano possa essere importante e interessante condividere con la nostra community. E quindi è arrivato il momento, il Paese dei Balocchi! Ecco tu con il Paese dei Balocchi! Ah, il Paese dei Balocchi! Volevo chiedere prima a Sara, Sara hai qualcosa da condividere con noi? Guarda, la prima cosa che mi viene in mente dopo tutta la discussione che abbiamo avuto sul costruire nuove cose scintillanti eccetera eccetera, una guida che ho molto amato che si chiama "Don't build it", la Guide for Practictioner in Civic Tech, che è stata scritta da Luke Jordan nel 2021, ed è in effetti una guida sul perché a volte bisogna fare un passo indietro prima di cominciare a costruire un nuovo software e dirsi "questa cosa è veramente utile, ce ne abbiamo veramente bisogno o potrei spendere le mie energie altrove ed è assolutamente quindi una lettura che consiglio che trovate online gratuitamente. E che consigliamo a tutti quelli che stanno per iscrivere un software che già esiste in Rust. Esatto. Esatto. Ehm, se io devo consigliare qualcosa, io voglio consigliare un'altra cosa che non è di Open Data, che non è di software, ma sto leggendo un libro che si chiama "Salt, Fat, Acid, Heat", è un libro di cucina perché random, perché mi piace, si chiama "Salt, Fat, Acid, Heat", è un libro di cucina che parla di questi quattro elementi importanti di tutta cucina, come salare la carne, come maneggiare l'olio o il grasso, cosa fa l'acido nel cibo, come il limone o l'aceto e come maneggiare il calore. Cosa succede nella cucina e nel cibo con questi elementi? E dopo anche un paio di ricette in questi libri. Mi è un libro che mi è piaciuto tantissimo, sto imparando un sacco di cucina con questi libri e credo che Netflix ha un... quattro episodi, uno per salt, uno per fat, uno per acid, uno per heat, consiglio a tutti che se vi piace cucinare o no, ma è questo un libro che a me mi ha servito tantissimo. adesso io non vorrei sbagliare ma questo libro è già stato un balocco di Gitbar quindi ti sembrerà strano ma è così e se non mi sbaglio lo portò il mio amico Mattia Tomasone tra l'altro uno dei co-host di Gitbar e lo portò dicendo che era un libro che aveva un approccio un approccio quasi metodologico e scientifico alla cucina che è una cosa che piace tanto a noi nerd, non so se tu confermi perché non l'ho mai letto ma facciamo un'analisi dettagliata quindi non è un libro di ricetta è proprio un libro che ragiona su questi componenti. Sì, e non è tanto scientifico con le formule e con il compound chimico, ma sì, ma parla sopra l'interazione chimica, sopra come funziona la cucina, come funziona il calore, il perché dell'acido, quindi sì, beh, il tuo amico ha la ragione. - Bello, bello, bello. Io sono un po' overwhelmed, ma credo che sarà uno di quei libri che utilizzerò quest'estate per decomprimere. Io un podcast, lo so sono noioso non ci posso far nulla. Prima quando Sara e Patrizio dicevano che uno dei problemi era la formazione di chi condivide i dati, mi ha riportato alla memoria un episodio di un podcast chiamato "The API Experience". Questo podcast ormai non è più, diciamo, attivo, ha smesso a luglio 2024, però era molto figo perché parlava di API, API enterprise, API fatte in scala, API che devono servire con testi complicati e uno degli host raccontava quando si è trovata a lavorare per la FAO forse o comunque una grande organizzazione che doveva raccogliere dei dati sparsi scattere un po' da da tutte le parti del mondo no? E uno dei problemi che lui ha trovato è che aveva creato questa piattaforma figa per applaudare i dati, modificarli online, editarli, fare un pacco di robe online e poi si è trovato in una situazione tale per cui alcuni dei provider di dati, quindi alcune delle realtà delle NGO, delle organizzazioni che devono mandare i dati magari erano davvero in quel paese sperduto dove la connessione funzionava un minuto ogni ore e mezza e il tool più più più più evoluto che potevano avere in quella macchina non era il browser era una roba tipo open office o un un excel della situazione e quindi lui con quel preconcetto, quello schema mentale dell'API o della web application si è trovato a sbattere la faccia contro il muro in un contesto che sembrava quasi assurdo, quasi paradossale adesso capite perché vi ho fatto quella domanda prima no? E di questo se ne parlava appunto in... credo fosse il primo il primo episodio o il primo o il secondo episodio di The API Experience che è un podcast molto molto bello che assolutamente vi vi vi vi consiglio Credo che siamo arrivati alla fine, spero vi siate trovati bene il nostro bar virtuale. Grazie per l'invito Mauro, è stata una conversazione estremamente piacevole, neanche me ne racconta perché noi un dice un quarto. Lo è stato tantissimo anche per me e immagino anche per gli ascoltatori, quindi non ho paura a dire per noi. Io prima di lasciarvi andare perché visto allora insomma sembra il caso, vi devo ricordare una cosa. Gate bar non so se avete presente, in Italia negli anni '70 esistevano i circoli del dopo lavoro, cioè il dopo lavoro ferroviario e il dopo lavoro postale, cioè erano dei piccoli bar, non propriamente dei bar perché erano bar dove non si pagava le tasse e potevano entrare solo che aveva una tessera, ok? E si passava là... tu eri magari un ferroviere, quindi passavi tutta la tua vita sui treni, al posto di tornare a casa finito il lavoro ti fermavi per un'altra ora e mezza con altri ferrovieri a parlare di ferrovie mentre bevi una birra, ecco questo era il circolo del doppolavoro. E cosa succedeva? Che quando andavi magari non eri un ferroviere, però questi circoli erano esentasse, non pagavano l'IVA, non pagavano tutta una serie di tasse perché erano delle piccole associazioni, ok? E tu andavi là perché volevi stare là e soprattutto perché la birra costava meno. E la prima volta che entravi ti facevano una tessera, come può essere questa qua insomma, e con questa tessera tu la dovevi avere perché se entrava la polizia tributaria, la guardia di finanza, se no ti metteva la multa e con questa tessera tu potevi bere spendendo pochissime parlando con persone che condividevano la tua passione. Ecco da oggi voi avete la tessera di Gitbar, cosa vuol dire? Che Gitbar è un po' casa vostra per cui tutte le volte che avete un progetto interessante, un qualcosa di challenging che vi fa piacere condividere con la nostra community, i miei contatti li avete, tirate un urlo, ci facciamo un'altra chiacchierata super super con estremo piacere. Fantastico. Mi piace il concetto del circolo dopo lavoro. Mi piace. Detto questo e ringraziando di nuovo Sara e Patrizio io vi do appuntamento speriamo alla prossima settimana un grande abbraccio alla prossima ciao ciao a tutti ciao a tutti ciao