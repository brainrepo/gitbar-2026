Bene e benvenuti su Geekbar, nuova settimana e nuovo episodio. Come sapete a Geekbar gli esperimenti un po' non mancano, ne abbiamo fatto diversi, abbiamo provato a raccontare in monorepo con i tre porcellini, oppure abbiamo provato a far fare a Calvino un po' di refactoring. però tutti gli esperimenti che abbiamo fatto erano un po' nella nostra zona di comfort quindi trattavano di qualcosa di tecnico, parlavano in "tecnichese" e parlavano di strumenti. In realtà oggi proviamo a fare un gioco. C'è un bellissimo libro che un amico che adesso non c'è più mi faccia vedere si chiama potenze di 10 ed è un libro dove c'è a metà libro la foto di un uomo sdraiato su un prato. Se tu sfogli il libro da sinistra verso destra quindi torni indietro vedi che piano piano pagina dopo pagina hai come uno zoom in nel corpo dell'uomo fino ad arrivare alle cellule e agli elettroni è un po' quello che abbiamo fatto fino a oggi nelle nostre puntate del podcast ma ma se lo sfogli dall'altra parte si vede che la camera si allontana sempre di più fino a posizionare l'uomo col globo terrestre sull'universo ho appena distrutto metà studio sull'universo ed è un po' quello che proviamo a fare oggi con il nostro super ospite che vi annuncio però dopo avervi ricordato i nostri contatti e aver salutato i miei compagni di viaggio Luca, Alessio e Carmine. Ciao ragazzi! Ciao a tutti! Ciao a tutti! Siete pronti ad uscire dalla zona di comfort? Yes! Aspetto questa puntata da tanto tempo, quindi assolutamente! Fantastico! Allora, ricordo rapidamente i nostri contatti info@gitpar.it @brainrepo su Twitter e cosa manca ragazzi? La gruppa Telegram Si accendono sul vostro client Telegram preferito che sia web o fisico cercando semplicemente Gitpar al momento in cui stiamo registrando siamo quasi 650 membri quindi vogliamo ringraziare tutti quanti voi per il rapporto insomma e se devo pensare che che quattro mesi fa stiamo festeggiando i 300 metri, i 300 membri, i 300 metri piani, i 300 metri piani con i 300 membri piani, l'abbiamo tutti messo così. Beh detto questo io direi che possiamo iniziare. Benvenuti su Gitbar, il podcast dedicato al mondo dei full stack developer, i mezzo artigiani, i mezzo artisti, che ogni giorno infilano le mani nel fango per creare nel modo più efficiente possibile coi prodotti digitali che quotidianamente usiamo L'ospite di oggi si chiama padre Paolo Benanni, è un traslittero, un teologo, un accademico del terzo ordine regolare di San Francesco giusto padre Paolo? Salve a tutti, correttissimo! Ed è anche docente alla pontificia università gregoriana. La cosa interessante di padre Paolo è che in realtà è un eticista quindi da diverso tempo a questa parte sta approfondendo l'impatto etico di quello che noi andiamo a fare tutti i giorni. Com'è questa battaglia padre? Direi antica come l'uomo, antica come l'uomo perché da quando nella caverna per la prima volta abbiamo visto una clava e abbiamo trovato uno strumento fantastico per aprire le noci di cocco e mangiare e spamarci in maniera più efficiente, però era stato anche uno strumento molto efficace per aprire la testa del nostro vicino. Ora la clava non la gestiamo più con la mano, ma quando scriviamo "if this then that" ecco che quel "this" facciamo la stessa operazione, questa è testa o questa è cocco, quindi stessa battaglia ma con strumenti diversi. Quindi uno degli elementi che vai a studiare tutti i giorni è la relazione tra uomo e strumento, a questo punto ti chiedo qual è il ruolo dello strumento e come gestire l'interdipendenza tra uomo e strumento? Qui al di là della parte più tecnica c'è tutta la storia dell'uomo che si interroga su che cosa è lo strumento per noi, per cui qualcuno ha risposto che lo strumento è semplicemente una pezza che noi mettiamo su qualcosa che ci manca. Ci piacerebbe volare come i falchi ma siccome non voliamo come i falchi allora facciamo l'aeroplano. Ci piacerebbe correre come il ghepardo, ma siccome non corriamo come il ghepardo, allora facciamo una bella automobile. E quindi ci vediamo come qualcosa di venuto fuori male. Qualche collega inglese dice, parlando dell'uomo, che siamo una "half-baked reality", una realtà mezza cotta. Ecco, tradisco la mia origine francescana perché sentite le campane in sottofondo, quindi capite che parlo da casa, come si dice. Bene, questa questione qui è quindi vedere la tecnologia come qualcosa che noi facciamo perché ci manca, siamo venuti fuori male, ci manca qualcosa. E anche l'ultima frontiera di quelle che sono le intelligenze artificiali, se partiamo da questa prospettiva, altro non è che un mettere a una pezza un ragionamento che a noi manca. Però io vi invito a fare una riflessione. L'elefante ha la famosa memoria di elefante. Tra le stranezze che ho fatto da francescano c'è stata quella di andare a visitare i miei con fratelli in Sri Lanka. In Sri Lanka c'è un po' questo culto dell'elefante e siccome c'è stata la guerra civile e gli elefanti crescono solo in branco, hanno fatto per gli elefanti rimasti orfani una sorta di orfanatrofia. Ecco, lì ho fatto un'esperienza abbastanza come dire strana, inusuale per noi, perché ho allattato un cucciolo di elefante. Quindi voi immaginate questo coso grande come una 500, che pesa più o meno come una 500, che si aspira un 25 litri di latte come un nitrofora di quelle serie. Quello che ho fatto all'elefante è stato produrre un cambiamento dei suoi neuroni per cui non mi si scorda più. Lui ha la famosa memoria di elefante e lo Sri Lanka è pieno di scene di questi elefanti che sono diventati ancora più grandi da 500, come un piccolo bus, che corrono in mezzo alla gente per andare a fare una coccola con la proboscide a chi in passato gli ha fatto un favore o per andare a fare un dispetto, una bella proposcidata su chi è stato scortese con loro. Io e voi no, io e voi non abbiamo abbastanza neuroni per ricordarci tutto, però questo che vuol dire? Che non siamo solo la nostra condizione biologica, cioè siamo un'eccedenza rispetto alla nostra condizione biologica. E allora guardiamo la tecnologia in questo senso, perché se noi guardiamo la tecnologia in questo senso, la tecnologia è una traccia di questo nostro volere di più e meglio, può essere la traccia di un cercare di realizzare cose più belle, cose più umane, cose che hanno un impatto positivo. L'etica si gioca in questo senso, secondo me, l'etica si gioca nel senso di chiederci ma quello che stiamo facendo, quello che stiamo usando, per che cosa lo stiamo facendo? Il professore, sì. No, dammi del tuo. Vale il francescano, quindi tutti del tuo, dai. Guarda, io ti do del tuo, insomma. Nel senso che... Perché tutti un elefante, mezzo tonnellata al garrese. E allora, è una questione veramente complicata che già me l'ho scordata. Nel senso che è una cosa... Immagino che tu abbia letto Feuerbach che diceva che la religione è antropologia capovolta. Quindi, secondo te, in qualche modo l'uomo, piuttosto che vedersi come qualcosa di difettato, come hai detto tu, potremmo dire anche che in qualche modo, o comunque che cosa ne pensi se dicessimo che in qualche modo aspira al divino attraverso una perversione del potere della creazione che è l'intelligenza artificiale o comunque il codice? Entriamo subito a gambe adesa. Non lo so, mi è venuta in mente questa cosa. È molto molto importante questo. Perché, allora, io direi subito una cosa. Evitiamo di fare quelli che pensano che la tecnologia è cattiva o è paurosa, no? Quindi è evidente che ogni forma di tecnologia è multistabile. Certo. Cioè io la posso usare nel bene come nel male. ogni utensile è anche un'arma a seconda di come lo utilizzo. Bene, detto questo, secondo me anche l'intenzione e il desiderio è molto stabile, per cui posso cercare di essere come Dio o giocare a fare Dio o posso in qualche misura, anche detta così faccio un po' troppo il francescano rispetto all'ingegnere, ma insomma per capirci, cercare Dio. Dove cercare Dio non è cercare di vedere Dio, a cercare un senso anche nel mio essere creatura, nel mio essere uomo. In fondo, quando l'uomo ha cercato di andare sulla luna, e non era semplicemente per farsi divere, era anche per vedere che cos'è quest'oltre. Dante ce lo diceva, "no, fatte non foste per vivere come bruti". Ecco, questo desiderio, questa nostalgia dell'oltre che abita il nostro cuore, è secondo me qualcosa di profondo nell'utilizzo della tecnologia non è garantito. Secondo me la questione di fondo è etica proprio perché non è garantito, perché se io lascio cadere una mela quella casca verso il basso e è la forza di gravità. Se io faccio uscire qualcosa da me non è garantito dove quella va e anzi ancora di più da quando Nobel ci ha insegnato che la dinamite poteva salvare operai in miniera e poi è diventata l'unità di misura delle bombe in guerra con i megatoni, sappiamo proprio che quello che io posso fare oggi non è detto come venga usato domani. Una delle discussioni simpatiche, visto che parlo degli sviluppatori, con cui ho discusso un po' con la comunità di GitHub e quando GitHub poi è stato anche acquisito da una compagnia privata, è quel codice che io regalo e regalo a una comunità. Ecco, se poi domani me lo trovo in un sistema di acquisizione del bersaglio di un drone? Perché la mia sub routine mi fa risparmiare corrente elettrica nel sistema di propulsione e quindi è più efficiente di qualcun altro. E' così tra l'altro, cioè nel senso... Lo so, questa è la parte... Allora questa cosa qua è chiaro che per esempio ci vuole una sorta di giuramento di Ippocrate, ecco questa è la seconda parte dell'etica. La La seconda parte dell'etica è se noi vogliamo che la mela caschi verso il basso, che cosa possiamo fare perché caschi verso il basso? Allora, è evidente che non possiamo fare la versione digitale dei dieci comandamenti, ma creare una sorta di alleanza tra persone e tra sviluppatori, questo secondo me può essere una cosa molto etica e molto bella che segna la nostra stagione. Un po' perché il mondo del software nasce un po' sempre in maniera contropulturale, no? Non avremo le grandi innovazioni del software se non ci fosse un po' di contropultura. E un po' perché secondo me è tempo di fare cose nuove. Cioè, quando la medicina è la cosa che ha cambiato un po' il mondo c'è stato il giuramento di Ippocrate. Ecco, oggi che il software è quello che scrive e riscrive il mondo, che il codice è quello che scrive e riscrive il mondo, non ci vorrà una sorta di, come dire, di nuovo giuramento di Ippocrate. qui faccio una sorta di 1-2 con le gambe visto che ci dato Feuerbach, perché sin dall'inizio della medicina, la medicina guarda al farmaco, col termine greco "pharmakon" che significa due cose, medicina e veleno. Ecco, il software è l'equivalente del farmacon, può essere medicina o può essere veleno, quella libreria che tu includi può essere esattamente tutto il bene o tutto il male, quella chiamata che fa quel software dipende come la fa, può essere addirittura, abbiamo visto SolarWinds, ne abbiamo viste tante di tutti i colori, però può essere strumento di tante cose. Non se ne esce da soli, è chiaro che c'è una domanda che riguarda ogni sviluppatore, cioè ogni volta che lo sviluppatore mette dentro un circuito condizionale, sia IF, WILE, quello che sia, c'è una domanda etica che gli fa chiedere questo giudizio che tu stai facendo computare la macchina che senso c'è. Ma poi non si ferma lì, perché poi quello diventa sociale, quello diventa incluso in una serie di prodotti che a layer costituiscono prodotti finali, cioè di un grande software che gira, ma neanche di un medio software che gira oggi. Un milione di linee di codice? Due milioni di linee di codice? Ecco, ma chi lo scrive tutto? Cioè, anche io quando gioco Python per fare i miei momenti di schiacciapensieri, è evidente che includo delle librerie, è evidente che includo pezzi fatti da altri. Forse una cosa interessante che può nascere e che deve nascere dal basso è questa sorta di alleanza, se vogliamo creare una community di software, che sia un'alleanza su queste cose qua, su questa idea di fine che ci diamo. Per arrivare al momento dell'alleanza, io provo a fare questo ragionamento, per per portarci a quel punto secondo me è necessario che da sviluppatori, da ingegneri, da analisti tiriamo su la testa dal nostro codice e guardiamo ciò che ci circonda perchè spesso, questo lo vivo in prima persona quindi immagino che sia una cosa condivisa spesso quando lavoriamo siamo completamente in bolla direi quindi chiusi in questa bolla dove c'è gli elementi che entrano in gioco sono il nostro codice siamo nel micro e spesso non abbiamo contezza del macro quindi del contesto dove siamo immersi anche di quello che stiamo facendo siamo pagati da una corporation per fare qualcosa ma l'impatto di quello che sto facendo l'ho fatto il valore etico poi andremo un po più a fondo con Paolo su questo termine. Lo sto analizzando. Cosa è che devo fare da sviluppatore per riappropriarmi di quel momento in cui rimetto al centro l'uomo e prova a vedere l'impatto che questo ha verso l'uomo come singolo e verso la collettività. Questo è un po' il problema dell'ingegnere, perché l'ingegnere è è efficace e funziona se scompone il problema in una serie di parti e poi assolve parte per parte. Questo purtroppo è come ci hanno insegnato a funzionare, è così nell'edilizia civile, è così nella meccanica, è così nell'aeronautica, è così nell'elettrico, nell'elettronica, sto prendendo tutte nelle idrauliche così non si offende nessuno, è così fino all'informatica. Cioè la mentalità ingegneristica è quella che vede la realtà come un problema, scompone il problema in sue parti per risolvere ogni singola parte del problema. Poi ci pensa il compilatore a ricordarci che qualcosa l'abbiamo saltata. Bene, ma al di là di questo qui c'è un bisogno che è un altro, non è un bisogno di cause, di conoscenze di cause, è un bisogno di fine. Ecco, è qui che l'ingegnere, secondo me si deve ricordare che ingegnere non è un sostantivo ma è un aggettivo ed è l'aggettivo di un sostantivo molto più bello che è persona, per cui il fine, il senso di quello che uno fa a fine giornata è qualcosa che riguarda la persona. È vero che uno ha un contratto di lavoro per dare una competenza, per dare uno skill, ma ce l'ha anche perché lo porta con un bagaglio di valori, di idee, di patrimonio che è l'idea che lo fa a persona. Ora, da noi un pochino di cose in America si stanno muovendo, specialmente adesso che il mondo del software impatta così tanto la società. Quando l'informatica era una cosa un po' da smalettoni, era vista come una perdita di tempo e mi ricordo che mio padre mi diceva "fai le cose serie e non giocare col computer". Poi è diventata un'industria e oggi è diventata un'industria che è l'industria che muove il mondo e questa inevitabilmente ridispone il nostro modo di abitare. Spero non ci sarà mai più una guerra, ma probabilmente la prossima guerra sarà anticipata, saranno informatici per immobilizzare una serie di servizi e quindi è evidente che oggi è lo strumento come come una volta c'era l'aviazione come uno strumento più avanzato oggi è il cyber è il lato più avanzato delle nostre relazioni e quindi qui dal discorso etico diventa un problema di allineamento anche tra il lavoratore e la company e questo per esempio la cosa grande che è successa lo scorso anno con Google dove di fatto un comitato etico che era un comitato etico interno a un certo punto ha iniziato ad avere una serie di come dire di tensioni con quello che era l'amministrazione e si sono saltati uno alla volta non si sono trovati non si sono capiti e sempre di più le grandi compagnie cercano di avere un allignment etico poi chiaramente nessuno è ingenuo e sa che se noi ci autoregoliamo con l'etica è un principio di soft law ed è molto più pratico che se mi regola uno stato da fuori con un principio di hard law, quindi c'è anche una win win situation, però questa è una novità, ed è una novità perché se noi parlavamo di questo tema negli anni 70 l'unica questione era un problema salariale, oggi parliamo di questo e ne parliamo anche in un termine di valori, ne parliamo nel termine di valori vissuti e trasmessi, quindi grazie a chi ci ha preceduto per aver fatto le battaglie salariali, anche se oggi non è detto che tutti se la passano bene a fare il programmatore. Però detto questo è chiaro che se stiamo sulla frontiera dei valori è un modo di partecipare diverso all'impresa. L'informatica consente anche un modo di partecipare diverso all'impresa in cui qualcosa che io scrivo è parte della mia persona che rimane per sempre attivo all'interno dei processi. Io penso sempre a quel tizio che ha scritto il programma sulla mica 500 che è ancora apre e chiude le finestre in una scuola, in una grande università americana. Tutti guardano sta mica sperando che non si fonda perché non sanno come fare altrimenti. Ha capito quello da mo che sarà andata in pensione e ancora il suo software regola una serie di cose. Là non c'è a Kubernetes che fa rollout del deployment quando si fonde la mica purtroppo. Esatto. Ed è quello che vivono ogni giorno i nostri poveri sviluppatori COBOL, no? Questa nata inesplosiva. E' quello ZOM, ognuno ha la sua nicchia, non si estingue, sta là. Ma allora, in realtà questo ultimo discorso è una cosa che mi sta parecchio a cuore, Personalmente è una cosa che cerco di portare avanti da parecchi anni anche con i miei colleghi. Parlo del contesto generale, ma specialmente di quello italiano. Tendenzialmente si riferisce all'etica, alla modalità di lavoro, a ciò che si fa nel proprio lavoro, solamente quando si tratta di giudici, medici, avvocati o comunque in queste professioni che sembrano essere a contatto più diretto con la persona, insomma. Magari è indubbio, oppure è assolutamente assurdo trovarsi magari in un pronto soccorso, ci sono due medici che stanno parlando con un paziente davanti, ma allora con questo che c'è? C'è "boh, non lo so, gli puoi dare questo" poi si vede, oppure magari c'è questa persona che non cammina ad un certo punto cammina, si vede "mai", il medico dice "magari vicino all'altro medico" vabbè, dai, comunque cammina, lo possiamo mandare a casa, non fa niente tanto comunque cammina. Se riportiamo questa discussione, questo pressappoghismo questa mancanza di etica professionale all'interno del contesto informatico, una cosa invece che avviene sempre e che sembra essere socialmente e professionalmente accettata. E incoraggiata in alcune realtà. E incoraggiata in alcune realtà. Just works. che però magari in alcuni contesti che sono più critici di altri, perché magari nonostante solo noi bisogna avere la stessa etica in ogni cosa che si fa, insomma nel senso a partire dall'e-commerce per la pizzeria al sistema critico per un'infrastruttura sanitaria o per un'infrastruttura militare, insomma. Nel senso, perché viene percepita come una cosa socialmente accettabile? Alla fine, anche se andiamo verso quelle professioni più tradizionali, non lo so, a voi come la prendereste? Se venisse una ditta che fa in traulica a casa vostra, vi sta perdendo il lavandino, a un certo punto vengono, ci perdono 5, 6, 7 ore, che lo guardano, che lo guardano, lo smontano, a un certo punto il lavandino non perde più. E l'irale lo dice "guarda, il lavandino non perde più, ha riede 10.000€". Quindi, nel senso, non è comunque una cosa che accettereste questo pressappochismo. E allora, come mai è socialmente accettato e come mai la figura del programmatore o dell'ingegnere del software in generale spesso sembra non percepire questa responsabilità che ha verso quello che scrive. Poi secondo me è anche il mondo al contrario. Se andiamo in quelle cose più critiche, in quelle cose che magari sono anche pubbliche, nella pubblica amministrazione succede il peggio del peggio, tra la consulenza e il subappalto, lo facciamo così, boh, si, funziona, facciamo. In questo periodo di pandemia, dove c'è stata una digitalizzazione più spinta, una digitalizzazione obbligata, abbiamo visto gli scempi più totali. Perché secondo voi questa cosa non viene percepita? Perché quello che scriviamo non è una cosa materiale? Oppure perché culturalmente siamo abituati a fare così? Fatto un pippone assurdo che potrebbe essere rassunto in questi ultimi 15 secondi. Secondo me in realtà c'è il problema complesso e merito, nel senso la testimonianza della fatica di chi si trova a vivere un voler fare le cose bene, un sistema che invece gli dice "beh, metteci una pezza", che poi è il famoso patch che ci ha salvato in un sacco di occasioni, però è chiaro che secondo me è importante perché già l'istanza è etica. Allora io non ce l'ho una risposta, però nello stile del, come dire, del prolisso, sapete che i piace ascoltare la propria voce, quindi è un macello. Proviamo a mettere alcune cose. Secondo me una prima cosa è già che lo chiamiamo software e chiamarlo soft, una martellata fa male, un software sembra che non fa niente a nessuno. La seconda questione è anche legata a come ci hanno formato, perché chi non si ricorda il corso... - Oddio, Kit, che ti è successo? - L'ho mancato, mi hanno avvelenata prima di sparare. - Non sono io, non so. - Io non ero. - Non so cosa sia. - Chiamo un video. - Non lo so, però sembrava veramente un bel film, ragazzi. - Non so che cosa è successo, però ho i poteri, faccio partire la musica in sottofondo. io facciamo un taglione, no? togliamo indietro. Vabbè, hai fatto i miracoli, ok. Penso avere de shtreeh. Dunque, secondo me c'è un pannello con un hardware che è partito sul browser di qualcuno, però va bene. L'ultima volta che mi è successa una cosa del genere, a me era successo una pubblicità è partita su Corriere.it. Dunque, torniamo indietro. La prima questione è che quindi si chiama soft, no? Se siamo disponibili a pensare che un martello se casca in testa a qualcuno fa male a qualcuno, pensiamo che il software, perché è soft, non abbia un impatto sulla realtà. La seconda questione secondo me è connessa e in maniera non banale anche a a come veniamo formati. Chi di noi non ha fatto qualche corso di informatica all'università in cui il professore gli ha detto che l'importante è che il software che è come compito giri. E' un software che è destinato solo a girare la prima volta. E quindi se tu parti con questo single shot in mente, ecco, è già una modalità. La terza questione, secondo me, è che ci ha rovinato un po' anche l'etica delle professioni. E l'etica delle professioni ci dice che l'ingegnere responsabile dei dati di targa. Ecco questo è vero, è verissimo, il responsabile della qualità, ma l'ingegnere non è un assunto a tempo, è all'interno di un'organizzazione. Per cui se l'organizzazione a un certo punto managerialmente fa alcuni tipi di scelta o c'è, che ne so, un body renting per cui tu vai, se seduisci una cosa e devi costare x giornate di lavoro e non di più ecco questa è un'altra questione ancora senza considerare poi e qui metterei un po di scusa che viene dalla contro cultura della cultura hacker che il software ha creato nel processo industriale una cosa che prima non esisteva cioè se tu produci mattoni il mattone ha una grande qualità che quel mattone esiste così e se ne vuoi un altro devi comprare un altro se invece invece c'è un software e lo copi, ecco che quel prodotto industriale funziona mille volte. Quindi questa idea di moltiplicazione del software e questo utilizzo del software ad un certo punto ha dovuto cercare nei programmatori dei mix, quindi le famose linee di morte nel codice che così erano costretti a richiamarti quando la cosa era ancora molto artigianale, perché inizialmente tutti ti dicono "se ti pago questo, poi dammi il software, poi soldi non vedi mai. Quindi la famosa che prima o poi crea un errore randomico per cui torno o ti sei scortato di pagarmi l'ultima fattura? Quell'errorino di quel tipo anche è a un certo punto parte del business. Oggi diciamo che però un prodotto come potrebbe essere un prodotto di un sistema operativo o di uno smartphone, tirarlo fuori con la qualità di cui parlavamo prima significa non tirarlo fuori mai. Cioè uno non sta appresso a questa diversità di device, pluralità di device, necessità di innovazione e pluralità di protocolli e cose che girano, attacchi che vengono fatti ai telefoni e quant'altro con questo ritmo, se non la lascia almeno aperta l'idea che l'utente finale alla fine diventa anche un tester. Cioè questo deploying del software cui l'uso è parte del test e quindi il software non è per forza perfetto prima, ma nell'uso eventualmente patch o delle cose, porta con sé, soprattutto piano piano che i sistemi si complessizzano, un'ereditarietà di problemi che non si risolvono più, che non si scoprono più, che ritirarla fuori è qualcosa di veramente problematico. Come tanti cerchi d'acqua, abbiamo lanciato la pietra in uno stagno ed ecco che i problemi si allargano. Secondo me un modo come dire di affrontare questo problema è quello di non ipersemplificarlo. È un problema complesso, teniamolo complesso e nel tenerlo complesso, cosa che a noi ci piace, lo gestiamo con tutte le diverse forze. E qui mi permetto di fare un esempio. Allora, quando ho fatto il dottorato negli Stati Uniti, il professore con cui ho seguito perché l'etica delle tecnologie non era così chiara, prima l'etica era o l'etica dell'utilizzatore, quindi come la mano utilizza la clava, o l'etica dell'ingegnere, come l'ingegnere fa il design della clava. Mi ha venduto una clava che doveva spaccare un cranio in un secondo, ci ho dovuto dare due martellate, questa cosa non è secondo la specifica di Targa. Questo nostro professore che invece si è inventato la tecnologia e ci dava una prospettiva diversa. Allora, una delle grandi cose che ci faceva fare era la gita a New York. La gita a New York e andavamo tutti con una bus che si chiama China Buses con 14 dollari fino a New York e ci faceva vedere le grandi strade di New York, il profilo di New York, eccetera, eccetera. E ci diceva "sapete chi ha fatto tutto questo? Un politico negli anni '40 che si chiama Richard Moses". Richard Moses era un grande razzista, lo diceva senza problemi, e lui pensava che le parti migliori della città dovessero essere delle persone migliori. E lui è quello che ha fatto i palazzi, le cose, un sacco di cose. Tra le varie cose che ha fatto, ha fatto la Parkway, che è l'autostrada a sei corsie che unisce Manhattan con Long Island. Lì c'era la sua spiaggia più amata che era Johnson Beach e per lui Johnson Beach doveva essere solo di quelle che lui riteneva le persone migliori della città, cioè la white middle class, che fa allora evita che il treno arrivi a Long Island, quindi niente mezzi di trasporto pubblico e fa costruire i ponti sulla parkway due piedi, una cinquantina di centimetri sotto lo standard rispetto allo standard nazionale, gli autobus non passano. Ed ecco che improvvisamente solo chi c'era la macchina, cioè a quell'epoca solo quelli di una certa classe sociale potevano andare in spiaggia. Ecco, il nostro professore che era London Winner ci diceva "guardate che l'etica della tecnologia è quella cosa che vede in ogni artefatto tecnologico, lui lo diceva in inglese, a displacement of power, a form of order. Ecco, il software è il ponte in calcio estrusso degli anni 50, è una forma d'ordine, è un modo di disporre il potere". Ecco, questa secondo me è un'altra bella cosa per chi fa lo sviluppatore, perché quel pezzo di software garantisce o nega, quel modo di scrivere quella cosa garantisce o nega altri diritti che invece sono scritti non in codice, ma magari su carte costituzionali, su codici dei diritti e dei doveri. Veniamo tutti fuori da un'esperienza comune, noi ci siamo tutti vaccinati, per vaccinarci siamo andati sul portale della regione e abbiamo messo i nostri dati. Ecco, lì è un algoritmo che ha detto sì o no se potevamo essere vaccinati. Lo stai dicendo tu e non lo sto dicendo io, è incredibile. Lo ho iniziato dicendo prima o poi vi reirò su questo argomento. Però capite lì c'è qualcuno che mediato da un ingegnere, dove per ingegnere in realtà parlo di tutto il layer tecnico, che sia l'azienda che ha vinto l'appalto, qualsiasi cosa, qualcosa che dà verticalità a quell'istruzione, se mettiamola così, che la mette a terra, ha realizzato una cosa che è di un'altra parte. Allora, se c'è scritto "Il cittadino italiano ha diritto alla salute e alla Costituzione", poi a un certo punto è diventato "If this then that". E quel "If this then that", chi l'ha deciso, come è controllato, visibile alla unità. Ecco questa questione per esempio è una questione molto etica, molto di etica della tecnologia, che a mio parere può diventare una cosa molto interessante e se noi nella cartella di documentazione oltre alle specifiche del programma mettessimo anche delle specifiche etiche, se tirassimo fuori una specifica etica che dice guarda che se tu tu questo modulo lo applichi così da strumento che non ci ricocco immediatamente, lo fai diventare un'arma? Chi meglio di un ingegnere può tirare fuori i dati di targa che danno il confine etico di quello strumento? LM: Ma questi confini etici siamo costretti a farli nel modo "if this then that" o l'etica in qualche modo può essere codificata e auto appresa, imparata? Per esso noi l'abbiamo fatto, abbiamo impiegato qualche migliaio di anni però alla fine abbiamo in un certo senso codificato l'etica, fino a un certo punto. Ci sono delle pagine bellissime e qui parte il mio trip da eticista. Allora, nel '67 a un certo punto una donna, perché bisogna parlare pure di donne, qui siamo solo tra uomini ma si sa che i programmatori sono maschi, sta usando un bias di genere. Quando io andavo ingenieria, forse c'era qualcuna ingenieria ambientale, qualche donna, per il resto eravamo tutti uomini, disperatamente tutti uomini. Detto questo, quando Filippa Futta nel '67, una donna filosofa a Oxford, parlava di altri temi, però inventa una cosa che è il dilemma del carrello. Forse l'avete sentito, il dilemma del carrello c'è questo tram che sta andando dritto e rischia di mettere sotto 5 persone, c'è il conducente. Se tirare vada lo scambio il tram va a destra e ammazza la persona. Che deve fare il conducente? Lei lo faceva teorico. Dal '67 in poi iniziano a diffondersi i trenini tipo skybridge che guidano solo all'aeroporto. Capite che questo dilemma che lei ha fatto è diventato eccezionale per discutere la scelta etica e come automatizzare la scelta etica. La prima cosa di cui ci siamo resi conto è che, questo non è successo nel 67, ma ad oggi, se tu lo chiedi a parole, se lo metti in una realtà immersiva con tanti visori 3D, col pulsante davanti da schiacciare, il 90% delle persone dice "tirare la leva", il 10% no. I numeri sono standard, come la fai vivere la fai vivere in simulazione, a parole o in in realtà inversiva. Già questo ci potrebbe interrogare perché non c'è un 100%. Seconda questione, la parte più complessa arriva quando gli dici "mi dici perché è giusto fare così?" Ah, ecco in parte che ci divertiamo e partono dei filmoni. Allora c'è chi ragiona come medievali con una cosa che si chiama il principio del duplice effetto. I medievali, che erano belli, quelli erano veramente programmatori, perché facevano analiticamente tutte le cose e dicevano "Allora, se c'è un'azione che porta con sé due effetti, uno positivo e uno negativo, è lecito" sentite che il linguaggio medievale compiere tale azione "e quelli partivano quattro condizioni, se tu vuoi l'effetto positivo e tolleri quello negativo, se quello positivo è proporzionato a quello negativo, se di fatto non c'è altra realtà, allora tolleriamo il male che esce fuori ma cerchiamo di fare il bene. E questo è un principio che ha funzionato, è un certo punto però poi è arrivato Immanuel Kant e Immanuel Kant ci ha detto che non si può mai usare la persona come fine, mai come mezzo ma sempre come fine. Io sto usando la persona a destra per evitare che le altre 5 finiscono. grande altissima discussione c'è un paper che è uscito in cui hanno fatto l'analisi delle parole di Kant dal tedesco eccetera eccetera si riesce a giustificare che quella persona era una persona con fine. Arrivano gli utilitaristi si può fare e è giusto fare la soluzione che simizza il risultato figo se non fosse che Smart che è uno di questi smart poi bellissimo questo libro che uscì nel 1974 a Cambridge, utilitarianisme pro and against. A un certo punto Smart intuisce che qui però ci vorrebbe un sistema che ci fa calcolare le probabilità, si potrebbe applicare la teoria di Hockey, perché lui secondo me non c'era il machine learning, perché qui già se no era una cosa molto interessante. Però Smart, se mi perdonate come se fosse molto romana di strada, si intrippa perché a un certo punto gli dicono "sì ma quante cose devi considerare per capire cosa che massimizza la soluzione? Cioè, se l'uno a destra è madre Teresa e a sinistra tra i cinque c'hai Hitler, Himmler eccetera eccetera eccetera, se tu ne ammazzi i cinque salvi milioni di vite. Allora le cause sono le prime, le seconde, le terze, le quarte, le quinte. Capite che l'utilitarismo in quanto tale cade in alcune aporie per quanto sia ben quantificabile e calcolabile, non è così capibile cosa è che fa un'azione buona o male, se tu non parti da qualcosa che vuoi fare o non vuoi fare a priori. Vi faccio un esempio. Se voi avete il vostro capo, e ragioniamo in maniera utilitarista, è lecito uccidere il vostro l'utilitarista vi direbbe se quello che viene dopo è meglio sì. Ecco però tu quando lo uccidi non lo sai chi viene dopo. E se lo sai? E se lo sai a quel punto si chiama delitto premilitario. Detto questo capite che io volevo semplicemente complessizzare i metodi o i sistemi che pian piano abbiamo sviluppato per cercare di dare ragione di quello che dentro ci sembra istintivo. Ci dispiace per quello che more ma meglio uno che 5. Allora questa cosa qua è un po' il peso dell'umanità e come facciamo a calcolarla e calcolarla con tutti i problemi che ci siamo detti prima che magari stanno dentro una una libreria che è incluso rispetto a un'altra. Guarda, è incluso la libreria però è una versione buggata quindi purtroppo la chiamata che hai fatto fa due e mezzo. Ancora più problematico, abbiamo fatto fare questo test, se volete andare all'MIT lab, si chiama The Moral Machine, in cui si fa questo test online e ci sono varie situazioni. Allora, è meglio che muoia il proprietario, quello che guida la macchina o la mamma col passeggino in mano e ti fa la soluzione e tu devi rispondere. E' meglio che muoia l'anziano sulla macchina o tre bambini che attraversano, tutti pronti a dire l'anziano. E se quelli hanno attraversato col rosso? Ecco, e poi un'altra questione. Ma supponiamo che io mi sia comprato quella che la macchina più venduta nel settore di macchine in Europa oltre 135 mila euro che si chiama Tesla. Ecco, la Tesla ha un sistema di guida autonoma. Detto tra noi, ma io vorrei che i miei 135 mila dollari o euro che siano uccidessero il sottoscritto piuttosto che tre che attraversano magari una piccola minoranza etnica che io non posso vedere e qui sorge un'altra domanda ma perché io sono proprietario della macchina più diretti di chi sta per strada e chi ti prende la macchina dice guarda se io ti dico che la macchina di voci 3 magari tu non te la compri quindi t'arrocchiamo un po alle levette se li alziamo o abbassiamo il threshold e così via. Allora questa cosa qua capite quanto complessizza tutto il discorso. Secondo me la soluzione non è riuscire a codificare un "if this then that" che vada bene per tutti, ma tenere aperto uno spazio dove si discute di questi problemi. Guardate che l'etica se la sono inventate i greci. I greci vivevano in piazza al centro della polis e chiacchieravano di queste cose. Per questo questo podcast è una sorta di proseguimento ideale di quella prima chiacchierata in piazza che ha questo valore perché non siamo qui per includere la libreria ethics.c o ethics.comevi fare da mettere dentro il nostro software si tratta chiaramente di tenere aperta una via perché l'etica è sempre una situazione di compromesso tra le possibilità, i desideri e quello che realmente vuoi fare. Finora abbiamo parlato di sviluppatore, utilizzatore e di company. E qua guardando ciò che ci circonda e guardando l'importanza delle corporation nella visione tecnologica attuale mi viene da dire e che ruolo dovrebbe giocare lo Stato o gli Stati in questa dinamica? Abbiamo tre risposte. Gli americani dicono winner takes all. C'è Apple, c'è Android, c'è iOS, c'è Android che decide il mercato. chi vince il mercato setta lo standard. C'è Windows, c'è Linux, c'è quello che setta il mercato vince lo stato regola il minimo. Andiamo dall'altra parte dell'arco e c'hai state driven per cui la Cina ti dice no no meglio l'armonia globale andiamo giù in verticalità. In Europa stiamo in mezzo in Europa abbiamo una lunga relazione di tradizione di regolamentazione diciamo creiamo dei regolamenti, dove i regolamenti possono essere da un equivalente di direttiva macchina, la famosa direttiva macchina, cioè se io vendo una fettatrice in Europa, non è che dico la fettatrice che vende di più, ma deve avere un marchio di qualità. Quel marchio di qualità rientra all'interno di un sistema di test, eccetera eccetera. Forse si tratta di fare la stessa cosa della direttiva macchina, facendo una sorta di marchio di qualità per il software, cioè creare uno standard al quale si può stare. Non ci scordiamo che da questo punto di vista sul software l'Europa ha già perso tre grandi battaglie, ha perso la battaglia dei sistemi operativi, ha perso la battaglia dei sistemi mobili e adesso probabilmente siamo pure perdendo la battaglia dell'intelligenza artificiale, dei sistemi cloud sull'intelligenza artificiale che saranno as a service via cloud ma non prodotti nostri perché gaia x è semplicemente un protocollo per fare affari in europa che non non una produzione europea di intelligenza artificiale fino adesso ci ha andato bene perché se voi comprate la stessa macchina in europa in america in europa è molto più sicura perché chiaramente non essendo regolata e là vince il costo e il costo fa risparmiare su una serie di processi. Questa cosa è chiaro apre una serie di ulteriori domande. Qual è il ruolo dello Stato? Non lo so, secondo me se lo Stato è troppo coggente soffoca il mercato. Di contro ci sono dei servizi che possiamo definire critici dove secondo me il ruolo dello Stato è fondamentale perché tu non puoi avere un defibrillatore un ventilatore meccanico o peggio ancora, oggi un diabetico può avere un infusore di insulina che con un algoritmetto di machine learning automaticamente dà l'insulina nella maniera migliore per metabolizzarla sull'organismo e così tu hai una vita molto molto migliore che prima. Ma se lì noi non diciamo niente, chi mi garantisce quell'algoritmetto di machine learning, visto che tu mi paghi il farmaco, non è fatto per massimizzare la quantità di farmaco che sottomette? O, come le fotocopiatrici a nolleggio, se io ti pago un fisso, chi mi dice che il toner lì non viene raschiato al minimo, che la quantità di copertura della pagina non è il minimo, così io risparmio sul singolo costo d'opera? Lì una regolamentazione, quando si toccano valori così alti, è necessaria. Pensate pure a quello che è un algoritmo che può calcolare o prevedere la capacità di un soggetto di restituire un prestito. E noi lì rischiamo di inoculare, altro che i punti di New York, delle barriere perché i dati su cui abbiamo addestrato alcuni algoritmi sono baisati, per cui c'hai che alcuni cap sono molto meno pagatori che altri. Ecco allora lì chiedere una certa sorta di trasparenza per tutte le cose che per esempio rendono effettivi o non effettivi i dritti per tutta una serie di mission critical dello Stato, quello diventa un'altra questione ancora. Ma adesso ti direi che un modello di verticalità dello Stato non c'è, andiamo dalla completa deregulamentation fino al completo controllo, è la stessa cosa vale sui dati. Luca volevi dire qualcosa? LM: Sì, era riferito all'argomento di prima. Inserire l'etica in vari processi decisionali significa intervenire pesantemente, significa prevedere centinaia se non migliaia di possibili casi e intervenire forse manualmente? Sembrerebbe proprio un problema di machine learning. Sì, adesso andiamo direttamente all'interno dell'intelligenza artificiale, del machine learning, del learning che forse è più più problematico ancora, perché fino a quando io ho qualcuno che mi ha scritto un algoritmo condizionale la condizione data da chi l'ha scritto e questo è lineare. Il problema è se io ho un algoritmo di regressione su una serie di dati, per esempio, perché l'algoritmo di regressione in qualche misura mi tira fuori una mediana, da una serie di anni modellizza la realtà. Allora, è chiaro che lì c'è un problema. Il primo problema per esempio è la qualità dei dati su cui viene fatto l'addestramento. Supponiamo che io abbia tutti i voti mai espressi da quando esiste gli Stati Uniti d'America ad oggi in tutte le elezioni presidenziali di tutti i collegi di tutti gli americani. Set di dati perfetto e c'è un algoritmo, sceglietelo voi, il migliore che vi viene in mente di machine learning, il migliore che potete avere in mente per quel set dei dati, per quella cosa chiara, chi sarà il prossimo presidente degli Stati Uniti d'America? E quello mi dice, guarda, un uomo, probabilmente di etnia caucasica, te lo dà il 75%, visto che fino adesso è successo poco e poi ti dice "guarda, qui direi tra 55 e 65 anni con il 65% di possibilità". Perché non dice una donna? Perché non c'è mai stata nei dati. Allora è evidente che la prima questione è che servono dei dati di addistramento che siano fair e qui parlo degli sviluppatori. Quando noi facciamo il machine learning o quando noi lavoriamo con i dati etichettati qualcuno a un certo punto ha fatto delle scelte su quelle etichette. Supponiamo che io debba insegnare un algoritmo a riconoscere un felino, un gattino e gli do una cosa tipo 1500 immagini. A un certo punto mi compare un cucciolo di etichette. Gattino sì, gattino no. Non può essere gattino forse, no? Ecco, che cosa sto cercando di dire con l'esempio sciocco? Che nell'etichettatura dei dati io sto mettendo dentro una cosa che si chiama "Base Truth". Ora, se quell'algoritmo mi serve per riconoscere i gatti, è una cosa. Se quell'algoritmo un altro sviluppatore lo include all'interno come una chiamata di un'applicazione che serve per "guarda che carina l'applicazione che ti dice se questo cucciolo lo puoi accarezzare senza problemi", ecco, se la vostra "Base Truth" su "cucciolo di tigre" era "gattino", compratevi una buona assicurazione, perché ve rovinano quelli, quindi capite che c'è questa idea di un valore che non è un valore numerico ma che è il valore etico che prima o poi un uomo ci ha messo da qualche parte e qui arriva la seconda questione non si tratta di impedirlo si tratta di renderlo trasparente cioè si tratta di mettere in catena a chi faremo quella chiamata come servizio del riconoscimento del gattino quali sono i dati di contorno con cui è stato progettata quella cosa, perché io possa capire se quella cosa regge o non regge nell'applicazione che devo fare. È chiaro che per quello che avete detto prima, di chiarene lavorarci poco, di chiarene lavorarci di corsa, di chiarene lavorarci che non scocci troppo, tutto questo diventa opacissimo. Ancora e ancora di più potremmo ulteriormente complicare la cosa riguarda, c'è un discorso di fondo che si può fare su dove è l'uomo in questo processo decisionale. Cioè se l'intelligenza artificiale è un competitor dell'essere umano, e allora facciamo "Uomo Sapiens vs. Machina Sapiens", o se l'intelligenza artificiale può essere uno strumento che aiuta a scegliere l'essere umano. E qui di nuovo, come abbiamo cominciato, il problema è sull'uomo. Perché? Vi faccio un esempio che secondo me è lampante da questo punto di vista. Bill Gates, uno che di informatica non ci capisce, di numeri, al di là delle opinioni che ciascuno di noi ha su Bill Gates, è uno che un po' le mani in pasta ce l'avute. Bill Gates a un certo punto, quando si è ritirato da Microsoft, ha fatto con Melinda Gates la fondazione. Una delle cose su cui negli anni '90 lo ha supportato tantissimo è un movimento per le piccole scuole negli Stati Uniti. Tra le varie cose che sostenevano, davanti un sacco di gente, un sacco di miliardi, è che se tu andavi a vedere i dati, dalle scuole piccole i risultati erano i migliori. Ecco, ci sono due statistici americani che a un certo punto gli hanno fatto un articoletto in cui hanno detto, lo dico ironicamente, "caro Bill", e hanno iniziato a dire "signori, sapete dove si muore di più di tumore di tumore a rene negli Stati Uniti piccoli centri, stati rurali, zone poco popolose che votano repubblicano. Voi semplicemente direte beh che votano repubblicano che c'entra. Dov'è che si muore? Esatto. Dov'è che si muore di meno? Di tumore a reno piccoli centri stati poco zona rurale che votano democratico. Ah, ecco che dentro di voi è scattata una cosa che dice "non è possibile che il voto sia la causa del tumore". Benissimo, cerchiamo un altro motivo. Il motivo potrebbe essere che nei piccoli centri, zona rurale, si mangia meglio e quindi il cibo ha un effetto. Un altro motivo potrebbe essere che nei piccoli centri c'è meno meno controllo della salute, quindi quando ti becca, ti becca che è tardi e quindi muori tanto. Bene, adesso scrollate la testa, tornate come veri ingegneri sui dati e che cosa abbiamo scoperto? Niente, che nei campioni piccoli gli eventi estremi sono più frequenti. Se io vi prendo un vaso pieno di biglie rosse e bianche e vi dico tiratene fuori quattro a caso, che ne escono quattro dello stesso colore, tutte rosse e tutte bianche, si muore di più o si muore di meno il 12,5 per cento, cioè di possibilità, che ne escono 7 dello stesso colore 1,75. Allora non c'è nessuna causazione in questa distribuzione, è un motivo matematico, ma dentro di noi c'è un sistema, la razionalità divisa in due sistemi, un sistema molto veloce che risparmia energia, che cerca la causalità e c'è un sistema due che lo mette in crisi. E adesso parlo agli sviluppatori. Se io disegno un algoritmo in modo che nutra il sistema 1, io sto disegnando un algoritmo che volutamente o non volutamente rischia di ingannare l'uomo nel suo decidere. Ecco l'etica, la user experience è anch'essa parte dell'etica. Voi immaginate se io faccio un algoritmo che nutre il medico con una serie di dati per fare una decisione clinica. Decide il medico, per carità, ma se quello è veloce e gli fa credere con una facilità cognitiva che quella è una causalità è come le scuole piccole di Bill Gates. Allora capite che qui c'è un'altra dimensione etica, che è la dimensione di chi confeziona il prodotto e si deve ricordare che dall'altra parte c'è un essere umano che funziona in una certa maniera, che fa un processo di decisione in una certa maniera. Quindi, l'etica è su tutta la filiera. L'etica si fa un sacco di domande, però tentare di vivere la risposta ancora ci tiene a questo mondo quindi io direi che insomma è una fatica da fare. Provando quindi a immaginare un modo per per inserire il concetto etico nell'intelligenza artificiale che è uno sforzo immagino anche abbastanza impegnativo, da dove possiamo partire? Allora come tutti i professori a me piace inventare le parole, direi che da francescano piace battezzare concetti ma dopo quello che è successo a Sanremo non si può più dire. Allora detto questo, la questione qual è? Secondo me si può pensare di scrivere un altro capitolo dell'etica, un nuovo capitolo, che possiamo chiamare algoretica, cioè dove questi guard rail informatici che vogliamo mettere perché la macchina non esca di strada siano in qualche misura non solo comprensibili, comunicabili e decisibili dall'uomo, ma computabili dalla macchina. È chiaro che se qualcosa di questo non diventa anche qualcosa di codificante o codificabile all'interno della macchina, ecco, questo è un problema. Facciamo un esempio. Ecco, l'esempio potrebbe essere l'introduzione di alcune librerie statistiche per cui, quando il risultato è statisticamente strano, la macchina chiede l'intervento dell'uomo, chiede il double check. Allora, se ci siamo detti che il valore non è un valore numerico, mettendo questa sorta di warning, ecco, lì la parte umana è chiamata a domandarsi eticamente che cosa sta succedendo. Funziona, ci garantisce sempre? No, ma si chiama etica, se no si chiama forza di gravità. Cioè, nel caso della leva, 90 tirano, 10 no, potrebbe darsi pure qua che c'è qualcosa di questo tipo. e poi si possono fare delle cose anche molto più sofisticate, soprattutto pensando a tutte quelle circostanze in cui uomo e macchina si troveranno a cooperare, dove secondo me la parte da tutelare è la parte umana. Non so se vi ricordate quel vecchio film di Charlie Chaplin, "Tempi moderni", dove dentro l'ingranaggio lui viene schiacciato. Ora è meno hardware e più software, però rischiamo di fare la stessa cosa. C'è un sistema che ho visto usare, che secondo me promette grandi cose, però c'è dei problemi. Sapete che oggi se uno segue l'oncologia, il vero problema del medico oncologico è trovare il fitting tra il paziente che è davanti e il miglior studio di laboratorio che è stato fatto su quel tipo di tumore. Ne escono tantissimi di questi paper. Voi immaginate di avere un sistema di intelligenza artificiale che semplicemente ti fa uno screening sui paper e ti suggerisce quali sono i paper e lo suggerisce al medico. Allora questo ci sta, è un aiuto al medico. Come quando tu dici al tuo assistente virtuale "chiamami quello" e quello ti fa un'azione. Il problema qual è? È che quando gli algoritmi di questo tipo interagiscono con l'uomo, questi non solo predicono, come l'algoritmo di Amazon o di Netflix che ti dice qual è il film che più o meno ti può piacere, ma producono anche dei comportamenti. Lo sa bene Amazon, per cui quel forse ti interessa anche a prodotto che tu ti sei comprato qualcosa in più. Cioè ti spingono al centro della caossiana. E allora capite che quando giochiamo su un tema così delicato come per esempio la cura del tumore, se non c'è questa istanza da parte dei programmatori, di mettere dei sistemi, dei check and balance, per evitare questa deriva automatica, ecco come noi ci mettiamo gli occhiali e improvvisamente gli occhiali sono parte di noi e quasi non ce ne accorgiamo più, rischiamo di metterci questi occhiali algoritmici e improvvisamente incorporiamo questi occhiali algoritmici che ci fanno vedere solo una parte della realtà. Allora l'algoritica è anche questa, se volete torniamo a Feuerbach, è un'antropologia inversa. L'informatica è un'antropologia inversa. Questa cosa può essere una formula in cui l'uomo è ciò che codifica o il codice è ciò che rimane dell'umano. Sto giocando un tocco di parole. Però secondo me l'istanza è etica e dire che l'uomo è ciò che codifica, più che noi siamo quello che rimane del codice, perché abbiamo già dato il potere alla maglia. Personalmente sono stupefatto, penso anche gli altri. Sazione male proprio. Io ho una domanda. Noi abbiamo chiarito il ruolo dell'etica in questo ecosistema. Però spesso un elemento, un player di questo ecosistema è anche la "startup", che ha come motto "vai veloce e rompi le cose" ed è diventato e sta diventando un elemento di tipo culturale. Quanto sono antagonisti questi due elementi? Di fatto non è caso che la start up nasca da un contesto che è un contesto della Bible cioè quella zona degli Stati Uniti dove c'è un protestantismo più forte che storicamente ripudia i concetti di etica. Questo proprio da Lutero in poi, dalle prime riforme, l'etica non serve perché o c'è lo Spirito Santo e sei redento o sei dannato. È interessante quello, perché quel "vai forte e spacca tutto" è proprio il sintomo di "non c'è responsabilità", teoria importante è che tu monetizzi. Quella monetizzazione come ultimo criterio è già una scelta etica, dire che i valori etici non contano. Posso io venderti una cosa che possibilmente ti fa male? Si posso, se ti fai male è un problema tuo. Questa cosa è tradizionale di una certa cultura, secondo me da noi questo modello di start up che punta solo al guadagno monetario è di fatto già una scelta etica che dice che l'etica è secondaria al resto. è arrivato il momento di ringraziare chi ci supporta ogni settimana con le donazioni quindi invitandoci una birra e questa settimana abbiamo Stefano Fiorucci che appunto ci invita una birra e ci aiuta a sostenere il nostro progetto Deeper perché noi lo facciamo con tutta la buona volontà i nostri ospiti vivono gratuitamente, noi investiamo il nostro tempo però abbiamo anche le potenze da pagare e quindi le vostre birre offerte ci aiutano proprio in quella direzione ci permettono di pagare speaker, ci permettono di pagare il nostro cluster kubernetes nel quale poi faremo girare alcune delle funzionalità che vedrete abbastanza presto ci aiutano a pagare streaming hardware che utilizziamo per registrare ci aiutano a pagare alcuni tool della suite adobe che utilizziamo quindi insomma è un grande un grande supporto e quindi alziamo i calici e ringraziamo e benveniamo alla salute di Stefano che appunto questa settimana è il nostro donatore però ecco questa questa questa questa cosa qui su cui sono assolutamente d'accordo è più facilmente percepibile dal pubblico se stiamo parlando di qualcosa che è materiale. Per materiale intendo che sia fisico, nel senso io ti vendo il dosimetro per l'insulina che è bellissimo, c'ha il machine learning, c'ha lo sistema di paper, ma si rompe, se se ti offro un prodotto software, anche se è pervasivo nella tua vita, è socialmente più accettato, il messaggio di errore spegni e riaccendi, come si fa a far superare al grande pubblico questa cosa? Sicuramente è un fatto culturale, un fatto di istruzione, di conoscenza di quello che c'è intorno e di quello che cos'è il software. Ma secondo voi è qualcosa che nei prossimi anni può andare a migliorare? Ho visto comunque questa tendenza, ci sarà sempre più una separazione tra ciò che deve fare e come è giusto fare il software e noi, nonostante il software sarà sempre più pervasivo nella nostra vita. Ma secondo me è successo all'inizio anche con la corrente elettrica, che non veniva vista come una cosa materiale, addirittura non si sapeva se era furto il furto della corrente elettrica, perché un conto è che ti rubo 3 pecore e un conto è che ti rubo 2 kilowatt. Dove stanno i 2 kilowatt? Ecco, siamo nello stesso faso, e ci è bisogno di nuove generazioni che generano una nuova cultura. Sempre di più, facciamo un esempio, il porn revenge. Non è niente di concreto perché tutto è digitale, iniziamo a chiamarlo per quello che è o il cyberbullismo, non è niente di fisico, ma iniziamo a chiamarlo per quello che è. Piano piano purtroppo passando dalle pagine negative è più facile che accada questo, però è evidente che stiamo un po' spostandoci. Se ci pensate tutto questo diventa cultura e diventa industria informatica dal '78 in poi, sono passati pochissimi anni e quindi ci sta che ancora una cultura non abbia assorbito in pieno tutto questo. Secondo me questo è un problema di comunicazione politica nelle grandi cose che avvengono dei sistemi juridici. Mi ricordo quello che è successo qualche mesetto fa con l'infrastruttura vaccinale della regione Lazio che poi si è scoperta che era quello in smart working, si è creato tantissimo scandalo, ma fondamentalmente non gli è fregato nulla a nessuno, nonostante quella cosa abbia prodotto un danno tangibile. E lì io mi sono preso in giro più dalla comunicazione politica che dal fatto in sé, perché c'era una parte addetti al lavoro tutta l'altra parte era sulla stessa scia di quelli che avevano fatto il sistema, si lamentava di questa cosa, mentre l'opinione non è pubblica, è semplicemente pensato "vabbè, è il sito che non funziona, che vuoi mai che sia?" Insomma, ecco, come possiamo anche dare, secondo me, un segnale alla classe politica per far sì che sia più attenta a questi temi e che sia comunicata meglio. Oltre alla cosa semplice, insomma, eleggi diverse persone, va bene, oltre a quella cosa lì semplice, ma come si fa a trasmettere comunque a delle generazioni che sono diverse dalla nostra? Sicuramente non posso eleggere un senatore ventenne, alla fine, sia per leggi sia per altri motivi. Come possiamo fare per trasmettere questa cosa? Perché veramente a volte sembra che non gli freghi niente a nessuno e ti prendono anche per pazzo se insisti su queste cose qui. - Secondo me bisogna anche semplicemente iniziare a parlarne, si parlava di creare coscienza del problema, sia come siamo in questa fase qua. Parlare è la prima cosa per trovarsi tra chi vive il problema. A difesa di tutto questo però, sempre perché se no non sarei sufficientemente eticista, il contro in tutte le cose, non è così facile fare equivalere il soft all'hard. Io sono stato dentro una discussione che riguardava i conflitti internazionali. Un attacco nella sfera cyber è da considerarsi un attacco equivalente a un attacco di terra, di aria o di mare? Allora, chi dice sì lo dice in una prospettiva per cui se noi banniamo alcuni tipi di armi tipo le nucleari, le chimiche, le gassose, possiamo pannare una serie di attacchi che magari vanno a colpire infrastrutture come gli ospedali. Se noi evitiamo di cifrare le cartelle cliniche di qualcuno che deve andare a farsi l'operazione, il medico non muore. E' chiaro, l'idea è buona, però c'è un problema. Uno, se io stocco le testate nucleari, da qualche parte ho 50 testate nucleari. Se io ho una vulnerabilità invisibile, la tengo ben nascosta e quella è un'arma a one shot. Quindi come fai a controllarle che nessuno le dichiara? Seconda questione è se a me arriva un attacco hacker che dentro è scritto in iraniano siamo sicuri che viene dall'Iran? Se a me arriva un attacco hacker che io traccio da una serie di computer che stanno in Iran siamo sicuri che viene dall'Iran? Di fronte questo problema di attribuzione. E' bene far sì che se a me mi arriva un attacco hacker che io attribuisco all'Iran la risposta è un missile nucleare? Ecco, allora questa fluidità del digitale che da una parte fa tanto male, dall'altra però rende difficili alcuni tipi di processi solo per essere complesso fino in fondo, è parte del problema. Perché è è una cosa nuova e come tutte le cose nuove, molto nuove, molto potenti, ancora dobbiamo imparare a gestire. Io sono... Overwhelmed. Esatto, avete presente il meme di Mike Blowing? Io pure. Io uguale. Io però guardavo l'orologio e ahimè... barista. Il mio ruolo è anche quello di avvicinarci alla fine, di accompagnarci alla fine. Ancora cinque minuti! Esatto, è stato super piacevole avere padre Paolo con noi e portare anche la discussione a questo livello. Prima però di salutare padre Paolo e di salutare anche tutti gli ascoltatori di Gitbar, noi abbiamo il nostro classico momento chiamato il Paese dei Balocchi, il momento in cui i nostri guest, i nostri host condividono un libro, un video, un audio, qualunque cosa abbia veramente valore e sia importante, possa essere importante per le persone che ci ascoltano. Quindi chiedo, Padre Paolo, hai qualcosa da ascerare? E conduco nel paese dei balocchi. Ah, il paese dei balocchi. Allora, io visto il tema, visto chi siete, visto quelle che sono le passioni che avete, vi condivido un libro che secondo me è molto interessante, di Giudia Pirl, che è un ingegnere informatico. Il libro si chiama "The Book of Why". Il libro è "Il perché", lui lavora sul fatto se è possibile o meno creare una macchina di inferenza causale all'interno dei dati e siccome di fatto la grande domanda etica è una domanda che risponde a un grande interrogativo "perché sto facendo quello che sto facendo", poter pensare di inferenza causale algoritmica è secondo me una bella sfida. Allora, visto che siamo nel mondo dei balocchi, ecco, questo è un bel gran giochino, ve lo lo lascio così come ulteriore food for tough. Sicuramente nel comodino tra una settimana, giusto il tempo di ordinarlo. Luca hai qualcosa? Sì io ritorno con un balocco visto che è stato citato, non è stato citato ma è stato citato, non è stato detto il nome ma penso pensieri lenti e veloci di Daniel Kahneman. L'ho rubato a qualcuno? A me? Ok, no, lo ripropongo, perché l'avevo già proposto in qualche altra puntata, però adesso mi è venuto in mente di rileggerlo pensando in ottica di etica e di intelligenza artificiale, che credo che sia completamente un'altra lettura. Allora io vi regalo due cose. La prima è un gioco di società che si chiama "Il trauma del tram" che è fatto dagli autori di "Saiyan Hide and Happiness" che è un fumetto molto cinico. E niente, praticamente è un gioco di società dove devi decidere sostanzialmente di squadre e poi c'è un autista del tram che deve decidere se prendere un primo o un secondo binario e sul primo o sul secondo binario ci finiscono un buono e un cattivo perché però faranno anche delle cose che magari il cattivo salverà tua figlia un incidente stradale, eccetera, eccetera. E' una cosa abbastanza, insomma, secondo me in tema, perché parla di le mie etiche, diciamo, in maniera giocosa. L'altra cosa che vi regalo è DoopSick, che potete guardare su Disney+, oppure se non volete dare soldi agli americani, visto che siamo in area grigia, quella etica, lo potete scaricare. e sostanzialmente parla di che cosa succede quando un'industria, l'industria medica, al posto di curarti nel modo in cui dovrebbe, ti fomenta una dipendenza da un farmaco. E tra l'altro è una storia vera, cioè una serie storica. That's it, vai Carmine. In realtà io riciclo anche un balocco, è un balocco tecnico in realtà, ed è "Designing Data Intensive Applications" di Martin Kleppmann, la copertina rossa, visto che ci sono anche altri, ma sono diversi. Ed è un bel libro che parla di come strutturare le nostre applicazioni dal punto di vista tecnico, per una grande mole di dati. È tutta una serie sia di best practices, sia anche di racconto di come sono state fatte alcune cose. Ed è secondo me un buon libro tecnico per riuscire magari anche a progettare queste cose, e soprattutto andare oltre le varie buzzwords che ci si dicono in giro, così magari la prossima volta che ci troviamo a progettare una cosa del genere lo facciamo con più condizioni di causa, sia etica sia tecnica. Io ne avevo uno, Luca me l'ha soffiato, ma non mi trovo impreparato perché in realtà ne avevo già preparato due. Allora, il primo lo sostituisco rapidamente con potenze di 10. è un libercolo di cui vi ho parlato all'inizio del podcast, è un libro fotografico procuratevelo, compratelo, andatelo a prendere in biblioteca se ancora esistono le biblioteche perché vedere il micro e il macro ci dà una sorta di posizione nel mondo e nell'universo e secondo me è importante buttare un occhio in quel libro e poi a quel punto non posso non suggerirvi il sito di padre paolo dove potete trovare tutte le sue pubblicazioni è super prolifico quindi se volete approfondire sulle tematiche che tratta ci sono un gozziliardo di libri che padre paolo ha scritto e che possiamo possiamo prendere e poi vi suggerisco anche il podcast perché dovete sapere che padre paolo è anche un podcaster quindi se avete piacere nel sito poi trovate tutto, il podcast si chiama Synthetix non vi dico di più, andatelo a guardare detto questo noi ci accingiamo a chiudere il nostro bar le birrette le abbiamo bevute Oggi abbiamo trattato un argomento un po' fuori dalla nostra zona di conforto ma importante per dare un senso o provare a dare un senso a quello che facciamo tutti i giorni. Io ringrazio nuovamente padre Paolo, grazie per esserci venuto a trovare. Grazie a voi e buon proseguimento, buon coding. Grazie, lo faccio a nome mio, di tutta la community e del gruppo Telegramma anche in maggio. quindi anche a nome di tutto quanto il gruppo Telegram. Io vedo che questa qui sia stata una delle più belle puntate, insomma, è stato secondo me una bellissima puntata su un tema che spesso intorno a noi viene completamente ignorato, perché secondo me è anche il segno che bisogna smettere di pensare di portare sulla casa la giornata quando facciamo cose che coinvolgono le persone. e se Alessio e Luca vogliono aggiungere niente? Io personalmente come closing note veramente ringrazio Paolo più che altro per averci ricordato ancora una volta che questo lavoro che noi facciamo e che diciamo siamo convinti che in qualche modo siccome è software siamo convinti non abbia impatto alla fine, alla fin fine sulla vita delle persone. Io ho potuto mettere in relazione l'operato mio lavorativo nella vita con la vittoria alle elezioni di Donald Trump, e quindi ringrazio veramente tantissimo Paolo per averci ricordato che quello che facciamo ha un un impatto fortissimo sulla vita di tutti quanti. Anch'io ringrazio padre Paolo e tutti voi perché dalle domande, se vengono meno le risposte, però l'importante è farsene le domande, mi auguro che io e tutti noi diventiamo persone e sviluppatori migliori. Sviluppiamo la parte di uomo piuttosto che la parte di sviluppatore o qualcosa del genere perché stare sempre a contatto con le macchine poi c'è il rischio che davvero diventiamo macchine anche noi e ci sono un sacco di barzellette che lo dimostrano alle quali noi tutti ridiamo non mentiamo detto questo grazie grazie di nuovo Paolo noi usiamo usiamo dire chi viene a trovarci la prima volta essendo un bar è un po il circolo degli sviluppatori questo quindi è diventato anche un po casa tua vienici a trovare quando hai voglia di chiacchierare con noi di qualcosa o hai qualcosa di interessante da condividerci? Guardate se tutto va bene ci sarà un libro che esce si chiama "Human in the loop" su come tenere l'uomo all'interno di questo processo decisionale dell'intelligenza artificiale ve ne mando una copia e poi mi dite che ne pensate va bene di chiacchieriamo insieme. Ok, volentierissimo, super super super volentieri. Allora noi intanto iniziamo a segnare già l'appuntamento di nuovo con padre Paolo. Grazie davvero Paolo, grazie di cuore. Ciao! Ciao! Ciao! Gitbar, il circolo dei fullstack developer. Una volta a settimana ci troviamo davanti due birre e combri il repo, parliamo di linguaggi e tecniche di sviluppo web, di metodologie ed strumenti immancabili nella cassetta degli attrezzi dei Full Stack Dev.