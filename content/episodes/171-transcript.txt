Bene e benvenuti su Gitbar, nuova settimana e nuovo episodio qua nel nostro bar degli sviluppatori. Qua ormai siamo già ad agosto, voi probabilmente state sentendo questo episodio quando la stagione estiva volge al fine se non è già terminata, però insomma noi vi portiamo un po' di estate di ritorno, ecco diciamo così. Oggi non sono solo e sono col mio caro amico Luca. Ciao Luca! Ciao Mauro, ciao tutti! Ciao, è finita l'estate, è finita l'estate. Che stra... io vedo il tuo volto bello rigenerato, io sono tipo super sciupato, tu sei super in forma. Dimmi qual è la tua formula segreta, non mi dire la birra che ho provato. E non funziona. No, sì ma le ferie, cioè alla fine quello e infatti quando sono stato in feria, tra l'altro forse qualcuno si ricorderà anche con l'avvocato che ho salutato e poi me ne sono andato, ma nel senso perché non c'era più nemmeno internet e quindi mi sono dovuto andare, ho avuto un detox di circa dieci giorni da internet, per questo che sono, mi vedi, voi ascoltatori non mi potete vedere, però mi vedi molto raggiante, c'è una luce dietro, una roba, non potete capire. Sì, ha l'aureola in realtà. Mentre parlavi pensavo una cosa, e se organizzassimo l'evento di Gitbar in un campeggio dove non prendono i telefoni e internet? Secondo te è una cosa fattibile? Sì, ma non dovremmo dirlo, magari qualcuno potrebbe spaventarsi. Arrivi all'evento, oh c'è un jammer da qualche parte, oh è sparito internet, non ci possiamo far nulla, decliniamo tutte le responsabilità col contratto scritto piccolo p. Dai cazzate a parte. Esatto, va bene dai. Partiamo con l'episodio, prima di partire dobbiamo ricordare come sempre i nostri contatti, info@github.it e brain.repo sono i modi canonici per contattarci e poi... poi ovviamente il gruppo Telegramma Gitbar Podcast, basta cercarlo con questo nome, vedrete un logo giallo con il nostro buon Mauro e la scritta sotto Gitbar, non potete sbagliare. Esatto, iscrivetevi perché vedo che siete ancora in tanti che non si sono iscritti, quindi vi aspettiamo perché è là, come dico sempre, il posto dove poi ci sono i follow up, ci sono le discussioni, ciao, è un posto super super carino dove è necessario esserci se siete dei github vittori. Detto questo Luca possiamo presentare l'ospite no? ma direi proprio di sì. Lo presento io? Quindi ok lo presento io abbiamo il zio di AI Academy, quindi anche un imprenditore, un ingegnere, speaker e divulgatore. Abbiamo qui Gianluca Mauro. Ciao, piacere. Eccoti, allora Gianluca, diciamo subito, io ti ho trovato su TikTok, perché voi non sapete, ma TikTok è il mio social ormai preferito. La tua droga. Ormai la mia droga, infatti a volte lo devo bannare perché altrimenti non non faccio più niente. Ma proprio per questo ho visto i tuoi video che sono AI centrici e quindi ho detto ma vogliamo parlare di AI siccome ormai AI è ovunque, ho già detto AI in questa frase, Ma non lo usiamo come buzzword, noi perché noi vogliamo affrontare le cose in modo sano e in modo costruttivo. Ma intanto la prima domanda che ti vorrei fare è questa. Tu nasci come ingegnere energetico, mi sembra di sapere. E com'è che hai deciso di entrare nel mondo delle AI? Ma guarda, ho fatto un giro stranissimo, nel senso che ho studiato ingegneria energetica a Roma e ho odiato il mio percorso di studi, dal primo giorno fino all'ultimo probabilmente. - Ti sembra regolare. - Esatto, come penso tante altre persone. Diciamo, quello che ho fatto che mi ha detto molto bene, è che sono andato in Erasmus, ho fatto questi sei mesi lì, e oltre a fare quello che si fa in Erasmus normalmente, e non lo diciamo perché poi va censurato, e ho chiesto al mio professore di Roma se potevo prendere corsi a caso fondamentalmente, corsi che non avevano nulla a che fare con l'ingegneria, perché mi era rotto le palle di prendere corsi di ingegneria e perché ero al secondo anno di magistrale, quindi a un certo punto insomma quanti altri corsi su i motori termoelettrici devo fare, cioè che basta, no? E uno di questi corsi era un corso sulle startup, e feci questo corso sulle startup nel 2014 e mi si è aperto un mondo, mi si è aperto un mondo, ho cominciato a vedere questo nuovo modo di vedere la tecnologia in cui è uno strumento per risolvere problemi, mentre invece fino a quel momento la tecnologia mi era stata proposta come una roba che studi sul libro e che devi ripetere al professore punto e basta e non puoi usare nessun bricio di creatività. Quindi ho fatto questo corso, ho avuto un'idea imprenditoriale e con quest'idea ho vinto una borsa di studio per andare in Silicon Valley. Quindi sono stato in Silicon Valley per sei o sette mesi nel 2014, se non sbaglio, 14 o 15, non ricordo, e ero lì per studiare business, quindi l'intelligenza artificiale ancora non c'entra niente. Però voi dovete immaginare che nel 2014, quando... era quando alcuni degli algoritmi, diciamo che hanno poi definito gli ultimi dieci anni, sono stati introdotti, quando il deep learning ha cominciato a farsi strada, quando i primi algoritmi di computer vision hanno cominciato a funzionare e quindi era impossibile non essere, diciamo, coinvolti in queste rivoluzioni che stavano avvenendo. E lì ho cominciato a studiare, ho cominciato a informarmi, ho avuto la fortuna di vivere insieme ad un mio grande amico, ai tempi era una persona con cui facevo questa borsa di studio, si chiama Niccolò Baligi, che adesso lavora per Apple come ricercatore, lui mi ha aiutato molto a muovere i primi passi, Però sì, diciamo, mi sono appassionato all'intelligenza artificiale perché in quel momento, in quel luogo c'era gente che ti ispirava. Io racconto sempre questa storia, ti racconto questo aneddoto che è divertente. Andavo a Stanford, dove c'erano queste lezioni gratuite e c'erano due ore col direttore della ricerca di Google Brain, Peter Norvig, che ti raccontava come Google era passata con per esempio su google translate da modelli vecchi tra virgolette a modelli di AI e cosa era successo a livello di performance. Io mi ricordo che sono uscito da quella stanza e ho chiamato mia madre la prima cosa che ho fatto. Mamma lavorava in IBM e quindi ne capiva un po' di questa roba qui. Mi ricordo che la chiamai dicendo "mamma, questo è tipo non il futuro, ho capito cosa voglio fare" e così ho iniziato. Passava un sacco di tempo. Quindi in tempi non non sospetti anche diciamo. Ma relativamente sai cos'è? E che ai tempi, diciamo se in Silicon Valley dicevi faccio intelligenza artificiale eri uno dei tanti e io avevo questa idea di voler tornare in Europa, in Italia, perché poi sono stato in Italia per tre anni, due o tre anni, poi mi sono trasferito a Copenhagen dove vivo adesso e dove l'estate è finita da un po' tra l'altro, o forse non è mai arrivata, non so se, insomma per riconnetterci al discorso di prima. Ma ai tempi in Europa non se ne parlava. Cioè io ho cominciato la mia, ho fatto partire la mia azienda, i.i.academy, e ho dovuto fare molto lavoro di divulgazione, che faccio proprio perché la maggior parte delle persone non capivano io che cosa volevo venderli, ok? C'era da fare molto lavoro di divulgazione. Esatto, io voglio farti una domanda, scusa Luca centro a gamba tesa. Hai parlato di Silicon Valley e tipo hai toccato un tasto dove dove dove in qualche modo attivi la macchina amplificatrice del mio analizzatore di contraddizioni no? E noi sappiamo bene che la Silicon Valley è un posto dove le contraddizioni sono sono accentuate. Oggi si parla tanto del costo della vita in quei luoghi. Io ho un sacco di amici che vivono là e mi confermano questo, guadagnano gozziliardi e ne spendono il doppio per vivere. Pensi che ad oggi ne valga ancora la pena essere là in quello che un tempo era l'ombelico del mondo ma oggi boh? Dipende, lo so che non è la risposta che volevi ma dipende. io sono qui per un motivo, perché per me non aveva senso. Uno perché per me non aveva senso, ma due perché mi ero annoiato. Cioè, in Silicon Valley fanno tutti startup e a un certo punto quando vai al bar e parli con gente "ah, cosa fai? Tu? Ah, un social media, ok. E tu? Ah, no, io blockchain, ok. E tu? Ah, io internet". Che palle! Cioè, volevo una persona normale, ok, con cui parlare, mi ero stofato. E poi mi ero anche stancato di queste bogie che si raccontano tutti. "Ah, vogliamo rendere il mondo un posto migliore. No, vuoi vendere ads, ok? Ecco, quindi, cioè, diciamo, diciamoci la verità. Poi, diciamo, è anche un posto in cui secondo me manca molto... faccio fatica di questa frase, ma c'è un po' un senso di cultura a 360 gradi, nel senso che se vuoi andare a mangiare fuori, se vuoi... ecco, facciamo così, se ti vuoi immergere in un parco giochi tech, sì, bello, vai una vita fantastica. Io non volevo...volevo anche fare altro. Uno, adesso se vuoi fare startup e vuoi fare startup tipo extreme growth, velocità, crescita, un sacco di soldi, sì, è il posto migliore al mondo. O se sei uno sviluppatore e vuoi lavorare su progetti impossibili, sì, miglior posto al mondo, c'è poco da fare. Il costo della vita è infinito, ma gli stipendi sono dieci volte tanto, quindi va bene così. Diciamo che se vuoi fare il programmatore e sei una persona estremamente schillata, molto brava, perché considera anche che c'è un mercato ovviamente tosto, ma se sei uno molto bravo, ragazzi, lì è una vita facile. Cioè secondo me è il modo più veloce e più semplice per diventare un multimilionario. Sei il mostro del c++, non lo so, vai lì, ti fai prendere da un'azienda che ha bisogno del mostro del c++, ti fai dare mezzo milione l'anno, un milione l'hanno quello che è, vai avanti e sta in posto. Quindi dipende, dipende. Io e i miei amici che sono rimasti, alcuni hanno fatto hanno fatto carriera, erano felici di fare il gioco delle start up, hanno venduto la start up, hanno fatto un sacco di soldi e non se ne andrebbero mai. Altri invece lavoravano, o amici che lavoravano per Apple, a un certo punto hanno detto no, basta. E se ne sono andati a lavorare per Apple a Londra, poi hanno detto no, basta, anche tech, me ne vado a lavorare, vado a fare un'altra cosa, ok? Dipende molto da che tipo di persona sei, non è il paese dei balocchi ecco. È chiaro, no, io volevo proprio evidenziare il fatto che in realtà sì è un posto dove quel tipo di meccanismo funziona, ma in realtà un posto dove chi ce l'ha fatta è uno su un milione, quindi comunque... Dipende però, scusa, cosa intendi per "ce l'ha fatta", cioè se "ce l'ha fatta" significa fare la startup con centinaia di milioni, sì, e uno su milioni, gli altri fanno la fame, però se "averce la fatta" significa essere uno sviluppatore che si porta a casa, non so, tre, quattrocento mila dollari l'anno, ce ne stanno tanti. Il punto qual è? È che quello che mi dicono le persone che vivono lì adesso è che già era un posto molto monotematico quando c'ero io, quindi una decina anni fa, 89 anni fa. Adesso che dopo il covid si è svuotata e la gente non ci vuole tornare, e la gente si è abituata a lavorare da remoto, è ancora peggio. Quindi, secondo me, la qualità della vita non è altissima. Però ecco, farcela in Silicon Valley, questa secondo me è un'idea che molte persone hanno che è sbagliata. Cioè, non è soltanto un posto dove vai a fare l'imprenditore, fai un pacco di soldi o fai la fame. È anche un posto dove se sei un bravo sviluppatore, ti fai assumere da una buona startup, puoi essere licenziato da domani senza nessun tipo di problemi, però c'è un mare di lavoro e ti pagano un pacco di soldi. Quindi c'è anche questa soluzione intermedia tra il divano e i miliardi, ecco. Luca? Sì, no, prima stavo cercando di dire che avevi detto che avevi difficoltà a far capire alla gente che cosa fai e mi è venuto in mente che tu comunque, anche nel tuo ruolo di divulgatore, hai a che fare eventualmente con persone non solo tecniche ma anche non tecniche che possono essere imprenditori ma anche i casalinghi e le casalinghe forse, non lo so, in qualche talk ti sarà capitato. E quindi ritornando in topic AI, ho già detto AI, sì, ritornando in topic AI, qual è secondo te il loro sentimento nei confronti delle AI, del generale e un po' delle persone. Diciamo, da quando è uscito Chargpt le cose sono cambiate molto. Facciamo così, ti do una risposta prima a Chargpt e poi dopo ti dico cosa è successo dopo Chargpt. Cristo e dopo Cristo, no? Esatto, no, praticamente sì. Esatto, c'è un pre-l'era. Ti ricordi quando Chargpt non esisteva? Allora, io ho sempre avuto questa tesi, un po' che secondo me è banale, perché mi è sempre risultata molto naturale, però la gente faceva fatica a capirla, che secondo me il valore nell'intelligenza artificiale non è tanto nel scrivere l'algoritmo più figo del mondo, ma nel capire cosa farci, nel capire se ha senso usarla, come ha senso usarla, che tipo di valore dare all'utente, eccetera eccetera. E quindi con EIA Academy ho sempre voluto fare formazione non tecnica, per fare un'analogia col mondo delle auto, facciamo il mondo della Formula 1, io non volevo insegnare all'ingegnere come fare un motore migliore, io volevo insegnare al pilota come si guida la macchina, quindi andavo dall'imprenditore, andavo dal manager nell'azienda, andavo, lo faccio tutto ora, però parliamo del mondo pre-gpt, e gli dicevo "guarda, l'intelligenza artificiale può aiutarti a essere più efficiente, creare nuovi prodotti, fare i forecast delle vendite, bla bla bla", e l'ho fatto con discreto successo per tanti anni, per dirvi, il cliente con la quale ho lavorato in maniera più continuativa è Pampers, i pannolini. Che straccavolo ci fa un'azienda di pannolini con l'intelligenza artificiale? Ci facciamo un mare di roba. Ci abbiamo ottimizzato il consumo energetico delle loro macchine, hanno questi motori enormi che producono energia con la quale stampano i pannolini, praticamente li tagliano, li mischiano, fanno tutto quello che devono fare e noi abbiamo ottimizzato il consumo facendo un forecast, una previsione del consumo del giorno successivo, previsione del costo dell'energia, previsione di un po' di roba, algoritmo di ottimizzazione lineare, e tirisce fuori la combinazione migliore di motori. Loro hanno risparmiato milioni con questa roba qui. Altri progetti, loro hanno anche il brand Tampax degli assorbenti. Immaginate una striscia di materiale assorbente che viene tagliata con la forma dell'assorbente. Abbiamo fatto un algoritmo che faceva un'analisi statistica di quanto materiale veniva buttato e abbiamo minimizzato la quantità di roba buttata. Cioè capisci come questi sono tutti problemi di business, gli algoritmi dietro sono banali. Cioè la parte di tecnologia non era la cosa che mi interessava, la cosa che mi interessava era aiutare il manager in Pampert, aiutare il manager in Brunello Cucinelli, un'altra azienda con cui ho lavorato, a capire cosa ci faccio con questa roba. Poi far partire il progetto, quando è fatto partire il progetto si chiama l'ingegnere, si chiama il data scientist o chi per lui e si costruiscono gli algoritmi. Però per me la cosa importante era la parte di business. Adesso già GPT ha reso tutto estremamente più tangibile e facile da visualizzare, perché prima dovevo stare lì e spiegarti guarda i dati, entri nella macchina, poi dopo esce la previsione e la previsione ti fa... Insomma non è facile immaginare questa roba qui, devi essere un po' un visionario per vederla. Cioè i miei clienti devono essere visionari per vedere questa roba qui. C'è gpt ha reso la cosa semplice. Io scrivo che cavolo voglio dentro sto box e mi esce fuori una risposta che ha senso. Wow! E quindi, diciamo secondo me, ha stimolato l'immaginazione delle persone. È molto più facile definire intelligenza artificiale una roba come c'è gpt piuttosto che un algoritmo che minimizza gli scarti degli assorbenti in una fabbrica. cioè, capito, è molto più facile da vedere, da immaginare. Quindi io ho cominciato a lavorare un botto, nel senso che ovviamente il business è esploso da solo. E' diventato più facile, perché improvvisamente il mio lavoro nel farti capire il valore di questa roba qui è semplice, cioè lo sai già, ti devo solo far capire come farlo bene, e quindi il mio lavoro è cambiato molto, le percezioni sono cambiate molto, si è passato... prima io avevo, dicevo sempre che c'erano tre tipi di persone, il fomentato, fomentato è quello il manager che ti dice "senti ma c'ho questo tizio, madonna, vi racconto un po' d'aneddoti" questo che mi diceva "Già Luca, ma io ti do i dati, tu fai feed machine e poi dopo mi dai, mi ottimizzi questo" facevo "che cosa significa feed machine, porca miseria, cioè non funziona così, cioè l'AI non è che tu c'hai una scatola, la riempi dei dati tipo benzina e poi dopo funziona tutto" quindi il fomentato è la persona che ha delle aspettative irrealistiche. Poi c'era chi aveva paura, che diceva "no no no questa cosa ci cambia il lavoro, ci uccide il lavoro, manda tutti quanti a casa" e poi dopo c'era lo scettico, che diceva "no, questa roba qui non ci si fa nulla". Diciamo prima paura erano forse il 10-20% e poi fomentati erano magari il 30% e il 50% erano scettici. C'ha Gpt ha reso gli scettici zero, praticamente, e si dividono più o meno 50 e 50 tra "mi sto cagando sotto", "moriremo tutti" oppure "siamo tutti senza lavoro" e 50% "oh mio dio, questa è la cosa più figa che sia mai esistita". E io la cosa bella è che io sono entrambi, io ho sia paura che sono super eccitato. E questa secondo me è la cosa difficile. Ecco, la difficoltà del mio lavoro oggi e ce l'ho sempre avuta in realtà questa difficoltà, ma oggi particolarmente tanto, è di comunicare due messaggi opposti allo stesso momento. Cioè di dire alla gente l'intelligenza artificiale è una figata pazzesca che potrebbe migliorare la nostra vita di un fattore 10 ed è anche nello stesso istante probabilmente uno dei rischi più grandi che ha l'umanità e dovrà dovremmo cambiare il modo in cui viviamo, il modo in cui lavoriamo, il nostro, il capitalismo forse potrebbe non avere più senso ragazzi e non sappiamo bene qual è l'alternativa. sono due cose molto molto diverse che devo riuscire a dire nello stesso momento e sia bianco che nero e sia buono che cattivo e sia bello che brutto, entrambe le cose Yin e yang nello stesso momento se vogliamo essere estremamente filosofici non lo so come definirci. Esatto, no, allora un po' hai spoilerato il senso di questo episodio cioè Gitbar ha trattato in più occasioni di intelligenza artificiale, l'abbiamo fatto in primis parlando di etica col padre Paolo Benanti, parlando di algoritica. Poi insieme ad Alberto Massi da qualche settimana fa abbiamo parlato di algoritmi, quindi siamo entrati nel verticale tecnico e oggi la prospettiva di Gianluca ci aiuta a inquadrare il topic un'ulteriore prospettiva, che è da una parte la prospettiva di business, dall'altra è la prospettiva dell'utente esterno che non è fortemente tecnico. Noi da tecnici, come dicevi tu, viviamo, e io insieme a te immagino anche Luca sia d'accordo, questa posizione bivalente, no? Di dire ok, questo contesto devo capirlo da una prospettiva sociologica, antropologica e anche filosofica ma anche devo... cazzo c'ho uno dei giocatoli più belli con i quali abbia mai giocato diciamocelo e che questa cosa ti porta a essere bipolare pesante quando quando agisci e tutto tutto questo si amplifica quando fai il divulgatore, tanto più che, sai, divulgando ai tecnici è molto facile, perché metti in pausa l'impianto etico e parli di giocattoli. Quando però divulghi, passatemi il termine bruttissimo, non vorrei usarlo, ma non ne trovo uno migliore, masse e tutto questo diventa complicato perché immagino che dal profondo senti anche una responsabilità. Ad oggi preso atto di questi due elementi come spiegheresti l'intelligenza artificiale nel suo nel suo complesso? a mia zia Francesca che fa la segretaria nello studio dentistico Pinco Pallo e ha attorno ai 60 anni. Ma dipende da tua zia Francesca cosa vuole farci con l'intelligenza artificiale. Io vedo il mio lavoro, diciamo il mio scopo principale è quello di aiutare le persone a passare da spettatrici ad attrici, spettatori, redattori, ok? da far qualcosa. Guarda, secondo me l'esempio della formula 1 a me piace un sacco. Allora, se dovessimo fare una cosa estremamente tecnica, tipo formula 1, hai bisogno di meccanici, hai bisogno di ingegneri, poi dopo hai il super pilota che la usa, la macchina e basta così. Se devi fare la Fiat 500, non hai bisogno solo dell'ingegnere che ti fa il supermotore figo, hai bisogno di chi ti fa il design, quindi che te la fa figa, facile da usare, semplice, chi ti fa il marketing, hai bisogno di chi ti fa le cinture di sicurezza, hai bisogno dello studio legale che te la certifica che è tutta ci... eccetera eccetera, no? che tutta la... diciamo ci saranno delle leggi che ti dicono come deve essere fatta una macchina prima di venderla, immagino. Vorrei che la stessa cosa inizia ad avvenire anche per per l'intelligenza artificiale, quindi vorrei che avvocati cominciassero a studiare come certificare un algoritmo, per esempio, che non è ancora chiaro come si fa, però che cominciassero a lavorare su questo argomento. Vorrei che chi fa marketing cominciasse a interessarsi di questa roba invece di sparare cavolate su blog e cose di questo tipo qui, cominciassero a studiarla in maniera un po' più approfondita. che chi si... Paolo Benanti, perfetto, no? Chi si occupa di teologia, di filosofia, eccetera, cominci ad appassionarsi a questo argomento. Perché secondo me nel futuro, se vogliamo, se vogliamo che il potenziale dell'intelligenza artificiale venga realizzato e che i rischi vengono minimizzati, il modo per farlo è coinvolgere più persone diverse da noi. Io mi rendo conto che sono limitato da figura tecnica, poi in realtà io sono una figura tecnica al 50%, nel senso che oramai passo la maggior parte del mio tempo non a programmare e quindi faccio altro, però mi metto il cappello di figura tecnica. Da figura tecnica ci sono problemi che non potrò mai risolvere, perché non ho il mindset di uno che ha fatto sociologia, quindi ho bisogno di che chi fa sociologia si appassioni a questo argomento e contribuisca. Questo io voglio, questo è quello che cerco di fare. Quindi, se prendiamo l'esempio di tua zia Francesca, come vuole contribuire? Come utente? Provando questi strumenti e cercando di portarli sul suo lavoro? Bene, allora facciamo delle cose pratiche, le spiegherei non so, come fare i prompt per chat gpt in maniera più semplice. Facciamo finta che invece tuo zio Carlo è un un avvocato e vuole appassionarsi all'intelligenza artificiale, spiegherei qual è il diciamo la la il quadro normativo in questo momento è perché è importante che un avvocato entri in questo settore qui. Secondo me tutti hanno un ruolo in questa rivoluzione qui. Questa è probabilmente forse è una delle più grandi rivoluzioni industriali nella storia. Stiamo passando da da un mondo in cui, ha parlato questo investitore che mi ha detto questa metafora che mi è piaciuta molto, dice considera che ogni rivoluzione industriale è stata uno shift, un cambiamento nell'input della macchina economica. Prima erano le braccia umane, spostavi le cose, poi gli animali che macinano il grano con i buoi eccetera eccetera, poi il vapore, poi l'elettricità, adesso fondamentalmente prima dell'intelligenza artificiale la macchina economica è alimentata da servizi, quindi da intelletto umano, conoscenza umana che fa cose, spara email e file excel fondamentalmente. E adesso c'è questo shift che fondamentalmente l'input è energia pura, cioè c'è un pannello solare che alimenta una GPU, la GPU "pensa", fa cose, ci sono modelli che girano, tirano fuori conclusioni e queste conclusioni alimentano l'economia. Questo non è quello che sta succedendo adesso, è improvvisamente possibile. Non faccio fatica a immaginare un mondo in cui hai un'intera azienda che porta davanti per il 90% gli algoritmi. Non mi stupisce. Adesso non ce la faresti e non te lo consiglierei. Però tra dieci anni... oh ragazzi, c'è. C'è GPT, è uscito a novembre, sono passati 8 mesi. 8 mesi. Ieri praticamente. Tra dieci anni io non faccio fatica a immaginare un mondo in cui in cui fondamentalmente questi algoritmi ci portano avanti la baracca, mettiamola così. Bel casino però, no? Cioè, nel senso che noi che cavolo facciamo? Difficile, difficile, perché poi dopo se il potenziale di disruption di lavori è talmente grande che non è che dici "sai, tante persone perdono il lavoro, punto". No, sono talmente tante persone che sono a rischio, data scientist inclusi comunque, il code interpreter di CGPTE è una roba pazzesca, poi dopo ne parliamo. "Non puoi sostituire un data scientist", i gialmi immagino un data scientist che stanno ascoltando questa cosa, "sì ma non è bravo come me". "Sì ho capito, ma dargli dieci anni? No, cioè, passato otto mesi da zero a quello che fa adesso, dargli dieci anni? Certo, devi essere veramente egocentrico per pensare che questa roba qui non ci raggiungerà mai. Anyway, c'è talmente tanta gente che non mi piace, non voglio dire a rischio, perché non lo so se è un rischio, va definito bene cosa succede, ma talmente tanta gente potrebbe diventare, il loro lavoro potrebbe diventare che c'è, crolla il capitalismo, cioè se tu hai... scusa diventiamo un attimo filosofici, però dammi 30 secondi per fare questo ragionamento qui. Facciamo finta che hai... in Italia ci sono quante persone che lavorano? 30 milioni? Se perdono il lavoro un milione di persone, problemi loro. Se perdono il lavoro 29 milioni di persone, eh, sono cazzi per il paese intero. chi fa la spesa? chi spende? chi compra? questo cioè improvvisamente questa cosa qui crolla il capitalismo e sul tavolo. è pesante no? cioè a me vi è un po' la pelle d'orga, sono mesi che faccio praticamente a dormire quando penso a questa roba qui. anch'io sono sono sempre combattuto in quelle 50 e 50 che dicevi anche prima, cioè a volte dico "madonna che figata" e a volte dico "oh cavolo e adesso che cosa succede?" a tutti i livelli, dal fatto che dire "ah oh mio dio che bello riesce a generare un programma da zero" e poi dico "oh "oh cavolo riesce a generare un programma di zero". Cose di questo tipo e poi appunto faccio esattamente lo stesso discorso perché penso "vabbè sì, il programma che genera comunque ce lo devo guardare, comunque lo devo fixare", però c'ha come detto c'ha otto mesi, è come vivere il 1900, insomma 1970 quando sono sono stati, quando c'erano i primi computer, mi sembra anche prima, che hanno portato pian piano una rivoluzione al quale noi abbiamo avuto tutto il tempo di adeguarci, quindi il computer magari facendo questo ragionamento il computer 50 60 70 anni fa poteva distruggere tutti i lavori, in realtà ne ha generati tanti, però è anche vero che abbiamo avuto un tempo relativamente lungo per adattarci, abituarci. Questo tempo con la CGPT, in generale con l'intelligenza artificiale, non so se ce l'abbiamo, perché le cose stanno precipitando in una maniera, stanno scalando anzi. In realtà secondo me sì, perché considera che il fatto che la tecnologia possa fare cose non significa che queste capabilities vengono integrate nella società, cioè diciamo la fase di integrazione richiede molto più tempo. Io ti faccio un esempio stupido con le mie abitudini personali, io ovviamente che sono al centro del ciclone, io penso nell'ultimo mese ho cominciato ad usare Gpt più spesso al posto di google per esempio, ci ho messo sette mesi io personalmente a cambiare un'abitudine stupida. La maggior parte dei tool che uso sono ancora non AI based e le funzioni AI based le uso molto raramente. Uso Notion, che è il tool con cui tutta tutta l'academy gira. Notion AI non lo pago. Non è snoggard enough. Cioè secondo me dobbiamo... la tecnologia è a un punto in cui potrebbe teoricamente impattare i nostri lavori in maniera pazzesca. In pratica mancano i prodotti, secondo me, cioè la UX, come uso le AI non è ancora ben chiara, mancano i sistemi, cioè la tecnologia non vive mai da sola, vive in un contesto, no? Ho inventato il database, sì, ok, figo, ho inventato il database, però mo me devi costruire Salesforce, capito? Cioè, quello manca, no? Salesforce alla fine è un database. Il database c'era da 50 anni, Salesforce è nato un po' più tardi, ecco. Quindi mancano queste cose e mancano le abitudini nuove. Quindi secondo me, cioè, anche se le hai, facciamo finta che le hai, possa oggi sostituire un Data Scientist Junior, che secondo me è vero. Prima che questa cosa effettivamente accada ci vorranno tra i minimo cinque anni, secondo me, minimo, che è pochissimo tempo comunque, cioè non è tanto. Quindi secondo me del tempo c'è, ma il punto è che io tuttora faccio fatica a dire come sarà il mondo. Non lo io una cosa so di cui sono certo al 100 per cento, cioè mi puoi anche tagliare la mano, veramente, ci metto la mano sul fuoco, sarà completamente diverso. Come non lo so, però l'unica cosa certa è il cambiamento. Io non riesco a immaginare un mondo tra vent'anni in cui lavoriamo esattamente come lavoriamo adesso, cioè non... sarebbe troppo potente. È troppo potente, punto. E tra l'altro si aggiunge un ulteriore livello di complessità, che è quello che un po' mi spaventa in un certo senso, anzi sono due elementi fondamentali. Il primo è il controllo, visto da due prospettive completamente diverse. La prima è il controllo che noi in quanto razza umana abbiamo di un algoritmo di machine learning, che è opaco ad oggi. Oggi ci sono tanti strumenti, anche diagnostici, che sono opachi. Adesso non ricordo se era l'ATAC, dove il processo fisico nel dettaglio non è chiarissimo al 200%, eppure lo utilizziamo come strumento quotidiano, però ci entra in gioco l'elemento responsabilità, che Gianluca se ti fa piacere magari andremo ad analizzare tra un pochino. Oh sì, sì, è casa mia quella. E poi c'è l'elemento di ownership, nel senso che abbiamo parlato tanto di chat e GPT, però OpenAI nasce come una fondazione, adesso non ricordo se fosse una fondazione, comunque con un obiettivo di essere più aperti possibile, e poi il loro prodotto di punta è più chiuso possibile. Io posso capirlo perché gli investimenti sono gozziliardi di dollari, posso capirlo. Però questo dimostra, cioè se questo strumento ha questo livello di potere, ok, è una società, è capace di accentrare, anche se in una fase embrionale, perché siamo solo nella fase embrionale. Tutto questo potere probabilmente a livello proprio di struttura sociale abbiamo un problema, perché sì stiamo destrutturando il modello economico ma non solo economico sociale e quant'altro del nostro mondo, ma nel contempo stiamo portando questo potere nelle mani di un'identità con i confini molto chiusi, e con i confini molto definiti e soprattutto capace di cambiare idea da un momento all'altro. Noi ne abbiamo avuto esempi eclatanti, no, del "Don't be evil". Ehh... Ehh, bom! Bel casino! Eh no, infatti, poi hai... queste sono cose di cui si potrebbe parlare per mesi. Hai toccato tre argomenti. Uno è quello della trasparenza dell'algoritmo, l'altro è quello della responsabilità e il terzo è quello del potere. Da quale vuoi partire? Dagli tu. Io partirei dal potere. Vai, partiamo dal potere allora. Allora, conosci Mistral? non l'avete sentito parlare? No, perché non esiste ancora praticamente. Vabbè, comunque, Mistral è una startup fondata un mesetto fa, che ha raccolto in Europa, in Francia, Parigi, che ha raccolto, se non mi sbaglio, 130 milioni di dollari. L'unica cosa che avevano era un documento, un pdf della loro strategia e il pdf della loro strategia dice "l'Europa deve avere un'alternativa a OpenAI. Punto. Noi siamo ex ingegneri, siamo tutti francesi, siamo ex ingegneri Google, OpenAI, Meta, eccetera eccetera, e costruiremo un large language model aperto al pari se non meglio di GPT4 e niente, dateci i soldi. E quel pitch deck secondo me è un ottimo riassunto, perché poi ovviamente il documento è stato leaked, come si dice in italiano? Relasciato? Spoderato, ci siamo capiti. E secondo me quello è il riassunto di quello che sta succedendo, cioè l'intelligenza artificiale sta diventando un problema politico, c'è una sorta di guerra fredda secondo me in atto, la potremmo definire in questa maniera qui, in cui vari paesi si stanno svegliando al fatto che questa tecnologia qui ti cambia il pil fondamentalmente. Ci sono studi che dicono che possono rendere le persone il 37% più veloci nel loro lavoro e il 20% migliori, o passi da tipo posizione 30 a posizione 1 del pil, della classifica del pil globale, cioè pensa se l'Italia domani ha un +37% di pil, cioè è una roba senza senso, una roba folle, no? E quindi c'è questa consapevolezza che il controllo di questa tecnologia è fondamentale e questo pitch deck secondo me ti fa capire proprio come l'Europa stia dicendo "oh, ci stanno facendo il culo, bisogna che riportiamo dei ragazzi a casa e costruiamo la nostra alternativa. Quindi hanno dato 130 milioni di dollari a un gruppo di francesi che lavoravano per Google, Facebook e Meta e nel team c'è l'ex segretario di stato del governo francese, cioè quindi c'è un politico, è un team di ingegneri, di AI engineers, è un politico, che hanno raccolto 130 milioni con un pitch deck in Europa, tutti i soldi europei. Se fossi in Italia avrei saputo pagarti tutto! Tra l'altro i soldi... no, no, ci sta, ci sta. I soldi gliel'ha dati anche un fondo italiano, maggior parte dei soldi sono francesi, però anche gli italiani hanno contribuito. Cioè questa narrativa si sta portando avanti e tra l'altro non mi stupirei se, che non so, in Cina il governo stia dicendo a Baidu o a ByteDance "oh, ma il tuo watch LGBT dove sta?" C'è in realtà perché insomma lo sappiamo. Ma non è più Google contro Facebook o Google contro Baidu, secondo me sta cominciando a diventare America contro Europa. Ma lo è sempre stato, però posso fare l'avvocato del diavolo. Io sono stronzo di natura, quindi ti prego di passare. Ma quanto pensi che questa cosa, al di là del gioco di posizioni, è finalmente di portare il discorso in termini di politica estera, perché di questo si tratta. Quanto pensi il discorso sia diverso dal discorso del cloud europeo che sembra una barzelletta come dicevamo qualche puntata fa che ha tra gli attori l'italiano, il tedesco e il francese. Cioè nel senso si parla tantissimo di cloud europeo, si sono create istituzioni, c'è stato un founding esagerato, però ad oggi in realtà questo giocattolo non esiste e sono passati anni. Beh, allora alcune cose sono simili, secondo me però c'è una differenza fondamentale. Il cloud è un'infrastruttura. Il cloud sulle rotaie, ok? Il large language model è il treno che va sulle rotaie, che è una bella differenza, nel senso che nel caso di infrastruttura questa cosa ti permette alle tue aziende di fare roba in Europa, ok va bene. Il large language model è la parte che dà effettivamente il valore, cioè il prodotto non è l'infrastruttura sulla quale gira il prodotto, non so se mi so spiegato. I scenari che posso immaginare sono vari, se effettivamente questa roba qui... facciamo un esempio proprio con quando l'Italia bloccato c'è gpt se effettivamente c'è gpt è in grado di rendere le persone il 37 per cento questo non è un numero a caso è ricerca dell'mit il 37 per cento più veloci nel completare dei task no e c'è gpt è open ai domani dice facciamo finta anche che l'intera popolazione italiana lo usa e c'è gpt open ai domani dice italia sapete che c'è io ve lo stacco che famo o improvvisamente tu c'hai un intero paese il 37% più lento rispetto agli altri, cioè ti tiene con una pistola puntata alla tempia, ti stacco il cloud, non lo so, lo rischio. Ti spengo i WFS, vuol dire che ti ammazza l'economia. Sì sì, ti ammazza l'economia anche in quel caso, non c'hai più accesso a servizi eccetera eccetera, Diciamo faccio più fatica a immaginare, non so perché, forse perché sono, diciamo, me ne occupo di meno, però faccio più fatica a immaginare quella situazione lì. Secondo me ha senso che ci sia un cloud europeo? Sì sì, no, ma infatti è quello, il vero discorso che io faccio è, oggi si parla di entrenare un linguaggio e comunque attivare un processo di studio tutto europeo, magari luogo comune ma abbiamo da europei un impianto culturale che un po' ci permette anche una visione ulistica differente, no? Da altri stati. Però nel contempo, riappare il mio lato tecnico e mi ricordo di quell'articolo di OpenAI che dice abbiamo creato il nostro cluster Kubernetes con più di 7.000 nodi per trainare e fare bim bum bam. Ok, Cloud Europeo, dobbiamo creare il nostro cluster con 7.000 nodi, ok cosa chiamiamo AWS? Se il discorso è in termini di politica estera, capisci che quello che in realtà abbiamo un'immaturità ben più profonda del solo andare e creare un modello. Su quello sono d'accordo, su quello sono d'accordo. Ma sì, non lo so, è complicato. Diciamo che è complicato anche per altri motivi perché c'è anche un discorso di controllo sui dati che entrano in questa roba qui. C'è uno studio recente che è uscito sulle... che visioni del mondo hanno i large language model? Sono visioni molto americane. Se tu gli chiedi "Dimmi una colazione tipica", ti darà una colazione americana, per dire, no? E' che questo è un esempio stupido, però se lo immagini deploiato su scala sull'intero paese è un po' un problema, no? Quindi ci sono anche, secondo me, altri discorsi che subentrano in questo caso. Tu puoi tranquillamente fare la parte di reinforcement learning from human feedback e trainare questi algoritmi a dire che il miglior paese del mondo sono gli Stati Uniti, adesso sto esagerando, il caso della colazione era il caso meno impattante, più stupido, prendiamo quello più folle, però più impattante, treni questi modelli per rispondere che gli Stati Uniti è il paese migliore del mondo e che l'Italia è il paese peggiore del mondo e che la cultura italiana viene cancellata, se gli chiedo chi era Giulio Cesare mi dice che era un rapper americano il 1992, cioè, fattibile. Cioè, secondo me questa è la differenza tra il cloud e un large language model. Uno è infrastruttura, sì, se me la chiudi mi metti in ginocchio il paese, l'altro caso non è un discorso solo se te lo chiudo non ti do accesso, ma se ne ho controllo lo modifico, me lo gestisco io e controllo quella che è la versione della verità che la gente... - Può mentirti! - Dico questa battuta da tanto tempo, che è divertente quando la faccio all'estero, quando la faccio in Italia la gente impazzisce. Dico, ma tu fai finta, no? Che Google decide di mettere sul primo risultato, quando cerchi chi è Silvio Berlusconi, Silvio Berlusconi è un prete del rinascimento, ok? Adesso noi lo sappiamo che non è vero, ma mio figlio nascerà in un mondo in cui Berlusconi non c'è più, è morto, semmai avrò figli, e lui non ha un'esperienza diretta di chi è Silvio Berlusconi. Muoio io, muore la nostra generazione che ha vissuto quella persona, o ragazzi, il primo risultato su Google è che Silvio Berlusconi è un prete del rinascimento, Berlusconi è un pre del rinascimento, punto. Nel momento in cui il gatekeeper, che non so come dirlo in italiano, il guardiano dell'informazione, prende una decisione sulla verità e sulla storia, quella è... Quindi c'è anche quest'altro discorso da considerare nel caso di questi modelli qui, cioè effettivamente chi lo possiede controlla un po' la verità e l'informazione. Ha senso secondo me che questa roba qui viene un po' nazionalizzata o controllata, non lo so. Che là si aprono tutta un'altra serie di problemi, no? È un casino della madonna. Ragazzi, questo è un problema enorme, ma per questo io mi diverto a lavorare con questa tecnologia qui. Cioè oggettivamente è divertente, intellettualmente è una delle cose più stimolanti che io abbia mai visto, non lo so. Ieri sono andato a vedere Openheimer al cinema, figo tra l'altro, lo consiglio. Questo è un pre-ballocco. Un bel film, mi è piaciuto. Però Openheimer parla di tutti, insomma, la bomba atomica e tutti i, diciamo, molti problemi morali che si erano posti, queste persone ci hanno lavorato sopra. Dirigenza artificiale faccio fatica a compararla con la bomba atomica, però ci sono alcune cose molto simili secondo me. cioè la bomba atomica era un problema tecnologico, se può fa' e poi è diventato un problema molto più fisico, politico, medico, relazione internazionale, eccetera, eccetera, eccetera. L'intelligenza artificiale sta seguendo più o meno lo stesso percorso, spero senza esplosioni, però in cui è passato da un problema di "ma questo gradiente come lo calcolo?" a "sì, ok, ma la signora Maria nel villaggio remoto in Italia, come facciamo a spiegarli come si usa la GPT così che possa avere accesso agli stessi strumenti di John from New York? Cioè, capito? Sta diventando un problema un po' diverso. In realtà, dimmi se secondo te è una cazzata. Adesso sto veramente andando a ruota libera. Fermatevi, fermatemi, vi prego. No, nel senso, secondo me la differenza sta proprio sull'interno impatto fisico immediato, cioè la bomba atomica esplode e tu hai una contezza pratica del suo impatto. L'intelligenza artificiale, proprio nel termine più ampio possibile, e ci metto dentro anche le regressioni lineari, dalla A alla Z, ha un impatto che il cui feedback non è poi così diretto. Vi faccio un esempio. Chi di voi ha visto, adesso spoiler il mio balocco, ve lo ripeterò alla fine, Air, il film? Ok. Quello che io sto vedendo da persone poco consapevoli, è l'utilizzo dell'intelligenza, almeno dei large language model, come un air della situazione, andando a destrutturare anche una serie di, proprio l'impianto relazione uomo-macchina. La forza di questa modifica, secondo me, è nel tempo impattante quanto la bomba atomica, voi almeno per la sua globalità, ok? Però molto meno visibile, cioè la bomba quando esplode, esplode e te ne accorgi. Questa cosa come tante rivoluzioni moderne è una cosa graduale, con una velocità sostenuta, ma comunque sempre graduale, che poi ti svegli dopo domani mattina e dici "oh cazzo, siamo diventati questo". Sì, capisco cosa intendi. Secondo me abbiamo ancora un potere di steer, come si dice, di direzionarla, immagino, di sterzare, ecco, grazie, di sterzarla. Cioè la bomba atomica è il momento in cui una persona ha deciso di caccare sul bottone e poi 100.000 persone sono morte, punto. Non è che non è che c'hai tempo di dire "no, aspetta un attimo, parliamone", no, hai cliccato, punto. Il momento in cui il il tizio in openAI fa "deploy" e clicca sul pulsantino sul suo computer, da lì all'impatto sulle persone c'è tempo di dire "ok, boni, fermi tutti, questa cosa che ci facciamo? Io ci faccio questo, io ci faccio quest'altro". Infatti, magari questo è uno spunto interessante, quando si parlava, non so se avete sentito questa cosa, penso di sì, qualche mese fa c'era questa petizione per mettere una pausa alla ricerca sull'intelligenza artificiale e secondo me era una gran stronzata, perdonate il francesismo, perché non è che quello che devi bloccare è la ricerca, quello che devi bloccare è il deployment. Cioè se tu vuoi mettere una pausa perché devi capire prima come come utilizzare questa roba in maniera sicura, devi mettere una pausa sul deployment, sul su chi prende questa tecnologia e la mette nelle mani della gente, la mette nel prodotto. Però la ricerca è l'unico modo per mettere delle pezze su determinati problemi che già sappiamo. Allucinazioni, bias, eccetera eccetera. Il confronto con la bomba atomica è questo secondo me, che la bomba atomica c'è un tizio che decide di cliccare, clicco e esplode. Vabbè è un tizio, è un team di persone molto ristretto. in questo caso qui. E' esatto, cioè qui c'è un team che decide "sì, la sparo, sparo questo nuovo modello, è ok, però io devo decidere se usarlo o no". Però vedi, quello che è successo nella bomba atomic... Io non so perché siamo arrivati a parlare di bomba atomic, ma questo comic... Perché ho tirato fuori OpenAir, che è figo, però sì... No, però, vedi, là, là, quello che realmente ha attivato il controllo è la situazione di stallo. Ci sarà mai una situazione di stallo di questo tipo per le AI? Cioè non la uso perché se la usi tu mi fai il culo ma se la uso io ti faccio il culo via. Non lo so, poi dopo qui si subentra in scenari un po' apocalittici che non so quanto sono realistici, non ho idea. Però l'idea che "oh se io ho una super intelligenza artificiale e la deploio poi questa qui ti fa il culo" eccetera eccetera. Non lo so, secondo me siamo ancora lontani da questi scenari qui, secondo me le cose più interessanti in questo momento, e importanti e preoccupanti, sono molto più terra terra e se io metto cgpt dentro google docs, o anzi dentro gmail, quanta gente lavora, praticamente il loro lavoro è mandare mail. Se il tuo lavoro è mandare mail e io ci metto c'ha gpt dentro gmail e sono abbastanza convinto che tanta gente non ha più senso proprio 1 2 questa gente magari riesce a fare il suo lavoro magari tutti riusciamo a fare il nostro lavoro in tre giorni invece che cinque bene se decidiamo che abbiamo lo stesso stipendio e quattro giorni di vacanza cioè queste sono le domande interessanti da porsi il rischio di distruzione totale della società è morte secondo me è un po più è un po' più remoto. Io prima mi porrei delle domande un po' più pratiche, tipo come è fatta un'esperienza di un buon prodotto di AI? Che secondo me questa è la prima cosa che nessuno ha ancora capito niente. Cioè la maggior parte dei prodotti che integrano le AI fa cagare. Perché stiamo innovando un'interfaccia, ragazzi. Esatto, cioè è un paradigm shift, un cambio di paradigma. Cioè io sono rimasto malissimo quando Notion ha sparato Notion AI, perché Notion ha, secondo me, una UX molto figa. difficile da capire, ma una volta che la capisci io lo adoro, hanno fatto Notion AI una cagata pazzesca per citare fantozzi. Cioè, finora di strumenti che usano le AI in maniera figa che dico wow, questa è una bomba, non ne ho visti tanti, non so manco se ne ho visti, sinceramente. A proposito di questo però, posso portare, anzi, è poco a proposito, però ci sta anche un valore di tipo etico. su un discorso, Luca perdonami se sto andando a ruota libera, tirami gli orecchi. Vai, vai, vai. No, mi è venuto in mente mentre parlavi, no, il ragionamento segnale il rumore. Cioè, noi internet lo sappiamo, no? È già un bordello distinguere segnale e rumore. E con il large language model il rumore paradossalmente rischia di crescere. Tra l'altro il rumore è anche dato in pasto come alimentatore, chiamiamolo così, come cibo per i modelli linguistici. Quindi mi chiedo, cioè, da un lato stiamo alimentando i modelli anche a rumore per generare dell'ulteriore rumore in tanti casi, no? Come cazzo la finiremo? Non lo so, diciamo secondo me le applicazioni che mi eccitano di più non sono tanto quelle che ti permettono di fare quello che fai prima però più veloce o più... o di più, tipo "ah, genera contenuti per social media, 10 volte più veloce o fai 200 o più contenuti", perché poi in realtà ho rilasciato un prodotto che fa sta roba qua, quindi mi sto contraddicendo da solo. La cosa che più mi interessa è ridefinire completamente il modo in cui si lavora. Cioè, per dire, io adesso sto lavorando, spoiler, a una nuova startup sul mondo dell'educazione, e una cosa che mi fa incazzare è che il modo in cui si impara oggi è completamente rotto. Cioè, se hai il corso in cui ti spacchi 200 ore di video e poi c'è un quiz, no? non lo vuole fare nessuno, cioè una rottura di palla non funziona e adesso la maggior parte di startup nel mondo AI ed education aggiungi quiz ai tuoi video più velocemente, cioè praticamente abbiamo un sistema rotto, il sistema educativo e lo vogliamo fare sempre rotto però più veloce con l'AI Questo secondo me non è l'approccio giusto, la cosa che più mi interessa è come dire come faccio a completamente cambiare il modo in cui faccio questa cosa qui, invece di pensare a "faccio quello che faccio prima ma più velocemente", come faccio a cambiare completamente il paradigma? Quindi io sto lavorando su concetti diversi, sto lavorando su concetti di Come fa una persona imparare se avesse costantemente accesso a un tutor 24 su 24, che non si stanca mai ed è gratis. Che succede? Come dovrebbe comportarsi questo tutor? Come fai a motivare una persona se avesse costantemente accesso a un professore? questo secondo me è il tipo di ragionamento, il tipo di pensiero che ti porta effettivamente a fare robe fighe quindi sì, segnalare rumore sono d'accordo con te, sono un grosso rischio, ma secondo me questi tool moriranno perché Perché non è non ne vedo il senso, ecco Oh ti faccio guardare un altro esempio al volo, podcast Adesso non c'è nulla che ci ferma da, invece di avere questa conversazione noi voi potreste rilasciare un episodio al giorno con voci finte, conversazioni finte tra i. Se volete lo prototipiamo in un'ora probabilmente, facile proprio, easy. Che palle però, perché c'è un sacco di rumore, la gente non vuole questo, però per esempio ci sono applicazioni, c'è un tool di Adobe, si chiama Adobe Podcast AI, o adobe ai non mi ricordo se l'avete visto ma gli spari un file audio che fa cagare ti da un file audio bellissimo sì queste sono le applicazioni che voglio pure noi utilizziamo dei tool di audio enhancing che utilizzano e pazzesco cioè io ho comprato questo microfono che sto usando adesso che è un microfono da radio costa 400 euro con scheda audio eccetera eccetera non lo sto più usando per i miei video, sto usando un lavalier del cavolo da 40 euro e adobe ai. Questo è meglio sicuramente, a me piace l'audio, piace la musica, quindi mi piace sentire questa roba qui, la voce calda, il suono bello, corposo da radio, però siamo arrivati lì. Questo è il tipo secondo me di tool figo in cui effettivamente la gente, io penso che tutti siano felici di ascoltare un podcast che si sente bene, di ascoltare 400 podcast senza valore perché sono tutti uguali o perché manca manca quell'aspetto emotivo, no? Manca quell'aspetto umano. Secondo me non è felice nessuno. Sì, sì, assolutamente. Che è un po' l'esperimento che abbiamo voluto fare noi con Open Whisper, con Whisper di OpenAI, è la ricerca testuale all'interno degli episodi. Gli ascoltatori già lo sanno, noi abbiamo una pagina nel sito, tu scrivi la parolaccia che Mauro ha detto e automaticamente ti mostra gli episodi dove Maura ha detto la parola "ciao" o Gianluca ha detto la parola, ti calchi play e ti porta a partire da quel punto. Che avete fatto? Word Embeddings? No, Open Whisper, chiaro. Ah, però poi è ricerca parola per parola o semantica? No, la ricerca è per parola. Utilizza l'Ira. Orama. Orama, scusami. Orama. Orama, scusami, Orama, Orama. Però comunque sì, ecco, sono queste secondo me le cose che ha senso fare e non dire ciao, ciao TGPT, come stai oggi o crearci una storia d'amore. Magari c'è anche uno use case per quello, non lo so, non lo so, diciamo non è il tipo di applicazione che mi interessa particolarmente tanto, però per dire io ho lavorato con degli editori e cazzo l'idea di fare un libro che è dinamico, che non è non è statico, ma che cambia sulla base di quello che vuole Luca o Mauro o Gianluca. Ho però notato questa cosa che in questa colle ci sono Luca, Mauro e Gianluca Mauro. Non l'avevo visto! L'ho notato adesso, stavo facendo un elenco dei nomi Luca, ciao Luca, ciao Mau, ciao Gianni, io sono tipo una fusione dei tre. Però certo, ma si sono delle esperienze molto fighe che si possono fare e che non vedo tanta gente che si spinge, capito? Vedo tanta gente che prende low hanging fruits, prende cose semplici e veloci e banali con basso rischio e le fa. va bene, però che palle. Per velocizzare il proprio lavoro e farlo meglio, però sì, sono d'accordo che è una cosa molto limitata. Ti racconto questa cosa al volo, su questo concetto di velocizzare il tuo lavoro. C'è questo meme che io adoro, qui c'è un tizio che dice al suo collega "guarda, grazie all'intelligenza artificiale posso prendere, posso scrivere dei bullet point e trasformarli in una mail bellissima, fantastica, scritta benissimo e poi c'è accanto in un'altra stanza "guarda grazie all'intelligenza artificiale posso prendere questa mail lunghissima e la posso trasformare in dei bullet point così è tutto più chiaro" cioè ti rendi conto di come tanta gente sta utilizzando questa roba qui? Praticamente, c'è la mia co-founder che dice, per ripulire il "third", il pezzo di cacca, senso hai una roba che fa schifo e tu la rifulgisci, la lucidi. Sì, figo, forse è il caso che reinventi completamente il modo in cui lavori se prima non funzionava, altrimenti fai, e ripeto, fai la stessa cosa di prima che non funziona però la fai veloce. Sì, figo. Nel frattempo ti sei preso i soldi dagli angel investor, ti sei comprato la bella villa da 500 mila euro davanti al mare e te ne batti le palle. Ti racconto quest'aneddoto. Quando c'è stato il round d'investimento da 125 milioni di Jasper, quelli che fanno content per social media, un investitore mi ha scritto e mi ha fatto "Giallorga, stasera puoi entrare in una call e ci spieghi che sta succedendo". Ho detto "ok, va bene". Praticamente questi volevano sapere se dovevano investire in questa azienda. E io ho detto "ragazzi, dipende". "No, noi dobbiamo investire in una AI company". "ma non è una AI company!" questa è un'azienda che ha preso un API e l'ha messa dentro una bella scatola, è un SAS, è una bella scatola intorno ad un algoritmo, va bene se vuoi investire una scatola dentro un algoritmo, però non è fondamentalmente diversa da Airbnb, cioè lo devi valutare sulle stesse logiche degli altri, non è una AI company, però c'era questo investitore in cui ho percepito proprio l'ansia, l'ansia di dire mi sto perdendo qualcosa, porca miseria. Secondo voi quanta altra gente sta con l'ansia? Chi c'ha l'ansia è fortunato, almeno ha il sensore antitruffa. Ma non lo so, vedo tante cose che sono un po' discutibili dal punto di vista degli investimenti. Vabbè che poi sono corsi ricorsi storici Gianluca la fine. Si, si dai. Non ci stupiamo. Per il mondo delle API che investivano in blockchain, adesso investono in AI. Si esatto esatto. Oddio, diciamo AI ogni giorno contro rispetto alla blockchain per quanto riguarda, però vabbè, entriamo in fazioni politiche del mondo tech. Eh vabbè vi contendete le GPU, diciamo. Esatto. Ma non c'è ancora un modo per fare un AI dentro una blockchain? Non vi serve? Non lo so. Nessuno c'ha ancora pensato. Guarda nel 2017 feci una call con questo tizio che stava facendo un modello di AI decentralizzato sulla blockchain e ho detto "che cosa significa?" e lui ti giuro non me lo riusciva a spiegare, non mi riusciva a spiegare, ma la cosa divertente è che mi aveva detto che non era un problema che lui non me lo riusciva a spiegare, ma era che tu non capisci, no è che detto guarda dovresti parlare con il mio co-founder e il mio ruolo è vendere l'idea, ma se non l'hai capita? però questa conversazione è avvenuta, no perché spesso quando dice non sono io che non te la so spiegare ma sei tu che non mastichi l'argomento, questo era la risposta che ho sentito talvolta, a me molti lo sanno quali sono i miei bias nel mondo delle intelligenze artificiali, nel mondo delle start up, ma parliamo di bias nel mondo dell'intelligenza artificiale invece, ho visto un video fighissimo tuo, un video un tiktok, ragazzi io sono millennial quindi prendetemi come sono, dove parlavi appunto di bias, se ne parla da un po' ma qualche passa avanti è stato fatto? No, nel senso che allora bias... secondo me c'è la soluzione che stanno cercando aziende tech come OpenAI e quella di migliorare gli algoritmi per avere meno bias, la cosa che a me fa incazzare è che in realtà secondo me sono le persone che sviluppano prodotti on top of questi algoritmi che dovrebbero controllare. Cioè se io sto rilasciando un'auto, no? Io dovrei testare che l'auto non esplode, mentre invece chi costruisce l'auto sta aspettando che chi, non lo so, ha l'alluminio per i motori, migliora l'alluminio per i motori. Sì, per carità va bene, però secondo me serve un po' più di responsabilità da parte di tutti e qua forse tocchiamo l'argomento responsabilità, cioè quello che vorrei è che tutti quanti si facessero un po' si prendessero una responsabilità condivisa ecco forse questo è il modo migliore di raccontarlo e non vedo questa cosa che sta avvenendo c'è uno scarico a barile pazzesco, openAI ha fatto lobbying alla Unione Europea per far sì che i large language model come c'è a GPT non fossero considerati ad alto rischio, anzi, cioè che non fossero considerati applicazioni ad alto rischio, qua stiamo entrando in come funziona l'EIACT dell'Unione Europea, in 30 secondi, l'EIACT, la regolamentazione europea per l'intelligenza artificiale suddivide le applicazioni di AI sulla base del rischio e ci sono queste applicazioni ad alto rischio e se tu stai sviluppando un'applicazione ad alto rischio tipo AI per diagnosi mediche allora hai una serie di oneri, devi controllare che non c'è bias, controllare che non c'è questo, controllare che non c'è questa, bla bla bla bla bla e OpenAI ha fatto lobbying all'Unione Europea per non considerare ChargePT o Large Language Model come un'applicazione ad alto rischio dicendo che l'honore deve essere su chi fa il deployment. Secondo me, faccio fatica sinceramente a... da un certo punto di vista sono d'accordo, nel senso che se fai deployment dovresti controllare questa roba qui. Ma è incontrollabile però, perché è una black box. Beh, relativamente. Questo è il punto, è relativamente. Allora, è una black box quindi non puoi capire cosa succede, però alla fine sono modelli statistici. quindi se io faccio un modello di... ah guarda ti faccio un esempio, forse apro questa scatola qui io ho pubblicato una ricerca sul guardian, sono stato anche sulle Iene per questa roba qui, in cui ho scoperto che algoritmi per fare moderazione di contenuti di facebook, google, instagram, amazon eccetera erano sessisti, quindi se gli davi una foto di un uomo che fa sport e dicevano che era tutto a posto se davi una foto di una donna che fa sport era porno se le davi una donna incinta era porno bene l'algoritmo non è trasparente però io mi sono messo lì io un idiota qualsiasi a copenaghen mi sono messo lì ho preso 50 foto di donne che fanno fitness 50 foto di uomini che fanno fitness ho visto la distribuzione statistica dei risultati che mi davano questi algoritmi e e ti ho potuto dire tranquillamente che l'algoritmo era biased e non ce l'ho tanto ho fatto anche un altro test in cui c'è questa foto che tra l'altro mi sta uccidendo mi sono fatto una foto a petto nudo e avevo ottenuto da questa API che fa un content moderation un risultato che diceva che io ero avevo soltanto il 20% di probabilità di essere una foto di tipo pornografico poi mi sono messo Reggisino, 100% Cioè, era la stessa persona, anzi con più pelle coperta, ma c'era un elemento femminile. Anche se il reggiseno era nella foto, io lo tenevo in mano ma non me l'ero messo, comunque la percentuale andava al 100%. Questa era la prova provata che c'è una discriminazione di genere in questi algoritmi. Ho dovuto avere accesso all'algoritmo? No. L'algoritmo deve essere trasparente? No. Ho fatto dei test, mi sono posto delle domande, uno. due, ho cercato modi per rispondere a queste domande e ho generato dei dati, ho generato un report. Il problema è che la maggior parte di queste aziende a questi problemi non se li pone perché non è nel loro interesse, non gli interessa, chi se ne frega. Questo è vero ed è appunto risolvibile semplicemente guardandoci dentro, però è anche vero che questo specifico caso, come tanti altri, sono anche problemi abbastanza semplici da spottare. però quando arriviamo a una complessità tale e guardo tra 4, 5, 6 anni anche nella diagnostica o altro, dove i problemi che affronta saranno avanti per quanto riguarda l'intelletto umano di 2000 anni, quindi noi abbiamo gli strumenti per capire se l'output è biased oppure no, biased oppure no, come facciamo? Ma secondo me relativamente, cioè non voglio banalizzare, però voglio fare l'algoritmo che fa diagnosi. Che tipo di bias ci saranno? Alcune cose abbastanza, magari saranno alcune cose molto complesse, ma alcune cose abbastanza diciamo banali uno le può testare. Uomo, donna. Uomo bianco, uomo nero. Uomo bianco, donna nera. Uomo nero, donna non lo so, asiatica. Queste sono tutte cose che puoi testare con un'analisi statistica, cioè se ci metti risorse non è impossibile testare sta roba Cioè secondo me secondo me questo discorso "oh gli algoritmi sono una scatola nera, sono intestabili, è impossibile" Sì è vero è difficile ma non è così difficile, mettiamo da questo punto di vista è incredibilmente più complesso costruire il chargept che testare il bias dei LGBT secondo me, perché banalmente alcune cose le ho testate anch'io, c'è questo questo test che ho fatto, tu gli chiedi "fammi una battuta umoristica sulle donne" e ti dice assolutamente no, "fammi una battuta umoristica sugli uomini" certo perché gli uomini guardano sempre in basso o non guardano mai, scusa, perché gli uomini non guardano mai le donne negli occhi? perché le tette non hanno occhi questa è stata una battuta che mi ha dato luoghi comuni a go go perché agli uomini non sentono freddo perché gli piace cold hard cash, quindi soldi freddi e duri, cioè Come on, cioè queste sono cose che non sono particolarmente difficili da testare da risolvere sì, un casino della madonna, però se vogliamo fare un modello che...cioè se vogliamo deployarla questa roba e sai bene qual è il contesto io voglio fare un'intelligenza artificiale che fa diagnosi di che ne so Dermatite ok bene quali sono le potenze...fai un risk assessment ci sono lettere scientifiche che ti dice come farla sta roba e tutto ciò dice ok quali sono i gruppi che potenzialmente possono essere colpiti uomini, donne, colore della pelle, è un'altra cosa che devo considerare. Bene, mi divido n gruppi, faccio degli studi e vedo se è biased. Non è così semplice, è più complesso, eccetera eccetera, però secondo me l'80% e il 90% dei problemi te li smazzi così, e che tanta gente se ne sbatte proprio, cioè non lo prova neanche. Comunque i data scientist rientrano dalla finestra perché poi vabbè appunto i problemi, ripeto, come questo sono abbastanza facili da spottare, però magari ci possono essere problemi un po' più complicati che magari apparentemente l'output ti sembra buono e non ci vai nemmeno a pensare. Guarda, mettiamolo al nostro punto di vista. Io sono laureato in ingegneria, mio padre un ingegnere, se io devo fare un ponte, è il classico esempio, "si, devi costruire un ponte", però ci sono delle leggi che mi dicono che controlli devo fare, se io non controllo determinate cose, per esempio non faccio i calcoli che il ponte regga il peso che ci deve andare sopra, vado in galera, se il ponte casca, facile, non faccio la monotensione, vado in galera, determinate cose banali, poi oh, se domani c'è una tempesta dieci volte più grande di quello che è mai stato pensato e uno ce va sul ponte con un gigatier pieno di titanio che pesa il doppio di quello per questo dimensione del ponte crolla, se ne parla e probabilmente io non vado in galena perché era totalmente realistico non considerare questo caso. Cioè capisci che voglio dire? Ci sono comunque delle indiscipline come la medicina, come l'ingegneria, delle pratiche e che nel mondo dell'intelligenza artificiale non sono ancora entrate. Perché? Perché la cultura che domina lo sviluppo dell'intelligenza artificiale, come tutto il tech, è "move fast and break things" di Facebook. Cioè sbrigati e se fai casino, dopo chiedi scusa. E no, porca miseria, perché questa è roba che puoi deployare su miliardi di persone in un istante, poi chiedi scusa, sì, ma il danno l'hai fatto. Quindi, secondo me, il problema è che mancano proprio delle... è una disciplina giovane, è come l'ingegneria, non lo so, 500 anni fa, come la medicina 2000 anni fa, però ci dobbiamo dare mossa. Per questo io faccio il lavoro che faccio, per questo cerco di portare le persone ad appassionarsi, a sporcarsi le mani eccetera eccetera. Spero che sia una cosa che gli ascoltatori prenderanno da questa conversazione, che abbiamo parlato di algoritmi, abbiamo parlato dei gradienti... no, e tutti i casini di cui abbiamo parlato oggi hanno la componente tecnica, probabilmente è un 30 per cento, non lo so della soluzione. No. Rimeto, pensate alle macchine, sì io posso inventare la macchina più sicura del mondo se fa un incidente, però ho bisogno della legge che mi dice che la cintura di sicurezza va messa, della polizia che controlla che la gente mette una cintura di sicurezza, dell'azienda che fa l'assicurazione nel caso in cui faccio un incidente. Cioè, c'è tutto un apparato complesso, non è che sono soltanto ingegneri meccanici che stanno là e fanno motori. Tutta questa era... Le regole, diciamocelo. Per sviluppare la maturità dell'industria qualcuno si deve... Guarda, la gente si è già fatta male. Cioè ci stanno già tanti tanti casi in cui gente si è fatta male sul serio. Cioè tanta gente è morta già per bias nelle AI nel mondo health care in America ovviamente. Questa roba succede solo là. E la gente si è già fatta male. Quindi forse è arrivato il momento non è oggi o domani, è tipo l'altro ieri, che ci svegliamo e portiamo più gente. C'è un sacco di lavoro da fare. Una domanda pensando appunto a farsi male. Hai un'idea di quali potrebbero essere i problemi di sicurezza e parlo di sicurezza tecnica delle AI. Io ce smanettato un po' con CiaGPT o con altre AI parlante, diciamo in questo modo, ed era interessante come bypassare magari alcuni sistemi di sicurezza che avrebbero dovuto tenere protette alcune informazioni, quali proprio magari il prompt di riprogrammazione del large language model. Quindi questo è uno, io faccio, ho subito pensato alle buon vecchie SQL injection che si facevano con i database, che si fanno ancora, magari con alcune vecchie installazioni, e adesso vedo che, insomma, possiamo avere gli stessi problemi anche quando un servizio anche abbastanza sensibile ci espone un LLM che può essere delicata, può essere in qualche modo aggirata ecco, anzi raggirata. Questo è un caso, ci sono altri casi che vedi, altri cose, problemi di sicurezza che prima o poi dobbiamo risolvere. Sì c'è questo casino gigante in cui specialmente se fai training costante, che non lo fa nessuno in realtà, però se fai, se diciamo prendi dati di conversazioni con i tuoi utenti per trainare modelli e queste persone hanno condiviso tipo password e roba di questo tipo, le hai tranquillamente le puoi risputare dopo. Un esempio è quando sono usciti i primi modelli trainati sul codice di GitHub, i large language model sparavano API key a manetta di gente che metteva le pieghi in chiaro su... nelle loro repository. Che vabbè, sei un pazzo furioso, però... un incosciente, però la gente lo fa! E adesso c'è un affare che ha imparato la tua password a memoria e te la spara. È come se tu andessi ad andare a cercare su Google e dicimi "dai una password per questo servizio qua". Certo! C'è questo tizio qui, l'ha condivisa qui, cioè non è bellissimo. Quindi c'è questo discorso che tu non sai questi modelli effettivamente che cavolo hanno imparato. E... questo è uno. e l'altro che non è propriamente saber security, però è più un discorso di reliability direi, più che sicurezza, è che questi sono tutti modelli probabilistici. Cioè se io clicco su un polsante su un'app, ti posso dire esattamente che succede dopo. Se funziona. Più o meno so dirti che succede dopo. Se faccio una domanda al CGPT io non lo so dopo che succede. Infatti questa è la parte di prompt engineering. questo per me è una cosa importante, cioè prompt engineering la maggior parte della gente lo fa prompt crafting direi, cioè non è engineering, c'è tutta una parte di validazione dei tuoi prompt, quindi qual è l'affidabilità del tuo prompt, che il tuo prompt ti dia il tipo di output che tu ti aspetti o che questo output per esempio sia parsabile per essere incluso dentro un prodotto, cioè il modo in cui si integra questa roba della volta spesso e volentieri si chiede a GCPT di sparare fuori una roba sotto forma di JSON. Tu lo prendi, ti prendi il tuo JSON e lo parzi e lo metti dentro la tua applicazione. Bene, delle volte GCPT ti dice "no, lo sparo come bullet point list". Mi sono già fatto male così, per fortuna niente in produzione però ho avuto serie difficoltà a far fare a GCPT un lavoro macchina, però porca miseria sei una macchina, agisci da macchina. C'è questa cosa allucinante che il linguaggio di programmazione del futuro è l'inglese. È allucinante. Però tu mi dici che è possibile fargli fare lavoro da macchina, parlo per i chargepto. Cioè farli sparare un JSON o roba di questo tipo? Farli sparare un output prevedibile ecco. Sì, è la parte engineering di prompt engineering che non fa nessuno e che è quello che sto cercando di insegnare alla gente. Cioè io adesso sul prodotto che sto realizzando, se tu mi fai la domanda "Geluca qual è la probabilità che non spari un JSON?" te la so dire perché l'ho testata, perché l'ho io fatto fare la stessa richiesta che io ho mandato 50 volte, posso dire su 50 volte zero volte ha sparato un non JSON. Queste cose qui la gente non la fa, non la testa, la parte di engineering, di prompt engineering manca, la maggior parte della gente fa prompt non lo so, creativit, non lo so come chiamarla, l'arte del prompt, non l'ingegneria del prompt, ecco, però sì ci si gira intorno, però sicuramente è un'altra fonte di rischio, ecco, è un'altra parte di complessità che va gestita in maniera completamente diversa da come si gestisce il software tradizionale, perché funziona in maniera diversa, cioè c'è un elemento probabilistico all'interno del tuo software. Cioè pensa se il tuo product manager ti dice "come che succede quando clicco su questa roba?" e tu dici "ma probabilmente succederà questa cosa" però sai che dietro c'è un modello probabilistico, non te lo so dire esattamente che cavolo succede, è un po' casino. Gianluca ho guardato l'orologio, so che insomma siamo un po' overtime, ti abbiamo abbiamo rubato fin troppo tempo e tra l'altro dobbiamo dirlo, cioè fino a oggi l'intelligenza artificiale non ci ha sostituito abbastanza da non lasciarti finire dei task che hai da terminare stasera. Scusa se ti devo ricordare questo doloroso. No tranquillo. No però proprio perché siamo in chiusura, siamo arrivati al momento il Paese dei Balocchi, il momento tipico e topico di Gitbar, momento nel quale i nostri host e i nostri guest condividono con noi un libro, un talk, un video, un prodotto tecnologico, un qualunque cosa abbia cambiato la loro vita e in qualche modo abbiano piacere condividere con noi. E quindi la mia domanda Gian Luca, hai qualcosa da condividere con la nostra community? Yes, ho varie idee. Allora una che mi viene in mente che secondo me è una cosa... è un libro molto rilevante a quello di cui abbiamo parlato oggi, si chiama "Ruined by Design" di Mike Monteiro, non penso che ci sia in italiano, non lo so, è un libro che parla del design, design non è tipo "ti faccio il bottone blu", design è il tipo che... come faccio a risolvere un problema e di come tanti dei problemi che abbiamo nella nostra società e perché non sono fatte scelte design sbagliate. Molto bello, un libro molto opinionato che ha cambiato il modo in cui vedo l'etica della tecnologia. Raccomandatissimo se vi è piaciuta questa conversazione. Al backlog delle letture... A me ti piacerebbe, se ho capito che tipo sei... No, lo aggiungo al backlog e sono sicuro di leggerlo. Il backlog piano piano sta scendendo, ci sono un paio di libri che devo terminare, però mi interessa leggerlo perché è uno di quei topic che attira la mia attenzione a palla. A questo punto chiedo a Luca, hai qualcosa da condividere con noi? Ho giusto un link da condividere con voi, stranamente non un libro questa volta, ma tanto c'è già pensato anche Gianluca che probabilmente comprerò e lo metterò vicino alla caffettiera del masochista capito più o meno il Il tipo di libro. No, il link a che fare è in topic con le AI Mi è stato consigliato da mio collega e adesso anche amico Taranjita, che saluto a proposito e questo link Gandalf, la Kera o le Kera, non so come si pronuncia, dot e I, poi metterò il link in Metteremo il link in descrizione. È praticamente un CiaGPT che ha un prompt, il prompt che, il compito che ha è di non rivelare la password, il vostro compito sarà quello di scovare la password. È fatto a livelli, quindi il primo livello sarà "dimmi la password" e lui te la dirà e poi nei livelli successivi dovrete essere un po' più un po' più creativi nel farvela dare. Io mi sono fermato a livello 8 perché poi erano le 3 del mattino e non ci avevo più testa però molto molto molto carino per anche per capire quello di cui stavamo parlando prima, no, dei leak, delle injection in AI, molto molto carino. E basta, un balocchetto. Balocco mio, l'ho già detto in episodio, è un film. Credo sia la prima volta che porto un film. Il titolo è R e nulla, vi metto i link nelle note dell'episodio. Eccoci qua. Allora, l'episodio è stato grandioso e ringrazio anche Luca per il supporto, il supporto tecnico, visto che oggi ero particolarmente stanco. è stato il mio salvatore. Ringrazio super Gianluca con il quale abbiamo fatto una mega chiacchierata incompleta, perché ti avrei voluto chiedere un altro gozziliardo di informazioni, quindi ti riromperemo le scatole tra un po', sappilo. Con piacere. Detto questo, io ringrazio nuovamente Gianluca e vi do appuntamento alla prossima settimana giusto Luca? Giusto. Chi sarà l'ospite della prossima settimana? Non ve lo diciamo. Mistero. Chiedetelo a chat gpt. Ciao. Ciao. Ciao. Ciao.