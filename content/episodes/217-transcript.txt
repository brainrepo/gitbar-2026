*musica* Siamo noi quelli che leggendo il codice cercano lo stronzo che ha scritto quello schifo Ma ahimè, lo stronzo è me medesimo e l'ho scritto giusto ieri *I'm sorry* Siamo quelli che santificano il nuovo framework javascript preferendo segretamente jQuery Gli stessi per il quale il testing è importante, infatti la nostra codebase ha solo due test e flakey pure Siamo noi quelli che il tuo linguaggio fa cagare, ma il mio è peggio. Quelli che la chiarezza nei comment message prima di tutto, e dentro ce l'appella tutti i santi. "Se non bestemmi o guarda" Quelli che in call parlano per 5 minuti prima di accorgersi che il mic è muto. Quelli che non si può fare di default, diventa velocemente un tutto e possibile se hai le risorse, tempo e budget illimitato. Siamo noi quelli che l'AI va regolamentata, ma hai visto questo nuovo modello che disegna gattini funambuli? Quelli che il dipende e unisci gratis la prigione. E quelli che la RAL... No vabbè, fa già ridere così. Siamo quelli che fanno lo slalom tra le specifiche che cambiano costantemente. Ormai rassegnati che la definition of ready è solo una pia illusione. Quelli che si sentano dire "ho un'idea per un'app" ed è subito l'ennesimo social come Instagram, ma meglio. Siamo noi che nonostante il deploy fallito, la CIA rossa, il business incazzato, ci troviamo al Gitbar e davanti a una birra tutto ci sembra un po' meno grave. Bene bene bene e benvenuti su Gitbar. Mamma mia appena si accende il microfono io non so cosa mi succede, mi arriva una botta di adrenalina al cervello in stile gintoneria proprio e parto a mille. Sono super carico oggi perché stiamo riregistrando una puntata, perché non è tutti i giovedì che riusciamo ad arrivare alle vostre orecchie ma questo giovedì, è giovedì e stiamo registrando alle nove e mezza, ma anche questo giovedì probabilmente riusciremo ad arrivare, se non è giovedì è venerdì mattina, abbiate pazienza, giusto il tempo di montare e di preparare l'episodio. Con me ho un amico, Luca, che piacere finalmente essere qui insieme. Luca: Ciao a tutti sì, finalmente, anche io non vedevo l'ora, potevamo fare la stream live così così eravamo puntuali invece no, tocca montare e rimontare. Sì ma non taglierò niente quindi tutto quello che vedrete è esattamente come è stato registrato quindi non vi nascondiamo niente. Prima di iniziare il nostro compito è sempre quello di ricordarvi i nostri contatti info@gitbar.it no, X non c'è, non c'è più ormai, Digital Detox abbiamo cancellato parte di Social Networks, e Luca? Rimane sempre il nostro amatissimo gruppo Telegram "Cercate Gitbar Podcast", il logo giallo con su scritto "Gitbar", siamo stabili sempre, siamo sempre lì, e siete tutti benvenuti prima a birra in omaggio virtuale se riusciamo a vederci anche dal vivo perché no. Sì speriamo di vederci il prima possibile. Topic di oggi, allora prima di presentarvi l'ospite perché abbiamo un super ospite e anche amico di Gitbar, volevo fare un piccolo cappello introduttivo, una piccola riflessione. Io non so se si è raggiunta una maturità, ma per mia esperienza ogni qualvolta si inizia a parlare, meno di topic hype driven e più di protocolli, io ho la percezione che si stia in qualche modo raggiungendo una certa maturità di un contesto o almeno ci si stia avvicinando a una certa maturità. Forse sono un po' troppo positivo su questo versante, però tutte le volte che io ho osservato una certa dinamica, parliamo di turismo, ok? Parliamo di turismo e tecnologia. Tutte le volte che ci si avvicina alla stesura di un protocollo, e qua Luca potrebbe portare la sua esperienza, vuol dire che si è fatto tutto un lavoro a priori di allineamento tra stakeholder differenti o quantomeno si va in quella direzione e questo è sintomo dal mio punto di vista di maturità. Cosa ne pensi tu Luca di questo? Assolutamente centrato, secondo me è una una buona riflessione, adesso pensando anche al turismo e agli standard, ai protocolli, quando tanti attori cominciano a fare ognuno di testa propria e al mercato va bene così fino a un certo punto e poi a un certo punto si dice "no ragazzi, qua si sta esplodendo, dobbiamo mettere ordine, dobbiamo fare un punto della situazione perché non è possibile essere tante piccole isole. Forse è quello che sta anche succedendo adesso, avevi in mente qualcosa di particolare? Sì, allora io ho visto che qualcosa si sta muovendo nel mondo delle AI e siccome io ne so una cippa, abbiamo sentito l'esigenza coinvolgere un amico di Gitbar ma anche uno degli influencer più più presenti che tratta in profondità l'argomento e infatti abbiamo con noi il nostro amico Piero Savastano, padre dello stregatto ma anche influencer del topic, opinionista sul topic. Minchia quanto sono male opinionista, però in realtà lo sei, nel senso che porti opinioni forti e punti di vista ben ancorati, quindi per noi è un super piacere averti qua con noi Piero. Piacere mio, ciao ragazzi. Abbiamo fatto un'introduzione sul concetto della maturità e protocolli, oggi parleremo di protocolli, però come lo vedi tu questo ragionamento e soprattutto come lo vedi declinato in ambito AI? I due punti sono tutti e due interessanti, sia maturità che consenso che avete entrambi che abbiamo anche ambi già esplorato un po'. Allora sulla maturità secondo me ci sta nel senso che al momento il mondo delle AI è un sacco frammentato e il consenso si è raggiunto più che altro su dei costrutti sull'API, sulle resti di AI del language model, quindi un po' di immaturità si è vista e viene dai grandi vendor che si sono un pochino imposti diciamo però effettivamente che ci portano piano piano verso definire quali sono i pezzi più importanti e poi trovare queste interoperabilità, no? Quindi la maturità si avvicina, mentre invece il consenso su questo ho un sacco di doppi pensieri, nel senso che al momento questi due protocolli di cui oggi parleremo, l'MCP, A2A, sono entrambi in realtà lanciati molto top down. e ricalcano un pochino delle strutture, dati e algoritmi che trovi nell'open source dell'intelligenza artificiale da cui dovrebbero emergere i protocolli, in teoria, in collaborazione con enti che fanno protocolli standard pubblici di ampio respiro, il V3C, l'Engineering, International engineering task force, questi qui non si stanno vedendo tanto, i protocolli vengono comunque da uno d'Antropic MCP e l'altro viene da direttamente da Google e sono entrambi molto legati a quello che stanno sviluppando come prodotto proprio a livello enterprise, quindi alcune parti di questi protocolli sono assolutamente ragionevoli perché effettivamente ricalcano quello che sta succedendo in pratica anche dei piccoli player, altre cose sono insomma così cosa quindi maturità sì con senso un po' di dubbi. Proviamo ad affrontare la la la questione dal punto di vista politico no? Perché questa cosa sta avvenendo top down come spesso avviene tra l'altro no? Sta avvenendo top down e non è difficile che avvenga o non sta avvenendo affatto bottom up perché appena parlavi mi veniva in mente Kubernetes. Kubernetes è il classico esempio di innovazione potente top down che poi ha settato uno standard ok e se io provo a pensare a un'innovazione simile ma bottom up non vedo lo standard. Quindi perché pensi che questa cosa stia avvenendo top down e non possa o abbia difficoltà ad avvenire bottom up? Un motivo sicuramente è la potenza di fuoco, nel senso non so per Kubernetes perché è è una cosa di cui capisco poco veramente, però nel caso degli agenti e dei language model, in realtà sono nate una marea di proposte bottom up, ma nessuno aveva potenza di focus sufficiente. Ci sono almeno 4-5 proposte per standardizzare le API, le REST API degli agenti web, ne ho viste di tutte, nessuna è decollata, anche se è fatta da nomi relativamente importanti nell'open, che so, Lungchain ha lanciato una proposta, per esempio, quindi io credo che sia un po' potenza di fuoco nel senso ci vuole capitale anche per spingere gli standard. Questo è interessante perché la prima cosa che viene in mente è potenza di marketing, no? Cioè tu dici quanto marketing puoi fare su una una specifica, ok? Tutte le volte noi diciamo "ah questa specifica ha preso piede perché il marketing che Google o chi per lui ha investito in quella in quella specifica, il budget che ha investito in marketing supera di gran lunga il potere comunicativo che può avere una comunità o un progetto open source", però nelle tue parole in realtà emergeva anche un altro elemento forse ancora più determinante che è proprio la potenza di fuoco globale quindi anche la potenza di sviluppo, la rapidità del time to market di una proposta, quanto tempo ci metti per fare in modo che quella proposta sia un prototipo e magari quel prototipo è già calato sul prodotto commerciale di punta. Questo non è marketing, è un'altra cosa questo è prodotto e quindi spesso quello che noi diciamo è ma la potenza di marketing di google la potenza di marketing di open ai la potenza di marketing di deep seek o antropic è più forte, non è marketing è la potenza del prodotto e la rapidità con quale con la quale queste idee arrivano nel prodotto di punta che è una potenza di prodotto bar a mercato non di marketing non so può essere può essere una banalità o una sfumatura ma secondo me è importante perché l'anchain ha un marketing importante l'anchain ha una penetrazione importante eppure quella proposta come tu ci hai detto non ha avuto lo stesso traino di tante altre per me è un buon esempio. questo è una una riflessione così sì sì guarda per prendere semmai un buon esempio è proprio la eh language model as a service. N'ha visto tutti connetti alla rest API al servizio web di Open AI? Eh devi mandare un geso in un certo formato e lui ti fa lo streaming dei token in un certo formato? Eh io credo che uno dei motivi per cui tutti è che le prime librerie, io le ho viste, erano tutte centrate su quel su quello scambio, su quella firma e soprattutto mettevano tutti le variabili d'ambiente della libreria del container con OpenAI key eccetera eccetera per cui quando poi il mondo si è reso conto che potevi fare a meno di OpenAI lo scambio di segnali è rimasto quello. Mi viene da pensare S3 di AWS. Sì molto simile concordo, si si ci sta. Luca ho visto che... Quindi semplicemente in questo caso è perché è arrivato prima non tanto la potenza di fuoco ma perché è stata la prima ad ad avere la sua libreria per far cose e poi tutti si sono adattati per dare il minimo sforzo per fare eventualmente uno switch, almeno nelle librerie di OpenAI. Eh sì, credo che sia un defatto alla fine, quindi in questo caso effettivamente magari il discorso potenza, imposizione ceder passa al discorso "siamo riati prima, l'abbiamo che è così e e amen. Mentre invece sugli agenti credo che ci sia l'aspetto prodotto che era quello che diceva che dicevamo prima perché eh sia MCP che attua sono proprio il risultato di voler standardizzare eh prodotti di massa cioè Cloud sta lavorando da ben prima ovviamente che facessero la proposta ed è un modo per fare system integration più facilmente tra gli agenti AI e gli applicativi tradizionali. Non si è capito bene perché la REST API non va bene probabilmente perché sono tutte troppo diverse tra di loro MCP dicono, loro dicono, cioè le risorse per gli agenti devono essere fatte così, scrivetecele così e l'interesse nell'aprire quel protocollo che è un'interesse che va in direzione della distribuzione di di degli oneri di questo sistema integration e quindi anche oltre all'onere anche il piacere di partecipare a un ecosistema che è basato su un protocollo aperto però l'intenzione a me sembra molto chiara cioè MCP è un protocollo che delle fa della sistema integration per l'intelligenza artificiale non so se sto però penso che proviamo a semplificarlo. Iniziamo a parlare proprio di MCP che è insomma il punto per il quale ci siamo sentiti ieri abbiamo deciso di saltare su una call. Dovendo raccontare MCP a Mauro che è veramente tonto in questo ambito, come lo disegneresti dovendo dipingere un'immagine? Certo, mi spiace se ho dato delle cose che ho scontato, allora parto da un po' prima. Language model è la rete neurale, tu gli mandi questi messaggi, questi messaggi vengono convertiti in una stringa di base che diventa un prompt e questo prompt viene passato, questa stringa di token viene passata poi alla rete neurale, ogni token è convertito in un embedding, in un array, viene fuori una matrice, la rete prende in input questa matrice e ti sputa fuori un token e poi poi il token che ha prodotto viene accodato alla matrice precedente e quello gli produce un token alla volta. Problemi? Come faccio a fargli leggere PDF? Come faccio a fargli aprire la fattura? Come faccio a fargli accendere la luce? Per cui si passa nel contesto degli agenti quando il language model da solo non ci basta più e vogliamo delle entità in cui il language model o magari anche modelli di computer vision o che che sia siano in realtà parte di un'architettura che fa altre cose, che è mescolata a quella che già conosciamo come servizio web, l'informatica tradizionale. Nasce il mondo degli agenti e in realtà già da parecchio c'è 'sta roba in open. Dentro l'anche i tool ci stavano già quando c'era già GPT. Dentro l'anche i tool ci sono da un pezzo. Che cosa sono questi tool? Se io voglio fare che il mio agente accenda la luce dentro casa, devo fargli prendere una scelta su quale comando eseguire all'interno di una lista. Quindi gli metto nel prompt, questi sono i comandi che ha a disposizione, accendi la luce, spegni la luce, regola la caldaia, eccetera, eccetera. Metto nel prompt queste cose, il language model dice, ok, usiamo il comando accendi la luce, passando magari questi argomenti, e il mio runtime, il runtime dell'agente, prende questa stringa, la parsa, trova il comando che deve eseguire, che c'ha in runtime già registrato, e lo fa partire, oppure fa la chiamata rest API o quello che sia. Questo qui è il tool. Cioè, vuol dire comunicare al language model che può eseguire un comando. Se il language model sceglie di utilizzarlo, quella è una rete neurale, produce solo token, quindi non accende la luce, però mi può dire "accendi la luce", io prendo questa stringa, dentro c'è scritto qual è il comando che devo chiamare, e lo chiamo. e questo è il tool. Quindi il mondo degli agenti è in larga parte basato su questo concetto di tool, sia se vai a vedere, insomma, le architetturine degli ultimi anni, sia quelle più nuove che ti usano il browser, no? Questi agenti che vanno in giro, che cliccano, che fanno, pure quelli sono basati su tool. Quindi il tool è diventato il centro del discorso. Infatti tutte le librerie trovi che quando dichiari l'agente, gli devi comunicare due pezzi. Uno è qual è il language model, e l'altro è quali sono i tool. E poi ci sono anche i retriever che è da dove prendere dati per fare la... la rug, insomma, per aumentare il prompt con contenuti di memoria, pdf e così, cose varie. Ora, dove entra in gioco MCP? Entra in gioco perché la pensata di Antropic è questa. Noi facciamo un client, un agente un sistema di coding che è astratto che ha un registro di tool che può utilizzare in questo caso i tools possono essere per Luca che è appassionato di domotica, questi qui su sulla gestione della luce, della caldaia, della della della tecnologia che ha in casa, mentre invece per Mauro che è appassionato di di di una serie di strumenti per hai fatto la faccia storta, infatti se puoi Però per Mauro magari c'è un altro interesse, i tool sono altri, e ognuno si può definire alla lista di tool che il suo agente può eseguire o meno, non solo. Questi tool possono stare su servizi remoti. E quindi abbandoniamo il runtime classico Python, dove hai le chiamate al language model e i tool scritti direttamente come funzioni Python, e facciamo in modo che ogni tool o ogni insieme di tool sta proprio potenzialmente da un'altra parte. E siccome non c'è un vero e proprio standard su questo, Anthropic propone MCP, Model Context Protocol, vuol dire costruiamo un protocollo per distribuire in rete i comandi che possono essere lanciati da un language model. In realtà non solo i tool, ma anche le risorse, ci sono i prompt, MCP è molto più grande di così, però ovviamente stanno tutti in fissa con i tool, perché quella lì è la cosa di più immediata utilizzo e comprensione. E la pensata è questa. Io sono Antropico, ho un client MCP. Questo client tu ci attacchi gli MCP server. Ogni MCP server è un blocco di questi tool che il mio client può decidere di eseguire, perché nel mio client c'è il language model e questo loop di scelta di tool. E questo è MCP. Non so se si può prendere da un altro punto di vista, però di base se Antropica ha l'MCP client. Oppure facciamo noi tre. Io creo un MCP client, visto che il protocollo è aperto. C'avrò un server, nel mio server comunico con il language model e ci mettiamo a collaborare insieme. Sia Luca che Mauro decidono di mettere a disposizione il loro MCP server. Luca quello sull'automotica e Mauro quello sul coding, a quel punto il mio MCP client parla con l'utente usa il language model e il language model nella scelta di tool può utilizzare i tool che sono definiti nei vostri server e lo chiamo... ah sì sì, per cui qua in realtà c'è una sfumatura che mi piacerebbe inquadrare quello che abbiamo fatto fin'oggi, fin'ora, è quello di avere un client che chiama il language model e poi è nostro compito orchestrare gli agenti che fanno cose, retrivano dei dati da qua e là, triggerano azioni e lo facevamo nel nostro client che consumava delle LM. Quello che sta succedendo qua è la stessa cosa con un protocollo di comunicazione o stiamo abilitando il provider dell'LLM a chiamare direttamente questi server? No, no sei sempre tu, sei sempre tu. Il provider dell'LLM può essere totalmente isolato e fa solo la produzione dei token. È il tuo client, è il runtime che sta nel tuo client MCP che autentica questi MCP server e decidete di lanciarli o meno. Cioè di base quella che prima era una collezione di funzioni Python, che tu menzionavi nel prompt, diventano dei veri e propri servizi web. Insomma una sorta... siete entrambi abbastanza vecchi da ricordarvi l'era dei mashup, delle applicazioni mashup quando iniziarono ad arrivare le prime API pubbliche e potevamo mettere le mappe nella nostra applicazione potevamo chiamare i servizi di Meteo per enrichare il nostro sito web con il Meteo praticamente è più o meno la stessa rivoluzione che c'è stata vent'anni fa con questa cosa che poi sono nati, no forse un po' di più, che sono nati tutti gli standard delle API. Faccio una domanda. Leggendo, e tra l'altro l'hai introdotto tu anche prima, leggendo ho notato che la comunicazione nel model context protocol avviene attraverso json rcp rpc scusatemi sono le 10 di sera e sono un po' bollito hai avuto qualche indizio del motivo per cui hanno deciso di passare per questo protocollo e non per un classico che ne so json restish api o un grcp o whatever bella domanda la prima cosa che mi sono chiesto anch'io dico ma perché è così complicato perché le remote procedure call cioè perché sta roba qualcuno dice che per motivi di performance perché effettivamente MCP è fatto per stare in connessione continua quindi volendo potete usare, che ne so, WebSocket io credo, sto dicendo un po' una cosa messa lì a caso, però è rimasto HTTP in realtà c'è pure standard input output per gli MCP server locali nel tuo computer però è rimasto HTTP un po' per lo stesso motivo per cui in cui i vendor di language model fanno tutti in HTTP. Cioè, lo streaming HTTP è stato preso in considerazione perché secondo me è molto più facile da gestire del WebSocket per il developer medio. E poi questo streaming HTTP è rimasto pure nel model context protocol probabilmente perché vogliano, appunto, una connessione che sia più o meno continua, di modo che non devi stare sempre a fare chiamate di rete senza però rinunciare alla facilità di HTTP, non lo so io ci devo bene WebSocket per cose del genere oppure un semplice HTTP con un API basato su Verbi, cioè normale REST Non lo so, questa è l'ipotesi. Qualcuno dice che è per performance, non lo so, io penso che sia un po' per aver valutato l'ecosistema e in aggiunta per voler tenere connessioni sempre aperte. Possibile, in realtà esistono dei paper sul topic. Antropica ha rilasciato dei paper sul protocollo. C'è una spec online, non credo ci siano paper, che io sappia, però non sono sicurissimo. La spec c'è, ci sono le SDK nei linguaggi, ma c'è proprio la spec proprio come standard versionata. Siamo già alla seconda versione. Possiamo buttarci un occhio ed eventualmente fare un follow up la prossima, la prossimo episodio nella chat. Domanda. MCP espone risorse, espone informazioni. Quando noi esponiamo informazioni uno dei requirement principali è quello di avere un sistema di autenticazione/autorizzazione. Onestamente immaginando un large language model consumare questo mi viene da dire che l'applicazione host debba in qualche modo di autenticarsi prima di dare in pasto i dati ma hanno formalizzato dei metodi, perché di metodi di autenticazione conosciamo un gozziliardo e quindi la domanda è esiste uno standard anche per l'autenticazione? Esiste qualcosa riguardante l'autorizzazione? che è un'altra cosa del tipo autenticazione tu sei tu e quindi ti lascio accedere autorizzazione tu puoi vedere questo quanto quanto hanno standardizzato di questo mondo? allora c'è un handshake con autorizzazione tra il client e il server e addirittura loro loro prevedono in MCP che ogni server si debba autenticare con ogni client. Infatti, quando i ragazzetti, questi qui che fanno i video su YouTube gasatissimi, fanno vedere le demo dove hanno il server MCP per usare Blender, lì sono... oppure il Google Drive, lì sono evidenti due cose per quanto riguarda. La prima è che ce l'hanno in locale, l'MCP server e pure l'MCP client. quindi non stanno usando HTTP come come transport come veicolo ma stanno usando lo standard input output e quello è il primo motivo per cui mettere MCP veramente in rete è ancora un po' complicato e l'altro aspetto è che tipicamente questi MCP server che girano ad esempio quello del Google Drive va lanciato a parte, l'MCP server ti fa autenticare con Google Dopodiché vai nel client, nel client ti connetti al server e c'è un'altra autorizzazione che devi dare al client per parlare con quello specifico server e poi dopo parti. Cioè è ancora una spaghettata. Però il protocollo lo prevede che ci sia... ma credo che molto dipenda dal fatto che molti servizi hanno ancora magari un no out e non offrono interfacce di autenticazione server machine to machine credo che per esempio il problema di google drive sia qualcosa relativo a questo nel senso che molti di questi servizi in realtà non sono pensati per essere consumati machine to machine. E quindi parte dell'essere convoluto dipende da quello e credo che questo tipo di evoluzione porterà necessariamente all'esigenza proprio di ripensare le API. Questa è una cosa interessante perché tutte le volte che noi pensiamo in API pubblica da 5 anni 10 anni a questa parte ci viene in mente l'autenticazione OAuth2 ok? OAuth2... quella pure che usa MCP usa OAuth2 addirittura mi sa che chiedono proprio in modo specifico PXI ma tra te tra l'NCP client e l'NCP server e questo ha senso yes ok però tra l'mcp server e le risorse diciamo che io mi faccio un bel mcp server che espone cazzo ne so le informazioni del sito di gitbar ma avrei potuto fare un ragga molto più semplice però facciamo che voglio complicarmi la vita ok è la mia api di spricker no spricker credo lo supporta la server... mettiamo che Spricker non supporta l'autenticazione server to server ok quindi cosa succede solitamente l'autenticazione server to server tu hai una bella chiave magari fai un handshake e ti generi una chiave temporanea da utilizzare nelle comunicazioni e poi inizi lo scambio server to server se il mio provider di API il mio google drive il mio qualunque cosa vogliate non supporta questa comunicazione server to server il mio ncp server e il provider avrà il mio ncp server scusami dovrà per forza attivare una comunicazione client like per esempio fare un out con il suo provider con il google drive della situazione e quindi credo che proprio questo problema e questa evoluzione porterà secondo me anche una maturazione in ambito api se questa cosa prenderà piede come ci aspettiamo le API inizieranno a fornire endpoint con metodi di autenticazione server to server il classico cosa ne so il token one time token il token che ti generi direttamente dall'interfaccia e mi dici io ho questo client questa nuova applicazione che si connette dammi la chiave, l'API key che posso usare per fare questo. Quindi secondo me succederà succederà qualcosa di simile vediamo vediamo un po' insomma come funzionerà. Una domanda scusate perché adesso l'ha spiegato a Mauro che ha detto che non capisce poco ma siccome capisco ancora meno, ho bisogno di un'altra spiegazione. No, volevo capire questi livelli di protocollo, operano sia a livello proprio di connessione, cioè loro stanno dicendo quindi ok usate, danno in assoluto alternative, cioè possiamo usare un sistema di messaggistica di Rabbit, oppure per forza Remote Server RPC, oppure si concentrano più sul payload, quindi sul messaggio che si deve inviare ai vari tool. Poi entrambi insomma. Si, RCP è a livello di RPC, scusa, è a livello di payload, mentre invece a livello di trasporto è tutto definiscono due tipi di trasporto uno è HTTP con lo streaming e l'altro è standard input output quindi tutto lo locale tutto direttamente nella tua definiscono anche quello ti danno delle alternative però te lo te le definiscono insomma bisogna usare queste io sappia adesso sì che io sappia, mentre invece i payload sono ultra definiti, con tanto di status code, che cosa ci deve essere in questo JSON, appunto c'è il nome della chiamata, ci sono gli argomenti. Di base i tool assomigliano un sacca a una chiamata post, mentre invece le risorse, MCP che in realtà è più pensata per prendere documenti, pezzi di test e cose varie, assomigliano alla get. Ok, il client MSP, tu hai detto allora che il client MSP, quello che tu appunto installi nella tua macchina, utilizza un LLM suo o un service da qualche parte, quindi prende in input il comando insomma della persona valuta quale tool chiamare di quelli di quelli definiti chiami il tool e il tool a loro volta utilizzano il loro LLM che però può essere un altro insomma, decidono loro quello che fanno. Ok, qua si apre un ginevraio. Allora, Se il tuo MCP server a sua volta può connettersi a un language model oppure parla con ancora altri server, perché fa anche lui da client questa matrioschia, è possibile. L'aspetto del protocollo definisce nel client, quindi dentro Anthropic, insomma dentro dove sta il language model essenzialmente, dove stanno le chiamate al language model, ci sono sono due costrutti che sono il root, che sono una specie di file system locale, poi il sampling, perché MCP prevede che il server, ad esempio il server per Google Drive, possa richiedere a sua volta al client di eseguire comandi chiamate al language model, gli altri modelli. Quindi volendo tu da client chiami il server, il server dice posso usare il language quello lì è chiamato sampling e te lo fanno usare. Ovviamente questa cosa uno non la conosce nessuno se non i malati che si sono messi a leggere il protocollo, due tantomeno l'hanno implementata. Chi è quel matto che fa il client MCP che permette ai server di usar language model? Capito? È una parte del protocollo assolutamente ignorata. E soprattutto che apre porte a falle di sicurezza della madonna immagino una situazione dove tu hai un language model provided l'open API della situazione tu utilizzi con una certa leggerezza un mcp server che fa sampling quindi che si collega al tuo language model e inizia a sfondarlo di richieste cioè è interessante no? si fa pagare per le richieste che tu fai con la tua chiave di Opera. è tutto aperto poi io immagino questa cosa poi va oltre il linguaggio nel senso che adesso i modelli diventano sempre più multimodali sia input che output no? e c'ha questi modelloni dove vuoi mandare testo, immagini, piano piano anche audio, eventualmente video e in output cominciano ad essere addirittura multimodali, quindi c'è diverse modalità anche in termini di risposta. Non ho idea di cosa andrà a succedere, però sicuramente è interessante. però è molto più complicato di come adesso che qui c'è ancora una forte tendenza a a a pensare ai modelli come produttori di stringhe che in parte è vero in realtà è molto più vasta la faccenda infatti l'altro protocollo quello di Google a tua che in teoria incapsula MCP prevede eh non so se posso parlare direttamente non è un protocollo di comunicazione passiamo su A2A eh A2A prevede è un framework un protocollo più ampio proprio di comunicazione uomo macchina e macchina macchina soprattutto macchina macchina dove danno per scontato che ci siano dei task che che che racchiudono queste comunicazioni questo task ha uno status e ci sono tra di loro per completare questo task. E come si parlano? Tramite messaggi e non solo messaggi, qua secondo me sta l'intuizione, secondo me è interessante, si scambiano artefatti, quindi listati di codice, immagini, pezzi di video, zip, la qualunque. Il fatto che Google Google at Wed è una proposta di Google che tra l'altro deriva anche in questo caso da un prodotto super enterprise che loro stanno costruendo che si chiama Agent Space, che circola già da diversi mesi e che è un po' una risposta al copilot studio di Microsoft che è molto simile. Queste qui sono piattaforme per agenti, diciamo, che volendo loro potrebbero per aprire a terze parti. Queste piattaforme di base, c'hai tutti questi agenti, puoi orchestrarli, puoi lanciarli, puoi vedere in che stato hanno, e tutto rotondo nel task. Hai diversi agenti, hai i task, e ci si parla tramite messaggi e artefatti. Delegano poi ai singoli agenti quello che vogliono fare in termini di tool di risorse o di raggo, di altre cose o di sistema integration. Per cui Google dice "Hat2A" è un protocollo generale. Adesso non so loro come l'hanno chiamato. "Agent to agent scenarios". Inquadrano proprio interazione di rete, macchina a macchina, come agenti, come programmi che sono il più possibile autonomi. a fine sono sempre servizi web, cioè non è che è troppo più diverso da così. E dentro la gente poi è liberissimo di usare MCP, per quello poi loro dicono "no, noi amiamo MCP", perché in realtà hanno pensato a una cosa molto più vasta. Cioè MCP è proprio una cosa molto più terra a terra, nonostante sia articolatissimo come protocollo, è una cosa molto più legata alle risorse, ai comandi che la gente, chiamato client può utilizzare mentre invece Attua è proprio una definizione, una formalizzazione della comunicazione macchina a macchina in questo contesto qui. Sai che sto facendo proprio delle difficoltà a vederne una una differenza nel senso Cosa Atua formalizza in termini di protocollo? Perché comprendo che ha una visione un po' più olistica della comunicazione tra agenti e questo lo comprendo, invece MCP è un livello sotto, però quali sono gli elementi che Atua formalizza nel protocollo? Secondo me l'essenza è proprio il task, cioè c'è un obiettivo, c'è un obiettivo e ci sono diverse entità che possono espletare questo obiettivo, che ne possono aggiornare lo status e nel collaborare a questo obiettivo si scambiano messaggi e artefatti non solo ma c'è anche una definizione di ogni agente può dichiarare i mime type di entrate ed uscita cioè tu alla gente ti puoi dire dal client, ti dici ok io ti faccio questa domanda mi rispondi in html visto che lo supporti e quello lì invece di risponderti con una stringa ti risponde direttamente con un form magari è molto molto più spinto. Ok è più ampio, chiaro. Insomma pensano a cose a cui noi non non abbiamo pensato e non penseremo per i prossimi. Come si capisce, ti interrotto Luca scusa, io un po' di lag mi sa. No no dicevo pensano a cose abbastanza avanti, insomma pensano già a modellare interazioni che noi ancora oggi forse fatichiamo a visualizzare o a immaginare che ci possono essere su macchina tu macchina per esempio non avrei pensato a mille type per per generare una risposta da un agente in questo modo però renderla standard è una buona idea si capisce forse anche guardando l'agent workspace di google che hanno pubblicato dei video e credo credo che sia ad accesso ristretto e proprio pensato per Enterprise, però loro già dicono che faranno il marketplace per agenti. Se pensi, come posso dire, come se fossero le app su un cellulare, cioè nel senso, se ti guardi Agent Workspace, tu apri questa interfaccia, hai diversi agenti con cui puoi parlare e quando gli dici le cose, ad esempio, guarda devo fare questa cosina qui. Quello lì in base a quello che tu devi fare, decide se risponderti a testo, mandarti un form, delegare poi a un altro agente ancora. Mentre invece MCP è proprio un agente e le risorse che sono a disposizione del singolo agente. A2A è proprio una popolazione di questa roba dove non si prendono decisioni su quello che che fanno, si prendono solo decisioni su come parlano, orientati a che cosa e come dichiarano quello che possono fare. Cioè, se @tua ogni agente mette su web, immagina tu ti metti su un server che espone un agente che è compliant con @tua, tu devi pubblicare sotto punto well known, l'indirizzo quello insomma che si usa di solito per fare queste dichiarazioni di chi sono, cosa faccio, tu dichiari una agent card dove dici io sono l'agente, mi chiamo per esempio, se io faccio un video, diciamo così eh eseguo questa cosa eh questo è il modo in cui mi autentico anche molto molto più libero in termini di autenticazione questi sono i i segnali che mi puoi mandare, questa è la firma delle cose che mi devi mandare, ovviamente ogni agente dice io so fare questo e devi parlare con me in questo modo il che vuol dire che attua è web proprio generale della serie che io metto su un agente e poi lo comincio a spingere poi magari ci mettiamo in squadra e facciamo che i nostri argentini collaborano e facciamo una subscription insieme. Mentre invece MCP è proprio vendor LLM che fa la gente e vuole l'integrazione dei servizi tradizionali nel mondo language model. MCP per come la vedo io eh ragazzi, MCP è più un modo di dire facciamo la system integration per usare qualsiasi cosa con il language model, mentre invece HAT2A è proprio... non c'è neanche il language model, cioè in HAT2A tu non sei costretto ad avere in nessun modo da nessuna parte per forza language model, ti puoi fare una gente che fa tutta l'altra, molto più Si, però chi consuma alla fine un language model o no? Non necessariamente. Non è detto, però in teoria sì. Anche questa è un'altra differenza, forse che ci aiuta a capire. In MCP tipicamente i modelli stanno nel client, il server non è altro che un pezzo di system integration verso API, o chiamate a database, insomma cose di questo tipo. per esempio, dico eh MCP per dire la cosa che ti trovi a utilizzare se c'hai il gestionale per le fatture e tu vuoi che da Cloud eh puoi fare le fatture, allora dice vabbè il mio gestione delle fatture c'è la rest API, faccio la MCP server e wrappo la rest API del gestionale dentro la MCP server e c'è proprio sistema pure, mentre invece attua mi faccio proprio un agente lì dentro che usa il language model e che eventualmente ha a disposizione MCP, che poi usa il gestionale. Dimmi se sto capendo male, ma a tua mi viene da immaginarlo come più un protocollo d'orchestrazione che è un protocollo di comunicazione cioè quello che io vedo su Atuada come me lo descrivi non ho approfondito l'argomento però è più un sistema di processo autonomo che paradossalmente può prendere una piega che tu non controlli nel senso che gli agenti ritornano risposte questa risposta magari può triggerare un altro agente che fa qualcos'altro, che ritorna una risposta diversa, che triggera un altro ed è un qualcosa che potrebbe prendere una piega completamente autonoma. Eh sì sì, concordo, è molto più pericoloso, anche molto più ambizioso, molto più astratto. Infatti quando loro nella documentazione di Attua loro hanno proprio dedicato una pagina per dire "Attua ama MCP", la merdagine di questa cosa solo sigle però loro secondo me ci vengono a dire quella cosa secondo me non è semplicemente un modo di dire no noi sposiamo gli standard nascenti ma è un modo per dire noi in Google l'abbiamo pensata molto più lunga di voi sì perché loro si basano sul concetto del non strutturato che è quello che ha fatto grande Google la puzza di quello che sento realtà da qua è che Google ha detto noi siamo i padri del non strutturato. NCP di base ha un protocollo bello rigido e l'hai appena detto no? Quindi secondo me il ragionamento è stato, NCP gestisce diciamo che si focusa molto sul rapporto 1 a n, no? Il client che chiama differenti server e il client che si occupa di questo. Invece a 2A io lo vedo molto come un rapporto molti a molti, quindi un'orchestrazione molti a molti, dove c'è l'elemento non strutturato che è nel dna di Google, cioè Google faceva un motore di ricerca con un crawler che prendeva dei dati non strutturati. E quindi secondo me è proprio quella parte. Poi non sono un esperto, onestamente ne so zero, però da come me lo stai raccontando io sento questa vibrazione, diciamo così. Naturalmente qua ci sono da una parte gli scenari etici interessanti da ragionare, nel senso che a a differenza di MPC, MCP, scusatemi sono le dieci e mezza ormai io con gli acronimi, però a differenza di MCP quello che io vedo è che a2a è paradossalmente più libero a livello di decisioni e questa cosa mi apre dei punti interrogativi etici importanti. Come lo vedi Piero dal punto di vista etico? La domanda delle dieci e mezza che non avrei mai dovuto fare. Credo che sia un po' un analogo del cloud e cioè arriva il cloud, questi giganti che offrono che si fanno questi servizi eh gli esperti di settore si cominciano a lamentare che i nostri dati fanno il giro del mondo e non va bene. Chi è che ha vinto a lungo termine? La comodità credo possiamo dirlo che abbia vinto la comodità, cioè ha vinto la semplicità di gestire le nostre cose nel quotidiano e secondo me sai che risposta anche stavolta risposta anche stavolta perché di sicuro una soluzione non è quella dell'Unione Europea che dice basta non non si possono usare modelli fondazione senza certi criteri e lama e meta dice vabbè allora l'Europa non usa lama perché cominciamo a fare richieste dal puntista legale che sono totalmente che facciano il quotidiano. Dall'altra, come hai deciso, i sistemi di questo tipo possono fare cose selvagge e quindi io credo che la risposta stia nell'avvicinarsi piano piano a queste soluzioni, vedere se Google lancia marketplace, Antropic pure potrebbe lanciare marketplace, se questa popolazione di agenti o di risorse per agenti comincia effettivamente a sollevarsi da terra però manomano usciranno una serie di cetrioli di di abusi e di utilizzi strani e poi lo standard verrà adeguato a cose di quel tipo e verranno fuori le leggi questo è un modo molto un giro molto lungo che ho fatto per dirti che ho smesso di pensarci sì chiaro io io io sto vivendo perché ho sposato il conflitto interiore per quanto riguarda il cloud, l'ho vissuto come una battaglia personale sai, quando vedo oggi vedo il cloud come uno strumento geopolitico e quindi ahimè sono nel bel mezzo di questo conflitto interiore dove magari ho una certificazione Microsoft per il cloud e alla fine dico a cazzo ho preso una certificazione in un contesto geopolitico dove magari dovrei tentare più di stimolare e di abbracciare quello che il concetto di cloud europeo e quant'altro no? Però nel contempo penso che l'innovazione debba in qualche modo da avere un po' di spazio ma non debba essere lasciata libera di sovrastare altri ambiti che sono parte della natura dell'uomo e secondo me vanno tutelati. Per quanto riguarda mi faccio ancora delle domande penso per esempio a se in contesti agent to agent dove c'è questa libertà degli agenti di interagire in modo non supervisionato, che cazzo gestisce il conflitto tra gli agenti? Per esempio, una semplice domanda. Questa è una cosa che ho visto scritta dibattuta parecchio in giro proprio riguarda da tua, quindi secondo me sei in compagnia. No approfondirò, approfondirò perché così seguendo il flusso è la prima domanda che mi viene. Cioè il debugging pure diventa impossibile. Ah no su questo su questo pensavo all'observability per esempio no? Quando tu hai detto dati non strutturati o immagini io che ho in testa open telemetry questo periodo che vivo di open telemetry mi dico ma in questi, sai su MCP per me è facile una volta che mi hai detto il protocollo immaginare un sistema di observability pensa che mentre stavi parlando mi chiedevo "esiste un modo per attaccare un'observability a MCP? si può estendere una roba simile a OpenTelemetry per questa roba?" però quando poi siamo passati a parlare agent to agent e abbiamo iniziato a dire output multiformato, no? Eh, observability magari inizia a essere fattibile ma più complessa e quindi bello però c'è ancora tanta strada da fare sia dal punto di vista tecnico in modo da avere gli strumenti per governare questa cosa e sia dal punto di vista etico e uno degli elementi che secondo me ha senso mettere sul tavolo è che questo protocollo è figo però per ricollegarci al ragionamento che abbiamo fatto all'inizio sul fatto che molte di queste innovazioni capitano top down la mia percezione è che con questo tipo di di protocolli che suonano come apriamo abbiamo inventato il nuovo dns adesso svilupperemo sistemi di discoverability per gli agenti che si possono scoprire da soli senza... sì ma in realtà la mia percezione... ciao google, ciao microsoft se siete all'ascolto un grande bacione... ma la mia perfezione è che a livello di narrativa va benissimo, a livello pratico la mia percezione è che si andrà a finire su una sandbox in stile app store dove le interazioni tra le genti sono governati da un'entità centrale e dove quel livello di osservability, quella gestione dei conflitti avviene in ambito centrale ed ecco che qua si accendono altri campanelli di etici no? Vi chiedo scusa se vi ho portato nel mio mondo delle turbe mentali, però in realtà la la la red flag sembra sembra sembra grande. Sarò pessimista, sarò negativista? No no ma guarda per agenti? Guarda quello che dici è cioè è assolutamente così se il risultato se attua è il risultato dell'aver sviluppato il prodotto agent workspace che è un che è una piattaforma per agenti dicono lancierebbe il marcio cioè questo protocollo qui secondo me guarda è un modo per dire ragà avete scritto le app mobile dovete fare il non è che tu devi dire che cosa fa l'app, no? I dip link, i permessi, le cose, vai adesso fai la gente poi magari non stanno su cellulare, stanno distribuiti in rete, però comunque ci saranno registri, ma assolutamente sì. Poi sarebbe interessante vedere come risposta a questo se se effettivamente un protocollo del genere si presta magari anche per esempio a iniziative di comunità eh oppure magari a di enterprise che sono fatti, capito? Ci abbiamo la nuvola di agenti, protocollo A2A però visibile soltanto all'interno di questo di questo gruppo di persone, chi lo sa? Però sì secondo me ci sta, cioè dire che queste qui sono iniziative big tech, ma assolutamente sì, MCP è un'iniziativa per per fare crowdsourcing della System Integration e invece A2A è un'iniziativa perché era un marketplace di entità che fanno cose in modo semi-autonomo. Siamo andati sul negativo mi sa. Forse lo sai che abbiamo iniziato l'episodio di oggi dicendo i protocolli sono sintomo di maturità ed è stata fantastica la piega che ha preso. Però fondamentalmente ecco La cosa interessante secondo me, che dobbiamo prendere da questo, è che in realtà dovremmo pensare a un protocollo come un modo per far comunicare entità di sistemi di ambienti diversi per cui ecco magari se affrontiamo o cerchiamo di leggere queste tecnologie non solo con il carico del geek che non vede l'ora di provare la nuova tecnologia ma anche con quella consapevolezza che questo tipo di protocollo può avere un valore anche se si buttano giù dei recinti a quel punto ecco tutto è diverso e con questo insomma abbiamo ci siamo nuovamente inimicati le big tech che avranno cose più interessanti da fare che ascoltare github credo però guarda questa se ne è una buona risposta sai a cosa perché adesso siamo immersi nell'hype che si mette lì e fa calimero, gargamella, cioè ci vuole, cioè qualcuno che dice regà, occhio che c'è sta l'inculata eh sì no cioè qualcuno che dice la verità ci dovrà pure stare da qualche parte poi magari siamo guarda caso chi è che ne parla in questi termini qua? Chi c'ha quarant'anni e programma da quindici, venti. È difficile il ragazzetto dei ventidue, ventitré anni, capito? Che sta arrapato come come un cinghiale dei 22-23 anni, capito, che sta arrapato come un cinghiale, capisce questa roba qua. Eh sì, anche perché noi comunque abbiamo vissuto un po' nell'alto dei nostri 40 anni, abbiamo vissuto la rivoluzione digitale e abbiamo visto anche come l'open source, le comunità open source e anche singole persone, se non gruppi, hanno cambiato le sorti, no, della rivoluzione digitale che altrimenti poteva essere solo nelle mani di pochi attori. Adesso, sì, questi big attori ci sono, esistono, ma per fortuna abbiamo tante comunità open source che in un certo modo li tengono a bada. Poi nel frattempo anche loro si sono evoluti, hanno imparato a travestirsi, sono le dieci e mezza, da Agnellini e anche loro a loro volta fotori dell'open source, però tanto ha cambiato e c'è bisogno secondo me anche in questa nuova rivoluzione di persone che non si accontentano, cioè ci sa, io li conosco i giovani che a vent'anni adesso si avvicinano a questo mondo, non hanno ancora scritto una riga di codice ma hanno già otto app sull'app store, però c'è qualcosa di molto più grande in ballo. Ed è già anche più difficile perché avere le risorse per farte un tuo LLM che possa competere con quelli attuali è già più difficile, quindi le armi della comunità open source sono un po' più deboli. Però insomma non ce lo dobbiamo dimenticare, secondo e li dobbiamo incentivare, così come penso anche il buon Piero sta facendo da parecchi mesi, no anche qualche anno a questa parte, nell'abito AI intendo. Sono concorde. Sì, no, mentre parlavate pensavo a una cosa in realtà. Adesso forse la piega, il discorso ha preso una piega negativa e forse stiamo solo vedendo lato negativo sai l'intero per se non pensiamo alla sandbox o al marketplace e la vediamo un po con gli occhi dell'amore ecco probabilmente potremo vedere una roba in stile dns no quindi ogni server espone ogni agente espone la sua interfaccia dall'altro canto però la vecchiaia ci dice, fino a oggi molte big tech ci hanno detto "dammi i dati, dammi i dati, no? Dammi i tuoi dati che sono importanti". Con Antois questa cosa mi puzza di uno shifting che dice "dammi i dati ma fammi anche cose quindi dammi dati e fammi cose che io da solo magari non potrei fare non è un problema per noi, è un problema per il settore il tempo sarà maestro credo. una cosa su cui penso siamo d'accordo è probabilmente se non sono questi i protocolli di del a revisioni di questi però in generale c'è questa ambiguità e questa secondo me è oggettiva cioè in entrambi questi casi c'è dalla parte di MCP c'è voglio la system integration dalla parte di A2A c'è voglio il marketplace voglio l'ecosistema perché parte comunque da entità che ragionano in quel modo lì. Cioè se tu ti leggi... come si chiama il libro di Tim Berners-Lee? "Weaving the Web", non so se l'avete mai... Allora, questo è il libro che ha scritto Tim Berners-Lee, che è il tizio che ha inventato insomma i protocolli HTTP, HTML. Lui ha scritto sto libro in tempi assolutamente non sospetti, non so se degli di anni novanta questo libro e l'ultimo capitolo di Weaving the Web di Sir Tim Berners-Lee è sugli agenti e lui ovviamente aveva immaginato un web basato sui protocolli che lui stava definendo e che già riteneva insufficienti poiché legati soltanto ai documenti e non ad attività applicazione e cose più sofisticate ragazzi c'è che mi ha chiesto un'opera vent'anni fa e diceva eh secondo me in futuro questi che adesso sono documenti saranno dei veri e propri agenti e la parte essenziale sarà stabilire lo stato della comunicazione e soprattutto il fatto che ci sia un sistema di firme e controfirme crittografiche di modo che ognuno sa effettivamente chi ha fatto cosa quando e se e gli è permesso di farlo e aveva centrato il problema sul discorso di critografia, di sicurezza nel capire chi ha fatto cosa quando? Tra l'altro quello fine anni '90, anni 2000 era il periodo, forse sì, 2000, fino al 2000 era il periodo dei suffer punk a manetta, nel senso era proprio un'epoca culturale permeata da questo tipo di ragionamenti quindi oh vero mamma mia ragazzi un po' perché allora noi sviluppatori per sta pressa sta roba ok tenti scimori perché lo fai nel tempo libro alla fine e se guardi pure il mondo dei content creator stanno tutti in crisi per l'intelligenza l'intelligenza artificiale comunque mangia mangia talento eh la storia del del no? L'intelligenza artificiale che fa tutte le immagini, toglie l'ora ai designer, è vero che in un certo punto? Però una componente c'è e c'è con queste cose ci si fanno i conti, stanno lì ed effettivamente c'è una stanca generale associata all'entusiasmo generale di avere tutti questi perché è difficile per la velocità con cui si stanno evolvendo, capire cosa ci mettiamo a fare? cioè io mai come in questo periodo non so se anche voi vi chiedo se vi sentite così io mai come in questo periodo da tecnico da da programmatore, da da da scientist, da ingegnere, tu lo sai che in sei mesi probabilmente cambi stack, devi reinventare un grosso pezzo ma adesso a me sembra che è un mese e mezzo il ciclo. Concordo con te a meno che non ci si sposta nella system programming a meno che non smettiamo di essere web developer ci spostiamo verso così un un pochino più core e forse quello dà un po' stabilità, il problema è che sto iniziando a percepire che ci sia qualcosa che traballa anche a quel livello. Questa era la mia certezza fino a qualche mese fa, nel senso iniziamo a fare un po' di system programming, iniziamo a fare un po' di computer science, ne abbiamo parlato un paio di episodi fa con Michele Riva, no? Cioè, meno web development e un pochino più di computer science, è quello da stabilità però onestamente se tu mi dici prova a immaginare quello che sarà l'IT tra cinque anni o dieci anni avrei un grande punto interrogativo se non l'avessi chiesto dieci anni fa più o meno. Dieci anni fa avresti sbagliato probabilmente. avrei sbagliato però avrei detto che avrei previsto il lavoro che sto facendo oggi con estrema facilità non so se sono riuscito a spiegarlo, mi sarei riuscito a vedere oggi se tu dici Mauro cosa sarai tra dieci anni? ma non idea probabilmente ed è una cosa che mi sono chiesto riguardando quante ratte del mutuo mi mancano da pagare. C'è però una cosa che secondo me gli argenti non riusciranno a gestire e sono le interazioni umane e sono la gestione degli stakeholder. Ma non lo so questo. No Luca è follino almeno almeno i miei stakeholder. Che non possano gestirli nell'umana maniera sicuramente sì, che non verranno mai sostituiti. Ci sono degli stakeholder dove l'intelligenza artificiale non riuscirà mai a gestirli, l'intelligenza naturale difficilmente riesce a gestirli, quasi mai, quindi proprio l'intelligenza non riesce a gestire questo spill con, questa è la mia conclusione, perché tutto quello che c'è intelligenza non è... non lo so, secondo me le interazioni tra le persone potranno essere un altro elemento pivotale, cioè allora io credo che oggi una cosa non è chiara, per collegarci al concetto di vibe coding che ha tirato Piero e che aprirà, aprirebbe il vaso di Pandora in questo momento, però credo che questi strumenti, Piero l'ha detto in molti dei suoi video, questi strumenti in realtà non sono strumenti per dare risposte ma possono essere degli strumenti interessanti per accompagnare nel ragionamento e se noi inquadriamo questi strumenti in quest'ottica, dobbiamo educarci in quest'ottica, possiamo sopravvivere a questa nuova rivoluzione industriale, dove c'è un elemento politico che non mi piace, però è un elemento politico che non è molto lontano dalla invenzione del vapore, delle macchine a vapore, forse sto dando tanto, tanta importanza a questa rivoluzione, forse anche data dal fatto che rimango comunque uno di quelli che gli piace giocare a queste cosine appena escono. Però stiamo usando questo periodo, da quarantenni che vivono questo periodo ce ne abbiamo anche un po' i coglioni rotti, possiamo nell'alta voce, nel contempo dobbiamo evolverci senza farci mangiare dalla tecnologia, perché c'è sempre qualcosa che possiamo aggiungere o almeno questo è quello che mi piace immaginare. immaginare. Quello sicuramente, insomma, ci si adatta. Non so, se io devo pensare, insomma, tutta la storia vissuta dall'alto dei nostri, dei miei 40 anni, vediamo sempre che l'uomo, il programmatore, insomma, l'utilizzo della tecnologia si è sempre adattata a quello che si poteva fare ma soprattutto quello che non si poteva fare. Il mio esempio preferito è quando io facevo i siti web nel 98/2000, non mi ricordo, e chiedevano di fare le cornici colorate, i bottoni in un certo modo con i gradienti, con le ombre, con quello, tu ti dovevi ammazzare perché Internet Explorer 5 non supportava nulla, allora dovevi ritagliare le immagini dovevi fare, poi hanno standardizzato i CSS, hanno fatto "vuoi fare l'ombra? Basta fare queste righe di CSS". Tempo tre settimane, flat design, perché c'è che cazzo, lo possiamo fare quindi non è più interessante farlo e via di flat design. Quindi noi alla fine ci adattiamo a quello che possiamo fare e il fatto che adesso con le AI, porca miseria, fare praticamente tutto perché io ho anche una cosa che ho pensato, ho sempre avuto il pallino dei giochi e ho sempre avuto come problema la grafica perché come one man io non posso farlo e adesso mi posso far generare gli sprite degli omini animazioni da cgpt che poi non si sa dove dove li prende, adesso che posso fare tutto questo non lo faccio più e quindi non lo so ci sarà qualche, ci sarà qualche cambiamento nel nostro approccio alla tecnologia, questo sono abbastanza sicuro, non so in quale direzione e come materialmente sarà però sarà così. È una cosa che, almeno io personalmente, sto vivendo, non so se avete anche voi l'impressione, cioè dicono che l'intelligenza artificiale, o che è l'LM, insomma quello che è, la stiamo sopravvalutando perché non sarà mai come l'intelligenza umana, molti dicono, ma io ho il feeling opposto, cioè mi sto rendendo conto che forse abbiamo sempre sopravvalutato l'intelligenza umana, visto che è ben emulabile da tutto sommato qualcosa di abbastanza recente e nemmeno troppo sofisticato. Cioè una volta trovato l'algoritmo di allenamento che è modellato con il nostro cervello, alla fine ci è voluto relativamente poco ad imitare centinaia di migliaia di anni di evoluzione. Quindi io mi chiedo, forse ci stiamo sopravvalutando noi, non è che stiamo sopravvalutando l'intelligenza artificiale. però questo è il mio feeling, non so quanto ho condiviso. Guarda, penso che un tuo collega, t'opinione è un premio Nobel, quello che ha appena detto, lo dice pure Hinton, quindi e tra l'altro secondo me ci hai preso alla grande perché ragazzi ma se ti dicevano a proposito dei dieci anni fa, no? Se ti dicevano dieci anni fa che tu parlavi con con una macchina in chat, adesso pure a voce, e questa qui contemporaneamente conosce tutta la cucina di tutti i posti del mondo, come funziona qualsiasi tecnologia diffusa, conosce la storia del Cile degli anni quaranta dell'ottocento, conosce cioè la la la quantità di conoscenza che ha è sia ampia che profonda e quando qualcuno viene da me e dice "no perché c'ha non è che GPT è stupido? No, cioè GPT è molto più intelligente di me e di te messi insieme forse. Poi per carità è un language model stateless produce un token alla volta però dal punto di vista del delle pretese che abbiamo cioè più queste macchine diventano abili a fare cose più spostiamo il concetto di intelligenza e soprattutto questo secondo me è un'ottima in pochi invece di mettere in discussione l'intelligenza della macchina mettono in discussione l'intelligenza umana dei mammiferi non solo ma se guardi la fisica che c'è dietro le reti neurali ti rendi conto che non è detto che l'intelligenza sia necessariamente neurale oltre che biologica. Cioè è possibilissimo avere intelligenze molto più spiente di noi che non solo sono artificiali ma potrebbero che sono delle tecnologie basate su meccanismi completamente diversi dai neuroni perché l'intelligenza la puoi definire come compressione, come come un fenomeno di teoria dell'informazione quindi se stiamo vivendo un periodo poi l'altra cosa che volevo aggiungere scusate il pippone ragazzi ma ma avete ma questa cosa mi ha fatto gasare ci sono questi due economisti dell'MT che hanno pubblicato riguardo al discorso del come ci mi è venuto in mente mentre lo dicevi il discorso del di tanti di noi magari delle nostre famiglie passate che facevano gli agricoltori e che si sono adattati in pochi decenni in realtà alla vita industriale e poi alla vita del terzo settore. Ah questi due economisti dicono eh quella che è stata la la grande evoluzione industriale e che ci ha di base liberato dello sforzo fisico in un certo punto in poi arriva l'automobile, arriva il battello, arriva macchina a vapore, tutti i macchinari sono alimentati da energia eh combustibile sì però di base lì c'è un'automazione del movimento fisico loro dicono la seconda rivoluzione industriale che non è ancora arrivata la prima è quella del della formazione del movimento esatto eh e allora questo mette in quello che ha appena detto no? Perché noi abbiamo sempre pensato che l'uomo sia sforzo fisico, sforzo cognitivo e emozioni rimane una sola cosa rimane una sola cosa rimangono le emozioni teniamocele strette Io direi che con questo. Diciamo l'amore e le emozioni, quello ci rimane. No però è, cioè sì, io tra l'altro ho scoperto proprio da te Piero, vedendo un video del "Il Paradosso di Mora", se non sbaglio, dove ok, noi le, che dice che le abilità fisiche che abbiamo si sono evolute in centinaia di migliaia di anni, hanno avuto molto più tempo per raffinarsi nonostante la complessità di dover gestire il nostro corpo, quindi mantenere un equilibrio, correre, rampicarsi eccetera eccetera, quando invece l'intelligenza umana ha avuto pochi millenni di addestramento e quindi ci siamo resi conto come alla fine quello che noi facciamo sono attività appunto relativamente semplici. Mi chiedo come, mi sono chiesto, ok chissà come saremmo tra 300 mila anni, ipotizziamo che possiamo essere ancora qui, però credo che a questo punto con l'intelligenza artificiale possiamo vedere uno scorcio in pochi decenni. di quello che avremmo potuto essere fra centinaia di migliaia di anni. Però teniamoci strette le emozioni che intanto quelle sono. LM: Mi ricordo, ho preso in giro per tutta la vita questi qui della singolarità, proprio il tempo passa e poi ti ricordo che questi tizi forse questa impennata l'hanno vista. Guarda, se ci vogliamo lasciare andare un po' di fantascienza, se me la concedi, se la concedete io vedo tanto nanosimbiosivo uomo macchina nel senso che una volta che hai avete sentito parlare dei brain organoids sono delle polpette di tessuto nervoso sviluppate a partire da embrioni da cellule embrionali scusa come si chiamano le cellule quelle multipotenziale staminale da da cellule umane che vengono coltivate come polpettine di tessuto nervoso e ci sono c'è una letteratura scientifica pure cicciotta di addestrare queste polpette a fare delle cose con segnali elettrici e con ormoni dopamina zucchero quindi se immagini tutto questo filone che noi stiamo vivendo che magari appunto tra dieci anni ci sembrerà una cosa antiquata dove ci abbiamo sti sti sti sti file giganti con dentro miliardi di numeri hai questo filone della coltivazione biologica di tessuto nervoso che fanno fatica a tenere vivo però già sono in grado di fargli fare che è diventata un obiettivo io vedo tanto un futuro di di simbiosi dove adesso ti cambi il cuore, poi ti cambi i denti, poi ti cambi la retina e poi ti cambi l'area di broca, ti cambi il cervelletto, ti cambi eh quel maledetto di Elon Musk che era un mito e del giro di qualche anno è diventato l'opposto in qualche modo. non dobbiamo diventare la specie multiplanetaria? Secondo me dovrebbe aggiungere se ci mescoliamo alle macchine diventiamo multiplanetari, se no no. Beh è quello che sta anche provando a fare, come che si chiama Neuralink? Adesso non so come sta andando, però sì avevo sentito anche di questi tessuti che vi avevano addestrati in qualche modo a fare a fare robe, è possibile giocare a Tetris, credo, no a Pong. Sì, no, interessante. Un po' inquietante. Hai una scheda video ma anziché avere del silicio e elementi hai delle cellule forse umane o di qualcuno o di qualcosa vive che forse ti aiutano, fanno cose. E là si apre forse anche un portone sull'etica e su che diritti abbiamo, che diritti vogliamo dare a un qualcosa, cosa che pensa più e meglio di noi. Comunque. Eh sì, no, è cinefraio, cinefraio totale. e poi dall'altro sempre tornando a Hinton lui lavorava alle reti analogiche queste qui delle il brain organ sono un tipo di comunque di rete neurale essendo tessuto è è analogico nel senso che non è che lo non fai copia e incolla lui diceva guarda secondo me eh le i modelli digitali basati su su molto più intelligenti di noi potenzialmente perché il il tessuto di apprendimento analogico è vero che consuma pochissime energie, è vero che c'è tutta una serie di proprietà fantastiche però eh non non può fare apprendimento in modo federato e questo te lo dice un premio Nobel secondo lui questo è il motivo essenziale per cui l'intelligenza che la data generale può essere molto più spinta di quella biologica analogica. In che senso l'apprendimento federato? Nel senso che se tu prendi eh le le le decine di migliaia di di GPU che Open AI usa per addestrare i modelli, no? Loro prendono questo modello che alla fine è un file cioè eh è un file lo la GPU, poi prendono i dati e loro mandano diverse di dati in parallelo a diversi cluster di GPU. Eh fanno la cioè vabbè fanno la fanno passare questi dati nella rete, calcolano l'errore, dopodiché calcolano il gradiente della rete, cioè qual è la correzione che devono fare su tutti i pesi per fargli apprendere i dati nuovi e poi questi gradienti vengono sommati viene fatto un update dei pesi e questo update dei pesi viene distribuito a tutte quante le copie. Cioè vuol dire che se tu hai duemila agenti in grado di imparare dai dati continuamente e ognuno può condividere in ogni momento quello che ha imparato con ogni altro, cioè non è è diversa dall'intelligenza come la nostra che alla fine stai in un cranio, ci parliamo e tramite il linguaggio ci scambiamo delle cose. Cioè quella lì è la famosa hive in mind, cioè quella lì è una flotta, è un'intelligenza che è una flotta, non è un'entità corporea diciamo, non sta in un individuo, hanno tutti la stessa mente. Perfettamente replicabile insomma. Eh sì, apprendimento federato quello è. Abbiamo aperto argomenti che vanno ben oltre il concetto dei protocolli, però è sempre un piacere parlare di cose un po' più ampie che del classico giocattolo della domenica che ci piace fare con amici come Piero, queste cose è facilissimo farle, farle, nel senso che ogni volta riusciamo sempre a lasciarci trasportare da ragionamenti che ci portano in altri nidi e soprattutto stimolano il nostro pensare libero. Ho delle difficoltà a descriverlo, però il fatto di essere liberi di pensare, di arrivare guidati da un ragionamento in posti dove magari non era previsto arrivare è sempre una delle libertà che noi ci prendiamo qua su Gitbar e che oggi ci siamo prese grazie all'aiuto la presenza di di Piero che è sempre super super super gradita però ahimè è passata un'ora e mezza dell'episodio e siamo arrivati al paese dei balocchi. "E conducono il paese dei balocchi" "Ah il paese dei balocchi" Il Paese dei Balocchi è il luogo dove condividiamo con voi un'idea, un libro, un qualunque cosa abbia catturato la nostra attenzione e valga la pena essere condiviso nella nostra community. Quindi la prima domanda che ho oggi è... Piero, hai qualcosa per noi? Volentieri, riguardo a librerie oppure libri, qual è la... Qualunque cosa! Ho già menzionato l'ultimo capitolo di Weaving the Web, quello lo raccomando ancora, e invece riguardo le librerie, tanto per capire e tornare al discorso di ricerca artificiale potentissima, ma anche contemporaneamente così terrena, così volgare a volte, sto facendo largo uso di una libreria che si chiama Jason Repair, riparazione di JSON, sia in Python che in JavaScript. Questa libreria serve per fare in modo che quando chiedi al language model di produrti una struttura dati, siccome spesso la fanno tutta storta, mancano delle virgolette, queste sono librerie specializzate nel fissare la sintassi di una struttura dati prodotta da un language model. noi sentivamo bisogno di questa perché mi capitava e mi capita spessissimo. Questo è molto figo sai? Per esempio i tool di cui parlavamo prima, tipicamente la scelta del tool è fatta con un JSON, cioè tu dici al language modeller "questi sono i tool, mi dici quale JSON vuoi usare e che argomenti gli devo passare" e gli passi anche il JSON schema degli argomenti se ci avete fatto caso e opinai quello fa infatti cioè prima che uscisse sta roba del function calling direttamente nell'API prima dei chat model io mi ricordo che facciamo sta roba erano delle spaghettate inguardabili però che bello era come il CSS appunto dove ti facevi le le cose che ancora non erano uscite no? E secondo me parla anche è perché è eloquente questa questa questa la presenza di ripriego è eloquente per farci capire che sì magari ci lasciamo andare un pochino tra amici e colleghi al discorso intelligenza artificiale, no? Eh che cosa succede tra dieci anni e il brain organoids e la rivoluzione industriale però fatto sta che questo è un produttore di stringhe e tu lo dici continuamente prenderà martellate per fargli produrre sensate e questa è la quotidianità di questa cosa però nel resto del nostro universo potenzialmente questo stesso oggetto ci fa lavorare magari la metà del tempo oppure il doppio non lo so. Sì sì sì bello naturalmente condividiamo il link nelle note dell'episodio Luca, adesso mi è venuto anche in mente una cosa delle cose che dobbiamo fare noi per non perdere la nostra umanità da sviluppatore, quindi Mauro ha detto di imparare, di concentrarsi sulle system integration, sulla programmazione dei sistemi, io penso anche che è un buon momento per diventare regular expression expert perché lì penso che gli LLM cannano alla grande e voglio vedere i vibe coder a debbagarli, quindi credo che sarà il mestiere del futuro. Detto questo il mio balocco non l'ho provato ma lo proverò presto, ho sentito parlare molto bene di Inmic, che è un self-hosted photo video management solution, lo prendo dal sito, cioè il vostro google photo on premise, è open source a gpl e quindi ci sta. E visto che non vorrei forse rubare il balocco a Mauro, visto che si parlava di agenti, di intelligenza artificiale, per chi non l'ha già stato sicuramente ballocato però questa volta credo sia proprio in topic n8n per le automazioni mi sembra che abbia una dual license ma è un bel tool Mauro - allora io ero un po' combattuto perché avevo una serie di balocchi tra cui scegliere però in realtà abbiamo... Piero ha parlato di task oggi e voglio riportare un balocco che portai un po' di tempo fa proprio riguardo ai task quando lavoravo a un tool che doveva coordinare una serie di task in background scusate stavo sbadigliando silenziosamente dovevo coordinare una serie di task in background il tool è trigger.dev che ha rilanciato una la nuova beta v4 qualche giorno fa che cos'è trigger.dev onestamente è una piattaforma per orchestrare dei job funziona con con diversi diversi linguaggi tra cui javascript e node.js e ha un sacco di funzionalità che per esempio semplificano il video processing o che permettono di mettere dei weight ai task, orchestrare workflow, permettono l'interazione o comunque di simulare attività di agent AI, retries, insomma c'è è possibile fare diverse cose col proprio codice ma la cosa più interessante o o almeno il motivo per cui io lo uso è appunto per orchestrare dei worker, far lavorare più worker in un workflow ed è questa cosa è molto figo, è molto semplice e ha una user è una developer experience allucinante quindi se avete qualcosa da fare in quel modo ecco buttateci un occhio perché può essere un tool interessante. Folks 11 della sera io ormai non so come faccio a reggermi in piedi infatti sono seduto io ringrazio nuovamente Piero, Piero ti avevo promesso che ti avrei rirotto le scatole e l'ho fatto e sapi che lo rifarò ancora. Volentierissimo. È stato un super piacere avere ti averti qua con noi e continuiamo a seguire i tuoi short su youtube che sono super interessantissimi. Grazie anche insomma della bella chiacchierata mi sono trovato bene. Anche anche noi insomma è stato un super super super piacere. Grazie ancora. Ah scusa Luca ti ho parlato addosso, prego. No ringraziamo anch'io, salutavo, è stato un piacere soprattutto anche, no non soprattutto alla fine, quindi anche l'inizio, metà e alla fine però abbiamo fatto un bel excursus, mi è piaciuto. Particolarmente ringrazio anche Piero e Mauro per l'occasione che mi date per stare qua in prima in prima linea, non dover aspettare un giorno per sentire la puntata. Grazie a te, ci si vede ragazzi. Ciao ciao ciao. Ehi Luca, niente sigla, ok. No niente sigla, niente sigla, intanto prima di iniziare la puntata ci siamo detti in una chiacchierata pre episodio che eravamo un po' combattuti in realtà perché ci sarebbe piaciuto portare un po' di topic che non sono super deep per esempio parlare di un rag o comunque di argomenti che molti di noi conoscono e e che noi abbiamo sempre evitato di portare come topic per non essere ridondanti adesso quello che ci interessava sapere è se questo tipo di topic che insomma sono un po' ovunque vi interessa che li portiamo col nostro stile dove praticamente si sa dove si inizia e non si sa dove si va a finire però ecco se vi fa piacere contattateci in privato, suggeriteci questi topic basic e possiamo pensare a una serie di episodi dove tocchiamo questi argomenti un po' più basici, fateci sapere ecco. Assolutamente, stiamo parlando di questo perché magari diamo tante cose per scontato però Cioè, magari ci sono degli approfondimenti da fare anche su argomenti che dovrebbero essere noti o ben noti o potrebbero essere più noti, ma che in realtà nel nostro intimo non conosciamo abbastanza. Io ne avrei una tonnellata di questi argomenti, quindi aiutatemi a fare puntate più… a convincere Mauro a fare puntate più basic, qualora fosse necessario. contattateci anche in privato e diteci su che cosa si può si può approfondire parlando anche con AI, con sistemi RAG o cose di questo tipo giusto? sì prima di chiudere però dobbiamo prendere veloci veloci un momento se parte il video forse prima della prossima settimana possibilmente pensavate che ce ne eravamo dimenticati però c'è una cosa che mi ha stupito questo periodo non siamo stati super iper mega presenti eppure c'è qualcuno che mensilmente ci ci supporta anche se non usciamo ogni settimana con un episodio e quindi sento l'esigenza di fare una menzione speciale a Livio che ha come ogni mese inviato tre birre con un messaggio che scrive "ciao Mauro un caro saluto a tutto il gruppo dei fedeli a tutti i membri del gruppo telegram continuo con piacere a sostenervi perché le puntate anche nuove" c'è un messaggio sotto che diceva andiamo vogliamo puntate nuove Livio credimi e credici ci stiamo impegnando in questo e ringraziando Livio noi vi diamo appuntamento alla prossima settimana un abbraccio ciao ciao ciao [Risata] Ciao ciao!